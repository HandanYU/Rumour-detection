{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a00ed975-afc9-4cbe-89e9-651cd7187fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f3821f7-0888-4ca0-a0b5-ed088ca2b77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>reply_reply_count</th>\n",
       "      <th>reply_like_count</th>\n",
       "      <th>reply_retweet_count</th>\n",
       "      <th>reply_quote_count</th>\n",
       "      <th>reply_possibly_sensitive</th>\n",
       "      <th>reply_has_url</th>\n",
       "      <th>reply_mentioned_url_num</th>\n",
       "      <th>reply_id_num</th>\n",
       "      <th>reply_isweekday</th>\n",
       "      <th>...</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>has_url</th>\n",
       "      <th>mentioned_url_num</th>\n",
       "      <th>id_num</th>\n",
       "      <th>isweekday</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>senti_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1249004694950817796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.051326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1267552274819227649</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.011393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1235238334722699265</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>1.959079e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.088659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1248746792914546688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.530263e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.013806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>523820806917603328</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>1.306053e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114537</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021542</td>\n",
       "      <td>0.037443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id  reply_reply_count  reply_like_count  \\\n",
       "0  1249004694950817796           0.000000      0.000000e+00   \n",
       "1  1267552274819227649           0.000048      0.000000e+00   \n",
       "2  1235238334722699265           0.000215      1.959079e-06   \n",
       "3  1248746792914546688           0.000000      6.530263e-07   \n",
       "4   523820806917603328           0.000119      1.306053e-06   \n",
       "\n",
       "   reply_retweet_count  reply_quote_count  reply_possibly_sensitive  \\\n",
       "0             0.000000           0.000000                       0.0   \n",
       "1             0.000000           0.000000                       0.0   \n",
       "2             0.000007           0.000024                       0.0   \n",
       "3             0.000000           0.000000                       0.0   \n",
       "4             0.000004           0.000000                       0.0   \n",
       "\n",
       "   reply_has_url  reply_mentioned_url_num  reply_id_num  reply_isweekday  ...  \\\n",
       "0       0.004405                 0.000000      0.001066         0.000000  ...   \n",
       "1       0.008811                 0.000000      0.004264         0.012048  ...   \n",
       "2       0.013216                 0.000000      0.000000         0.060241  ...   \n",
       "3       0.004405                 0.000000      0.001066         0.000000  ...   \n",
       "4       0.114537                 0.054348      0.062900         0.024096  ...   \n",
       "\n",
       "   quote_count  possibly_sensitive  has_url  mentioned_url_num    id_num  \\\n",
       "0          0.0                 0.0      1.0           0.333333  0.000000   \n",
       "1          0.0                 0.0      1.0           0.000000  0.020408   \n",
       "2          0.0                 0.0      0.0           0.000000  0.000000   \n",
       "3          0.0                 0.0      0.0           0.000000  0.000000   \n",
       "4          0.0                 0.0      1.0           0.666667  0.020408   \n",
       "\n",
       "   isweekday  followers_count  tweet_count  verified  senti_score  \n",
       "0        0.0         0.000557     0.051326       0.0          1.0  \n",
       "1        1.0         0.000012     0.011393       0.0          0.0  \n",
       "2        1.0         0.000048     0.088659       0.0          0.0  \n",
       "3        1.0         0.000015     0.013806       0.0          0.0  \n",
       "4        0.0         0.021542     0.037443       1.0          0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stat = pd.read_csv('./sep_data/train_stat_feat_df.csv')\n",
    "dev_stat = pd.read_csv('./sep_data/dev_stat_feat_df.csv')\n",
    "\n",
    "dev_stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5145a7-616e-4dbe-9030-4b91370ea858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet_id.1</th>\n",
       "      <th>label</th>\n",
       "      <th>reply</th>\n",
       "      <th>reply_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1249004694950817796</td>\n",
       "      <td>covid fact hand dryer effect kill new coronavi...</td>\n",
       "      <td>2020-04-11T16:01:39.000Z</td>\n",
       "      <td>35761403</td>\n",
       "      <td>1249004694950817796</td>\n",
       "      <td>0</td>\n",
       "      <td>1249011200068730880</td>\n",
       "      <td>fact germ breed [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1267552274819227649</td>\n",
       "      <td>expect result husband pend antibodi test pleas...</td>\n",
       "      <td>2020-06-01T20:23:06.000Z</td>\n",
       "      <td>2734457193</td>\n",
       "      <td>1267552274819227649</td>\n",
       "      <td>0</td>\n",
       "      <td>1270394169836568576,1270502071175909376</td>\n",
       "      <td>hi luck boat [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1235238334722699265</td>\n",
       "      <td>covid spread peopl catch covid other diseas sp...</td>\n",
       "      <td>2020-03-04T16:19:03.000Z</td>\n",
       "      <td>53980699</td>\n",
       "      <td>1235238334722699265</td>\n",
       "      <td>0</td>\n",
       "      <td>1235234904281165825,1235234927937048577,123523...</td>\n",
       "      <td>read lot corona viru late think share highligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1248746792914546688</td>\n",
       "      <td>everi news outlet use headlin like antibiot ef...</td>\n",
       "      <td>2020-04-10T22:56:50.000Z</td>\n",
       "      <td>393187879</td>\n",
       "      <td>1248746792914546688</td>\n",
       "      <td>0</td>\n",
       "      <td>1248775858120097792</td>\n",
       "      <td>appar headlin question answer usual [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>523820806917603328</td>\n",
       "      <td>research encount goliath birdeat world largest...</td>\n",
       "      <td>2014-10-19T12:59:47.000Z</td>\n",
       "      <td>39585367</td>\n",
       "      <td>523820806917603328</td>\n",
       "      <td>0</td>\n",
       "      <td>523821510042353664,523822210071658496,52382235...</td>\n",
       "      <td>eu tenho uma dessa em casa sÃ£o Ã³tima para coÃ§a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1249004694950817796  covid fact hand dryer effect kill new coronavi...   \n",
       "1  1267552274819227649  expect result husband pend antibodi test pleas...   \n",
       "2  1235238334722699265  covid spread peopl catch covid other diseas sp...   \n",
       "3  1248746792914546688  everi news outlet use headlin like antibiot ef...   \n",
       "4   523820806917603328  research encount goliath birdeat world largest...   \n",
       "\n",
       "                 created_at     user_id           tweet_id.1  label  \\\n",
       "0  2020-04-11T16:01:39.000Z    35761403  1249004694950817796      0   \n",
       "1  2020-06-01T20:23:06.000Z  2734457193  1267552274819227649      0   \n",
       "2  2020-03-04T16:19:03.000Z    53980699  1235238334722699265      0   \n",
       "3  2020-04-10T22:56:50.000Z   393187879  1248746792914546688      0   \n",
       "4  2014-10-19T12:59:47.000Z    39585367   523820806917603328      0   \n",
       "\n",
       "                                               reply  \\\n",
       "0                                1249011200068730880   \n",
       "1            1270394169836568576,1270502071175909376   \n",
       "2  1235234904281165825,1235234927937048577,123523...   \n",
       "3                                1248775858120097792   \n",
       "4  523821510042353664,523822210071658496,52382235...   \n",
       "\n",
       "                                          reply_text  \n",
       "0                              fact germ breed [SEP]  \n",
       "1                                 hi luck boat [SEP]  \n",
       "2  read lot corona viru late think share highligh...  \n",
       "3          appar headlin question answer usual [SEP]  \n",
       "4  eu tenho uma dessa em casa sÃ£o Ã³tima para coÃ§a...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweet = pd.read_csv('./sep_data/train_tweet_df.csv')\n",
    "dev_tweet = pd.read_csv('./sep_data/dev_tweet_df.csv')\n",
    "\n",
    "dev_tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d9d7b-b4cc-4144-8a0b-ac2e1f50d586",
   "metadata": {},
   "source": [
    "### Fill NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e477626-165a-4dd4-8b98-b70c007f79a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 522 entries, 0 to 521\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_id    522 non-null    int64 \n",
      " 1   text        522 non-null    object\n",
      " 2   created_at  522 non-null    object\n",
      " 3   user_id     522 non-null    int64 \n",
      " 4   tweet_id.1  522 non-null    int64 \n",
      " 5   label       522 non-null    int64 \n",
      " 6   reply       522 non-null    object\n",
      " 7   reply_text  518 non-null    object\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 32.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dev_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62faa088-f952-4217-8d4d-9d51ca76de70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1542 entries, 0 to 1541\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_id    1542 non-null   int64 \n",
      " 1   text        1542 non-null   object\n",
      " 2   created_at  1542 non-null   object\n",
      " 3   user_id     1542 non-null   int64 \n",
      " 4   tweet_id.1  1542 non-null   int64 \n",
      " 5   label       1542 non-null   int64 \n",
      " 6   reply       1542 non-null   object\n",
      " 7   reply_text  1532 non-null   object\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 96.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "439ce649-ba89-4df2-b886-f55ce3b07f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tweet.reply_text.fillna('', inplace=True)\n",
    "train_tweet.reply_text.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "580c969b-f940-445c-bc8a-bc699a5220a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 522 entries, 0 to 521\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_id    522 non-null    int64 \n",
      " 1   text        522 non-null    object\n",
      " 2   created_at  522 non-null    object\n",
      " 3   user_id     522 non-null    int64 \n",
      " 4   tweet_id.1  522 non-null    int64 \n",
      " 5   label       522 non-null    int64 \n",
      " 6   reply       522 non-null    object\n",
      " 7   reply_text  522 non-null    object\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 32.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dev_tweet.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d11469-56b1-4ba0-b50f-96208aabf747",
   "metadata": {},
   "source": [
    "### Get Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e5792f-a409-41de-9317-45adb20e7aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/522 [00:00<?, ?it/s]C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_18288\\1498738565.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dev_tweet.text.iloc[i] = '[CLS] ' + str(dev_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(dev_tweet.reply_text.iloc[i]).strip()\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 522/522 [00:07<00:00, 71.99it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(dev_tweet))):\n",
    "    dev_tweet.text.iloc[i] = '[CLS] ' + str(dev_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(dev_tweet.reply_text.iloc[i]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e24eefb-945f-4aee-a8ce-620ecbad2e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1542 [00:00<?, ?it/s]C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_18288\\569037025.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_tweet.text.iloc[i] = '[CLS]' + str(train_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(train_tweet.reply_text.iloc[i]).strip()\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1542/1542 [00:17<00:00, 85.96it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(train_tweet))):\n",
    "    train_tweet.text.iloc[i] = '[CLS]' + str(train_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(train_tweet.reply_text.iloc[i]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62fa74a3-39cd-4058-9837-b064bf613183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] expect result husband pend antibodi test pleas may [SEP] hi luck boat [SEP]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_tweet.text.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d7f58c5-7808-46b1-b541-63062280a714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf57658d-7846-448f-90e9-a11e2849e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee25759-322a-420b-8a7d-84b2be197b6c",
   "metadata": {},
   "source": [
    "### BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aadc52e-0850-448b-8282-6b35952d9d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 522/522 [02:50<00:00,  3.07it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1542/1542 [08:05<00:00,  3.18it/s]\n"
     ]
    }
   ],
   "source": [
    "max_len = 256\n",
    "dev_tokens = []\n",
    "train_tokens = []\n",
    "\n",
    "for i in tqdm(range(len(dev_tweet))):\n",
    "    txt = dev_tweet.text.iloc[i]\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    if len(tokens) < max_len:\n",
    "         padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "    else:\n",
    "        padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "    attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "    seg_ids = [1 if token == '[SEP]' else 0 for token in padded_tokens]\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    token_ids_t = torch.tensor(token_ids).unsqueeze(0) #Shape : [1, 12]\n",
    "    attn_mask_t = torch.tensor(attn_mask).unsqueeze(0) #Shape : [1, 12]\n",
    "    seg_ids_t   = torch.tensor(seg_ids).unsqueeze(0) #Shape : [1, 12]\n",
    "    outputs = bert_model(token_ids_t, attention_mask = attn_mask_t,\\\n",
    "                                  token_type_ids = seg_ids_t, return_dict=True)\n",
    "    cont_reps = outputs.last_hidden_state\n",
    "    cls_rep = cont_reps[:, 0]\n",
    "    dev_tokens.append(cls_rep.detach().numpy())\n",
    "\n",
    "for i in tqdm(range(len(train_tweet))):\n",
    "    txt = train_tweet.text.iloc[i]\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    if len(tokens) < max_len:\n",
    "         padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "    else:\n",
    "        padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "    attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "    seg_ids = [1 if token == '[SEP]' else 0 for token in padded_tokens]\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    token_ids_t = torch.tensor(token_ids).unsqueeze(0)\n",
    "    attn_mask_t = torch.tensor(attn_mask).unsqueeze(0)\n",
    "    seg_ids_t   = torch.tensor(seg_ids).unsqueeze(0)\n",
    "    outputs = bert_model(token_ids_t, attention_mask = attn_mask_t,\\\n",
    "                                  token_type_ids = seg_ids_t, return_dict=True)\n",
    "    cont_reps = outputs.last_hidden_state\n",
    "    cls_rep = cont_reps[:, 0]\n",
    "    train_tokens.append(cls_rep.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6fad0a-794c-4b6c-8958-07e9a4da423d",
   "metadata": {},
   "source": [
    "### BERT seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d9adfbd5-67e1-4334-8ccf-4cb9af1b7580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 522/522 [00:03<00:00, 153.04it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1542/1542 [00:06<00:00, 227.24it/s]\n"
     ]
    }
   ],
   "source": [
    "max_len = 256\n",
    "dev_seq = []\n",
    "train_seq = []\n",
    "dev_mask = []\n",
    "train_mask = []\n",
    "dev_seg = []\n",
    "train_seg = []\n",
    "\n",
    "for i in tqdm(range(len(dev_tweet))):\n",
    "    txt = dev_tweet.text.iloc[i]\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    if len(tokens) < max_len:\n",
    "         padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "    else:\n",
    "        padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "    attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "    seg_ids = [1 if token == '[SEP]' else 0 for token in padded_tokens]\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    # token_ids_t = torch.tensor(token_ids).unsqueeze(0) #Shape : [1, 12]\n",
    "    # attn_mask_t = torch.tensor(attn_mask).unsqueeze(0) #Shape : [1, 12]\n",
    "    # seg_ids_t   = torch.tensor(seg_ids).unsqueeze(0) #Shape : [1, 12]\n",
    "    \n",
    "    dev_seq.append(token_ids)\n",
    "    dev_mask.append(attn_mask)\n",
    "    dev_seg.append(seg_ids)\n",
    "    # outputs = bert_model(token_ids_t, attention_mask = attn_mask_t,\\\n",
    "    #                               token_type_ids = seg_ids_t, return_dict=True)\n",
    "    # cont_reps = outputs.last_hidden_state\n",
    "    # cls_rep = cont_reps[:, 0]\n",
    "    # dev_tokens.append(cls_rep.detach().numpy())\n",
    "\n",
    "for i in tqdm(range(len(train_tweet))):\n",
    "    txt = train_tweet.text.iloc[i]\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    if len(tokens) < max_len:\n",
    "         padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "    else:\n",
    "        padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "    attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "    seg_ids = [1 if token == '[SEP]' else 0 for token in padded_tokens]\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    \n",
    "    train_seq.append(token_ids)\n",
    "    train_mask.append(attn_mask)\n",
    "    train_seg.append(seg_ids)\n",
    "    # token_ids_t = torch.tensor(token_ids).unsqueeze(0)\n",
    "    # attn_mask_t = torch.tensor(attn_mask).unsqueeze(0)\n",
    "    # seg_ids_t   = torch.tensor(seg_ids).unsqueeze(0)\n",
    "    # outputs = bert_model(token_ids_t, attention_mask = attn_mask_t,\\\n",
    "    #                               token_type_ids = seg_ids_t, return_dict=True)\n",
    "    # cont_reps = outputs.last_hidden_state\n",
    "    # cls_rep = cont_reps[:, 0]\n",
    "    # train_tokens.append(cls_rep.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0c85e1-9dd7-467c-a3f4-3d49fdbc43a2",
   "metadata": {},
   "source": [
    "### test BERT adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "d14e6939-428d-4eb8-b857-e85c5999baa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdTweetDataset(Data.Dataset):\n",
    "    def __init__(self, seq, mask, seg, y):\n",
    "        self.seq = torch.tensor(seq)\n",
    "        self.mask = torch.tensor(mask)\n",
    "        self.seg = torch.tensor(seg)\n",
    "        self.y = torch.tensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.seq.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.seq[idx],self.mask[idx],self.seg[idx], self.y[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "5c982771-f7de-4e1b-b6ca-25dc0b33d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_tweet['label']\n",
    "y_dev = dev_tweet['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "23186e80-a34a-4888-b065-20a04b64826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = AdTweetDataset(train_seq, train_mask, train_seg,y_train)\n",
    "dev_set = AdTweetDataset(dev_seq, dev_mask, dev_seg, y_dev)\n",
    "\n",
    "train_loader = Data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "dev_loader = Data.DataLoader(dev_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "ac4ee5f3-9a21-4305-9296-146e7ae607a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RumorClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RumorClassifier, self).__init__()\n",
    "        #Instantiating BERT model object \n",
    "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        self.ffnn = nn.Sequential(nn.Linear(791,128),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(0.3),\n",
    "                                 nn.Linear(128,64),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(0.3),\n",
    "                                  nn.Linear(64,1),\n",
    "                                  nn.Sigmoid()\n",
    "                                 )\n",
    "\n",
    "    def forward(self, seq, attn_masks, seg, stats):\n",
    "        '''\n",
    "        Inputs:\n",
    "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
    "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
    "        '''\n",
    "\n",
    "        #Feeding the input to BERT model to obtain contextualized representations\n",
    "        outputs = self.bert_layer(seq, attention_mask = attn_masks, return_dict=True)\n",
    "        cont_reps = outputs.last_hidden_state\n",
    "\n",
    "        #Obtaining the representation of [CLS] head (the first token)\n",
    "        cls_rep = cont_reps[:, 0]\n",
    "        \n",
    "        x = torch.cat((cls_rep,stats),dim=1)\n",
    "        #Feeding cls_rep to the classifier layer\n",
    "        logits = self.ffnn(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "2a15bb73-449a-438b-9037-7e7db3321991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache ()\n",
    "net = RumorClassifier()\n",
    "# net = net.to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "opti = optim.Adam(net.parameters(), lr = 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "99dd698a-ed70-46b8-a860-bb755cba759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, criterion, dataloader, device):\n",
    "    net.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq, mask, seg, labels, idx in dataloader:\n",
    "            # seq, labels = seq.to(device), labels.to(device)\n",
    "            stats = np.array(train_stat.iloc[:,1:])\n",
    "            stats = torch.tensor(stats[idx]).float()\n",
    "            #Obtaining the logits from the model\n",
    "            logits = net(seq, mask, seg, stats)\n",
    "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
    "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
    "            count += 1\n",
    "\n",
    "    return mean_acc / count, mean_loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "f9666cce-201a-4823-ba27-db02fc97e329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 of epoch 0 complete. \n",
      " Loss: 0.6846710443496704; Accuracy: 0.625; Time taken (s): 42.114266872406006\n",
      "Iteration 10 of epoch 0 complete. \n",
      " Loss: 0.5652367472648621; Accuracy: 0.84375; Time taken (s): 450.7055449485779\n",
      "Iteration 20 of epoch 0 complete. \n",
      " Loss: 0.5372864603996277; Accuracy: 0.796875; Time taken (s): 420.6772892475128\n",
      "Development Accuracy: 0.7996528148651123; Development Loss: 0.5109295083416833\n",
      "Iteration 0 of epoch 1 complete. \n",
      " Loss: 0.5704385638237; Accuracy: 0.78125; Time taken (s): 304.4014186859131\n",
      "Iteration 10 of epoch 1 complete. \n",
      " Loss: 0.5232481956481934; Accuracy: 0.8125; Time taken (s): 424.1839075088501\n",
      "Iteration 20 of epoch 1 complete. \n",
      " Loss: 0.4466317892074585; Accuracy: 0.84375; Time taken (s): 407.72596192359924\n",
      "Development Accuracy: 0.7902777791023254; Development Loss: 0.4797263675265842\n",
      "Iteration 0 of epoch 2 complete. \n",
      " Loss: 0.48549237847328186; Accuracy: 0.78125; Time taken (s): 295.2558825016022\n",
      "Iteration 10 of epoch 2 complete. \n",
      " Loss: 0.47437116503715515; Accuracy: 0.765625; Time taken (s): 406.63692474365234\n",
      "Iteration 20 of epoch 2 complete. \n",
      " Loss: 0.5212807655334473; Accuracy: 0.734375; Time taken (s): 405.4704599380493\n",
      "Development Accuracy: 0.8090277910232544; Development Loss: 0.4209851854377323\n",
      "Iteration 0 of epoch 3 complete. \n",
      " Loss: 0.4679873287677765; Accuracy: 0.8125; Time taken (s): 299.49551796913147\n",
      "Iteration 10 of epoch 3 complete. \n",
      " Loss: 0.4659115672111511; Accuracy: 0.796875; Time taken (s): 416.35002541542053\n",
      "Iteration 20 of epoch 3 complete. \n",
      " Loss: 0.35029760003089905; Accuracy: 0.90625; Time taken (s): 414.5488133430481\n",
      "Development Accuracy: 0.8506944179534912; Development Loss: 0.39020565152168274\n",
      "Iteration 0 of epoch 4 complete. \n",
      " Loss: 0.4017079472541809; Accuracy: 0.875; Time taken (s): 297.816810131073\n",
      "Iteration 10 of epoch 4 complete. \n",
      " Loss: 0.27959227561950684; Accuracy: 0.953125; Time taken (s): 406.02892899513245\n",
      "Iteration 20 of epoch 4 complete. \n",
      " Loss: 0.2678160071372986; Accuracy: 0.96875; Time taken (s): 405.0453338623047\n",
      "Development Accuracy: 0.8975694179534912; Development Loss: 0.3053840630584293\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "best_acc = 0\n",
    "st = time.time()\n",
    "eps = []\n",
    "t_loss = []\n",
    "d_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeadff2-f94c-405b-a565-edc35d3313c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 of epoch 0 complete. \n",
      " Loss: 0.24491186439990997; Accuracy: 0.953125; Time taken (s): 19487.78353357315\n",
      "Iteration 10 of epoch 0 complete. \n",
      " Loss: 0.27128463983535767; Accuracy: 0.9375; Time taken (s): 417.8377842903137\n"
     ]
    }
   ],
   "source": [
    "for ep in range(5):\n",
    "    eps.append(ep)\n",
    "    net.train()\n",
    "    for it, (seq, mask, seg, labels,idx) in enumerate(train_loader):\n",
    "        \n",
    "        #Clear gradients\n",
    "        opti.zero_grad()\n",
    "        #Converting these to cuda tensors\n",
    "        # seq, mask, seg, labels = seq.to(device), mask.to(device), seg.to(device), labels.to(device)\n",
    "        \n",
    "        stats = np.array(train_stat.iloc[:,1:])\n",
    "        stats = torch.tensor(stats[idx]).float()\n",
    "        #Obtaining the logits from the model\n",
    "        logits = net(seq, mask, seg, stats)\n",
    "        \n",
    "        #Computing loss\n",
    "        loss = criterion(logits.squeeze(), labels.float())\n",
    "\n",
    "        #Backpropagating the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #Optimization step\n",
    "        opti.step()\n",
    "\n",
    "        if it % 10 == 0:\n",
    "\n",
    "            acc = get_accuracy_from_logits(logits, labels)\n",
    "            print(\"Iteration {} of epoch {} complete. \\n Loss: {}; Accuracy: {}; Time taken (s): {}\".format(it, ep, loss.item(), acc, (time.time()-st)))\n",
    "            st = time.time()\n",
    "\n",
    "        \n",
    "    dev_acc, dev_loss = evaluate(net, criterion, dev_loader, device)\n",
    "    t_loss.append(loss.item())\n",
    "    d_loss.append(dev_loss)\n",
    "    print(\"Development Accuracy: {}; Development Loss: {}\".format(dev_acc, dev_loss))\n",
    "    if dev_acc > best_acc:\n",
    "        # print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, dev_acc))\n",
    "        best_acc = dev_acc\n",
    "        torch.save(net.state_dict(), 'bertcls_{}.dat'.format(ep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d42f5e29-511c-4030-bf45-bfd9c1e46033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_tokens[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e460c87-f926-4d28-bef7-93dc439938af",
   "metadata": {},
   "source": [
    "### Create Train and Dev Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "feecfa1f-4cfe-498b-acdd-7ea02a534380",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_dev = []\n",
    "for i in range(train_stat.shape[0]):\n",
    "    X_train.append(list(train_tokens[i].reshape(-1)))\n",
    "    for j in range(1,train_stat.shape[1]):\n",
    "        X_train[i].append(train_stat.iloc[i,j])\n",
    "\n",
    "for i in range(dev_stat.shape[0]):\n",
    "    X_dev.append(list(dev_tokens[i].reshape(-1)))\n",
    "    for j in range(1,dev_stat.shape[1]):\n",
    "        X_dev[i].append(dev_stat.iloc[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4450b35a-db76-45dc-8139-435a7f25e6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1542"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "442b807a-76ac-4cb9-b6a1-f3c0fed6ad63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "791"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3382aaff-cdec-4aa9-9f64-4ae2cafae6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_tweet['label']\n",
    "y_dev = dev_tweet['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e435d-c046-4abf-bc48-8363c3aa35ec",
   "metadata": {},
   "source": [
    "### Test on simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e804cab2-226c-4c48-b725-5940eba222d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1e0a2bed-a9c8-4176-a6e9-dff543d9272b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.867816091954023"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(predictions, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7a2b01c3-66e6-45f3-bf3e-a0f6259d66fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.943579766536965"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = lr.predict(X_train)\n",
    "accuracy_score(train_preds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "030b153a-0955-4dbc-9a82-38a0ca5f640b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6609195402298851"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "accuracy_score(gnb.predict(X_dev), y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9bdb3ba2-1573-4a79-94d2-371ccedffd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('X_train.pkl', 'wb') as file:\n",
    "    pickle.dump(X_train, file)\n",
    "with open('X_dev.pkl', 'wb') as file:\n",
    "    pickle.dump(X_dev, file)\n",
    "with open('y_train.pkl', 'wb') as file:\n",
    "    pickle.dump(list(y_train), file)\n",
    "with open('y_dev.pkl', 'wb') as file:\n",
    "    pickle.dump(list(y_dev), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4d72b566-f8d7-4da6-8933-78a1bdd0ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mlp, self).__init__()\n",
    "        self.ffnn = nn.Sequential(nn.Linear(791,128),\n",
    "                                  nn.ReLU(),\n",
    "                                  # nn.Dropout(0.3),\n",
    "                                 nn.Linear(128,64),\n",
    "                                  nn.ReLU(),\n",
    "                                  # nn.Dropout(0.3),\n",
    "                                  nn.Linear(64,1),\n",
    "                                  nn.Sigmoid()\n",
    "                                 )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.ffnn(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ef89ef1c-17d2-416b-974e-71a914a25c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b334580150>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d50aff54-ec06-4038-8187-b2d2dc4e6033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "EPOCH = 5\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8d055d7b-773e-4d50-b92e-0155c0a54037",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_dev = np.array(X_dev)\n",
    "y_train = np.array(y_train)\n",
    "y_dev = np.array(y_dev)\n",
    "X = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "y = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "dev_X = torch.from_numpy(X_dev).type(torch.FloatTensor)\n",
    "dev_y = torch.from_numpy(y_dev).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "70a0b495-7d5c-40b5-bffb-76c7aaa151b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1542"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e33cc3f4-b096-4594-974b-ee9995d5c9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "296dc716-edd7-4ce6-b663-efb7fe28f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TweetDataset(X,y)\n",
    "dev_set = TweetDataset(dev_X, dev_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f355687f-8290-42c9-9dda-f8e72d35acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_loader = Data.DataLoader(dev_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "78c34c8c-9150-4c49-9ba5-e08d0e4d0d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_from_logits(logits, labels):\n",
    "    probs = logits.unsqueeze(-1)\n",
    "    soft_probs = (probs > 0.5).long()\n",
    "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
    "    return acc\n",
    "\n",
    "def evaluate(net, criterion, dataloader, device):\n",
    "    net.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq, labels in dataloader:\n",
    "            seq, labels = seq.to(device), labels.to(device)\n",
    "            logits = net(seq)\n",
    "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
    "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
    "            count += 1\n",
    "\n",
    "    return mean_acc / count, mean_loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7749fc1b-31f6-4621-977f-1b0815999566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net = mlp()\n",
    "net = net.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "opti = optim.Adam(net.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "14e9825f-acd4-417d-8e84-57894369eed6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 of epoch 0 complete. \n",
      " Loss: 0.02590068057179451; Accuracy: 1.0; Time taken (s): 0.004000186920166016\n",
      "Development Accuracy: 0.8802083134651184; Development Loss: 0.434159043762419\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "best_acc = 0\n",
    "st = time.time()\n",
    "eps = []\n",
    "t_loss = []\n",
    "d_loss = []\n",
    "for ep in range(1):\n",
    "    eps.append(ep)\n",
    "    net.train()\n",
    "    for it, (seq, labels) in enumerate(train_loader):\n",
    "        \n",
    "        #Clear gradients\n",
    "        opti.zero_grad()\n",
    "        #Converting these to cuda tensors\n",
    "        seq, labels = seq.to(device), labels.to(device)\n",
    "\n",
    "        #Obtaining the logits from the model\n",
    "        logits = net(seq)\n",
    "        \n",
    "        #Computing loss\n",
    "        loss = criterion(logits.squeeze(), labels.float())\n",
    "\n",
    "        #Backpropagating the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #Optimization step\n",
    "        opti.step()\n",
    "\n",
    "        if it % 100 == 0:\n",
    "\n",
    "            acc = get_accuracy_from_logits(logits, labels)\n",
    "            print(\"Iteration {} of epoch {} complete. \\n Loss: {}; Accuracy: {}; Time taken (s): {}\".format(it, ep, loss.item(), acc, (time.time()-st)))\n",
    "            st = time.time()\n",
    "\n",
    "        \n",
    "    dev_acc, dev_loss = evaluate(net, criterion, dev_loader, device)\n",
    "    t_loss.append(loss.item())\n",
    "    d_loss.append(dev_loss)\n",
    "    print(\"Development Accuracy: {}; Development Loss: {}\".format(dev_acc, dev_loss))\n",
    "    if dev_acc > best_acc:\n",
    "        # print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, dev_acc))\n",
    "        best_acc = dev_acc\n",
    "        # torch.save(net.state_dict(), 'sstcls_{}.dat'.format(ep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "289e761b-9b28-4e76-a02c-31eabbc776a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABGUUlEQVR4nO2deXgb1bn/P0eSJVvybslO4iW2syeQkJCEfQlr2EJJC2UpaymUwr1tgd5Lf72l26W9lJbShdJSSqHQQtlJW2jY15KQsGQFsthxYjuJbXm3ZdmSzu+P0diKbdmyPFosn8/z6LGsOZo5Ho++euc97yKklCgUCoVi4mNK9AQUCoVCYQxK0BUKhSJFUIKuUCgUKYISdIVCoUgRlKArFApFimBJ1IGdTqcsLy9P1OEVCoViQvLBBx80SSldw21LmKCXl5ezcePGRB1eoVAoJiRCiJpw25TLRaFQKFIEJegKhUKRIihBVygUihRBCbpCoVCkCErQFQqFIkVQgq5QKBQpghJ0hUKhSBGUoE8yurw+nvqgFlU2WaFIPZSgTzL+sbmeW5/cxO7GzkRPRaFQGIwS9EnGgTYvAAfbvQmeiUKhMBol6JOMho4eABo7lKArFKmGEvRJhm6Z68KuUChSByXok4xGZaErFCmLEvRJRkNQyJWgKxSphxL0SUQgIPuFvEEJukKRcihBn0S0dPfiC2jx58pCVyhSDyXokwjdKi9wWGnsVIKuUKQaStAnEbqgLyjOobW7D6/Pn+AZKRQKI1GCPoloaNciXBZMywagqbM3kdNRKBQGowR9EtFvoQcFXfnRFYrUQgn6JKKhvYcsm4Xp+Y7+3xUKReqgBH0S0dDhxZVtw5VlA1ALowpFiqEEfRLR0OGlMMtGQaYVIZTLRaFINZSgTyIaOnoozEonzWwi325VyUUKRYqhBH2SIKWkod1LUbbmbnFl2ZSFrlCkGErQJwntPT68vgCFWemAEnSFIhVRgj5J0KssFioLXaFIWZSgTxL0Ouh6hIsu6Kq3qEKROihBnyToDS36XS6ZNnr9Ado8fYmclkKhMBAl6JOEhqCFrrtcCrM1YVduF4UidVCCPklo6PCSnmYiy2YBNAsdlKArFKmEEvRJgpZUlI4QAhiw1FUsukKROihBnyQ0tPf0x6DDwOKostAVitRBCfokoTFooetk2SzYLCZVz0WhSCGUoE8SGjq8/VY5gBCCwmybqrioUKQQStAnAV1eH51eX7/fXMeVaVMWukKRQihBnwToC5+hLhdQ2aIKRaoRkaALIVYKIT4TQuwSQtw2zPYyIcTrQoiPhBCbhRBnGz9VRbTobpXCrEMt9MKsdBXlolCkEKMKuhDCDNwLnAXMBy4RQswfNOx/gCeklIuBi4HfGj1RRfT0W+iDXS5ZNtUsWqFIISKx0JcDu6SUVVLKXuBx4PxBYySQHXyeA9QbN0XFeBnJ5QLgVs2iFYqUIBJBLwb2hfxeG3wtlO8DXxJC1AIvAP8x3I6EENcJITYKITY2NjZGMV1FNDR09JBmFuTZ0w55XXfBKLeLQpEaGLUoegnwkJSyBDgbeEQIMWTfUsr7pZRLpZRLXS6XQYdWjEZj+6FZojoquUihSC0iEfQ6oDTk95Lga6F8GXgCQEr5HpAOOI2YoGL8DI5B11GCrlCkFpEI+gZglhCiQghhRVv0XDNozF7gVAAhxDw0QVc+lSRB6yU6VNCdmbb+7QqFYuIzqqBLKX3ATcBa4BO0aJZtQogfCiFWBYfdAnxFCLEJeAy4SqrOCUnDwXbvkAgXQGsW7bAqC12hSBEskQySUr6AttgZ+trtIc+3A8cZOzWFEfT0+Wnz9A2JcNFxZarkIoUiVVCZoilOY3/I4lALHbTYdBXlolCkBkrQUxxdrIuylYWuUKQ6StBTnMbggudwUS76642dqlm0QpEKKEFPccKl/eu4smz0+gK0e3zxnJZCoYgBStBTnIZ2LyYBBY7wgg7Q2KlCFxWKiY4S9BSnoaMHZ6YNs0kMu92l0v8VipRBCXqKEy4GXUcPZ1QLowrFxEcJeorTMKiX6GBU+r9CkTooQU9xGsOk/etkp1uwWkxK0BWKFEAJegrj8wdwd/VSGCYGHYLNorNUcpFCkQooQU9hmjp7kTJ8lqiO6i2qUKQGStBTGL2K4qiCrrJFFYqUQAl6CtPQricVhXe5aNttqoSuQpECKEGPMx/UNHPVn96npy/2jZkbRinMpePKTKelu49eXyDmcwJo6lR3AwpFLFCCHkeklHxvzTbe+KyRXQ2dMT/ewXbN6tYbWYSjv1l0V+yF9p2dTRz141epcXfF/FgKxWRDCXocWbvtIFvr2gHYEwdBa+jwku+wYrWM/G/ubxbdHntB31LXhj8g2V7fHvNjKRSTDSXoccIfkNz98mdML7ADsKcp9oI+Wgy6TjyTi/Y2a393VRz+foVisqEEPU78Y3M9Ow52cusZcyjKtlHd1B3zYzZ0eEddEIXQAl2xF/Qat/Z3VzUqQVdER2t3ryr3HAYl6HHA5w9wzys7mTsli3MOn0p5gSM+Lpd2b0QWen+z6Di4XHRBr26K/RqCIvXY3+Zh2R2v8OYO1YN+OJSgx4FnPqyjuqmLW86Yg8kkKC9wxHxRMBCQNHVGJuhWi4k8e1rMS+h6fX7q2zwAVCuXiyIKdjV00ueXbFNrMMOiBD3GeH1+fvnqThaV5HDavEIAyp0Omjp76ejpi9lxm7t78QVkRIIOmtsl1hZ6bYsHKWH+1Gxauvto6eqN6fEUqUd9q2YQ7HXH3mU5EVGCHmOe2LCPulYPt5wxByG0muQVTn1hNHYXZaRJRTqFWekx96HrH8IVc12AWhhVjJ26lqCgNytBHw4l6DGkp8/Pr1/bxfLyfE6Y5ex/vdzpAKA6hm6XgxGm/evEo56Lvm5w8hztTkW5XRRjpbZVCfpIKEGPIY+8V0NDh5dbzpjdb50DTM/XBL0mhoLWqFvoI9RCD8UVrLgYy+iBGnc3DquZI0pzsZgEVY1qYVQxNnSXy/42T9wymycSStBjRKfXx31v7uaEWU6Oqiw4ZFuG1cyU7PSYWuj9hblG6FYUSqHeLLonds2i9zZ3U1bgIM1soizfrix0xZipa/WQZhYE5IC4KwZQgh4jHnq3muauXm45Y86w28ud9pgmFzV0eMlOt5CeZo5ofDySi/a4u5ier60fVLocKhZdMSb8AcmBth4WleQCyu0yHErQY0Bbdx+/f6uK0+YVcURp7rBjKpwO9sRwpb6hPbKkIh2XHoseo6qL/oCkttnD9OCCcIXTQbW7i0BAJYgoIqOxw0ufX3J08I5XCfpQlKDHgAfeqaKjx8fNp88OO6a8wEFzVy9tntiELjZEmPavo7tmYmWhH2jvodcf6F8/qHRl0usL9MelKxSjUdeqCfiS6blYzSb2KUEfghJ0g3F3ennwnWrOWTiV+dOyw46bXhBcGI2RH11rDh25oLsyNWs+VoKuLwDrtWwqgpE+yu2iiJS6Vu3usSTPTkl+hrLQh0EJusH87s3dePr8fPO08NY5DAhaLBYGpZQR13HRyc6IbbPomuCHTxf0yhj+/YrURI9BL87NoCzfrgR9GJSgG8jB9h7+/F4NFywuYWZh5ohjB6ouGn9Rtnm0ZhVjsdCFEDFtRVfj7ibNLJiakwFoi7CZNosSdEXE1Ld6yLWn4bBZlKCHQQm6gdz7+i78AcnXT5016tj0NDPTctJj4nLROxW5xiDo+vhYZYvube6iNM+O2aTF4wshqHA62K1i0RURUtfqYVrQICjLt9PR46OtO3blMyYiStANoralm8fe38tFy0opC1rfozG9wBGTWPSGMSYV6cSynsuepu4h56XC6VAWuiJi6ls9FOdpgl4aDH9VVvqhTEhBT8ZQt1+/ugshBP9xysyI31PudMQkFl0PPSyKMKlIpzBGFrqUkr3N3ZQHF4J1Kl0O6lo9cemvqpj41LV4KM4dsNBBCfpgIhJ0IcRKIcRnQohdQojbwoy5SAixXQixTQjxV2OnOcAzH9Zyzq/fSSoRqG7q4qkPa7nsqLJ+H3EkVDjttHT3GX7b2N8cegyLoqBZ6M1dvfT5jU2pbu7qpdPr6/8Q6lQ4HUg5UCNdoQhHm6ePDq+vX9CVhT48owq6EMIM3AucBcwHLhFCzB80ZhbwbeA4KeUC4BvGT1VjSk46n+xv53dv7o7VIcbMPa/swGo28bWTI7fOgX6L1Wi3S0O7F7vVTKbNMqb36T73JoOtdD2Bavogl0ulU1s4Vs0uFKOhp/lPCwp6ps1CvsOqBH0QkVjoy4FdUsoqKWUv8Dhw/qAxXwHulVK2AEgpG4yd5gDHznBy7sKp3PfG7qRILPjsQAdrNtVz1XHlY16E1EMXjV4YHWtSkY7uczc60kXvIzp9kMulwhWMRVd+dMUo9Ics5g3cAZfm25NCA5KJSAS9GNgX8ntt8LVQZgOzhRDvCiHWCSFWDrcjIcR1QoiNQoiNjY3Rt5D6zjnzMJsEP/j79qj3YRS/eHkHmVYL159YOeb3lubbEcL4WGwtqWhs7haIXT2XGnc3QkBp/qHuqEybhcIsm0ouUoyKnlGsu1wAFbo4DEYtilqAWcDJwCXAH4QQuYMHSSnvl1IulVIudblcUR9sak4G/3nqLF755CCvfxqzm4FR2VLbxr+2HeDLJ1SQa7eO+f1a6GKG4QujjR1eXGNcEIUBQW+IgaBPzU7HZhlaKExFuigioa7Fg9ViosAx8Dkry8+grtWDz+A1n4lMJIJeB5SG/F4SfC2UWmCNlLJPSlkN7EAT+JhxzXEVzHA5+P7ftyVsgfTulz8j157GNcdXRL2PcqedaoMXBQ+2R+dycWZqHxbjLfSuIe4WnUpXpqqLrhiV2lYtwsVkGugrUJZvxx+Q7G+LbS/ciUQkgr4BmCWEqBBCWIGLgTWDxjyHZp0jhHCiuWCqjJvmUKwWEz9YdRg17m7+8FZMDzUsH9Q08/pnjVx/4gyy09Oi3o/RDaM7vT66e/0UjTHCBcBmMZNrT4uBD717yIKoTqXTofqLKkalvtXDtNxDr2kV6TKUUQVdSukDbgLWAp8AT0gptwkhfiiEWBUcthZwCyG2A68D35JSumM1aZ3jZzk5+/Ap3PvGLmpb4vtP/dnaHTgzbVx57PRx7ae8wEFrdx+t3cYIWkP72FrPDcaVaTO0hG6n10dTZ2/YZKuKOLTjU0x8QmPQdVQs+lAi8qFLKV+QUs6WUs6QUt4RfO12KeWa4HMppbxZSjlfSnm4lPLxWE46lP85Zz4CwY/+Eb8F0n/vauK9Kjc3rpiB3Tq20MDBlBtcpKo/Bj2KRVHQyugaaaHrdx962dzBVLpU1UXFyHh9fho6vBTnHmoUTM3JwGISStBDmJCZoqFMy83gplNmsnbbQd7cEX3kTKRIKfnZS58xNSedS5aXjXt/FcGGD3sMslAHkoqit9CNzBbdGyYGXac0X6vvomLRFeE4EPSRD3a5mE2CkjxVRjeUCS/oANeeUEGF08H312zD64vtAunfN+/nw72t/McpsyJu7zYSeuiiUVUXx+1yCdZzMapZ9OCyuYNR/UUVozFcDLqOikU/lJQQdJvFzPdXLaC6qYsH3q6O2XHe2tHIrU9s4ojSXC5cWmLIPm2WYOiiQRZ6Y4cXq8VETkZ0C7WFWel4fQE6vMY0i65xd5HvsJI1wsJxpVP1F1WEp651aAy6jopFP5SUEHSAk2a7OHNBEb95bVf/BWAk71c3c90jG5lRmMnDVy8nzWzcqaswsEhXQ4cXV6YNIcTog4fB6OSiGnf4CBcdPRY9GYuuKRJPXasHIRi2TlJZvp3W7j7ae1QZXUghQQf47rnzkUju+KexC6Sb9rVyzUMbKM7N4JEvLyfHHn2Y4nCUOzWXgxFujoPtPVH7zyEkucigMro17m6m548s6JWuTLy+APvbVTyxYij1rR4Ks2xYLUPlSo90UW4XjZQS9JI8OzeePJMXthzgnZ1Nhuzzk/3tXPHg++Q50vjLtUfjzIxeLMNRXuCgvcdHqwFVFxs6vBRFGeECA753IxZGvT4/9W0eysIkFekM9BdVC6OKodS1evqLcg2mVAn6IaSUoAN85cRKphfYuX3NVnp940sJrmrs5PI/ricjzcxfrz2aKTnRC+VIGBmL3WCQhW6Ey6W2xYOUUD6Ky0UPXVQLo4rhqG/tGdZ/DvTnNyg/ukbKCXp6mpnvn7eAqsYuHnw3+gXSfc3dXPbAegD+8pWj+i2BWKCnxY/Xj97T56e9xxd1hAtATkYaVrPJkOSi0UIWdQqzbDisZrUwqhhCICCpax2aVKSTnZ5Grj1NCXqQlBN0gBVzCzltXhG/enUn+9vGvkB6sL2Hyx5YT5fXx5+vOYoZrpEbPo+Xsnw7JjF+QW8cZ1IRBJtFZxmTXKQnFZWFSSoKPWaFy6HK6CqG0NTlpdcXGDZkUac0z87eZuMDISYiKSnoAN87bz7+gOSOf34ypve5O71c9sB63J1eHr5mOfOnZcdohgNYLSaK8zLGXaRLt6qjqbQYitMgQd/j7sZhNfcX/RqJCmemSi5SDKG+NZhUNEInsDIVi95Pygp6ab6dG06ewT827+ffuyNbIG3z9HH5H99nX3M3f7xqGYvL8mI8ywGMKNI10Bx6fILuyjRG0Pc2d1NW4IgohLLS6aC2RfUXVRzKSElFOqX5dmpbuvGrsNfUFXSAr540g9L8DL73/LZR+2R2eX1c9af32dnQwe8vP5KjKwviNEuN8gLHuEMXx1vHRceoei417q5RQxZ1Kl1af1HlC1WEoreeG0nQy/Lt9PklB1TYa2oLenqame+du4CdDZ089O6esON6+vxc+/BGNte28etLlnDynML4TTJIudNBR4+P5nGUkT3Y3oPZJA5pAhANrkwb7nE2i/YHJPuaPaMuiOoMhC4qP7pigLpWD1k2y4glqvurLqpm46kt6ACnzS/ilLmF3PPKDg4O8w3e6wtww6MfsK7azc8uXMjKw6YkYJbGFOnSs0RDmwBEgx666O6M/svlQHsPvf5A2MYWg+kXdOVHV4RQ2+IZ0ToHlVwUSsoLOmgLpH0ByY9fOHSB1OcP8I2/fcTrnzVyx+cO54LFxtRniYby/tDF6C/Khg7vuGLQdQoNiEXvL5sboYWelZ6GK8tGtbLQFSHUj5BUpDM1Nx2zKqMLTBJBn17g4KsnVvL8x/W8t1vruxEISP7r6c28sOUA/3POPC49avylcMdDSV4wdHE8FnqUrecGM9BbNHqfZE3w9rdsDPH7qr+oYjAjxaDrpJlNTMtNV4LOJBF0gBtOnklxbgbfW7OVPn+A29ds5ZkP67j59Nlce0JloqeH1WKiJG98ZWQbO7y4xrkgCsZki9a4u0kzi1Gtq1BmqFh0RQidXh9tnr5RXS6gqi7qTBpBz7Cauf28+ew42Mnq3/6bR9ft5fqTKvmPU2Ymemr9lDsdUVvoff4A7q5eQy308Qj63uYuSvO05hWRUuF00NzVa1g7PsXERo9wicQoULHoGpNG0AHOmF/ESbNdbKlr4/Kjp3PbyrlRl5mNBRUFdmqauqMKXWzqHF+nolBsFjM5GWn9YZDRUOPuDttHNBwVTi0jV7ldFBASgx6BoJfm23F39dJlUB3/icqkEnQhBD+/aBF3X7SIH6xakFRiDsHQRa8PdxShiwNJRcYUEBtP+r+Ukhp3d/9Cb6So/qKKUEZqbDGY/kiXODeLTzYmpqAHos8mdGbaWL2kZNyhfbGgfBxFug6Os/XcYAqzou8t2tzVS6fXN6YFUaDfRaMsdAVogp5mFhFd0yoWXWPiCfqn/4QHToX2+kTPxHDKndGXkdXdI0XZxlno0Ua5jNZHNBxWi4nSvAwl6ApA86FPyUmPyPjqF/RJ7kefeIJuSoOmnfCHU6D+40TPxlBK8jIwm0R/yN9YaOjwIgQRFcKKBL2eSzT+/LHGoIdS6cpkt2p0oUDzoUfibgGt7HNWumXSL4xOPEGffQZcsxaEGf50lmaxpwhp5qCFGkWkS2NHDwUOKxaDep0WZtvo6QvQGcUiU427GyG02PqxUhGM9FH9RRX1rR6KcyO7hoQQKnSRiSjoAFMOg6+8Cq658Phl8O6vwIB+nMnA9ILoGkY3tBsTg64zkFw0dj/6Xnc3U7PTSU8zj/m9lS4HPX2qv+hkp88f4EB7D8W5kV/TStAnqqADZE2Bq/4J81fBy9+Fv/8n+CdI5+8RvnwqnJqgj9XV0dDhNWxBFMCVqX2Qool0qWkee8iiTn87PhXpMqk50NZDQI5cZXEwpfl29rV4JvXd3cQVdACrHb7wEJxwK3z4Z3h0NXhaEj2r4ZESqt+Cv1wId82A2o3DDisvsNPV6x9zhElDhzFp/zp6PHtUgu7uGnPIok5lfyy68qNPZsaSVKRTmm+n1xcYV/7ERGdiCzqAyQSnfhc+9zuoeQ8eOA3cuxM9qwH8PtjyFNx/Ejx8HtR/BJYMePTzcHDbkOF6pMtYFkb9AUlTZ68hSUU6rszoXC6dXh9Nnb1RW+hF2TbsVjO7lYU+qRlLDLqOinRJBUHXOeISuHINdDdrYY173k3sfLwd8N5v4VeL4ekvQ283nPdL+MZWuPqfkGaHP39uyJePbtmOJXTP3eXFH5CGJRUB5NrTSDOLMVvo/Y2hR+kjGg4hhCrSpYjKQleCnkqCDjD9WLj2FbA74c/nw8d/jf8c2vfDK9+HXyyAtd+GnBK45HG48X048ipIS4e8crjieZB+bZ6t+/rfXpKXgcUkxrQwqmeJFhlooQshompFN56QRR0l6Iq6Vg/OTOuYFtaLczMQQgl6alEwA659GaYfA8/dAK/8AALRd96JmIZP4LmvwT2Hw7u/hMoVcO2rcM2LMOcszTUUims2XP4s9LTDI5+DzgYALGYTpfn2MRXp0kXXyCgXbX9jTy6KNqkolEpXJrUt3Xh9qr/oZKV2DDHoOlaLiWk5GZM6Fj31BB0gIw++9AwsuRLeuRueukpzeRiNlFD1Jjz6Bfjt0bDtWVh6NfzHh3DRw1CydOT3T10Elz2hZb0+ckH/gm55gX1MjS500TVyURS0L4ixW+jd5DusZI3QMmw0Kp0OAlKlcU9mImlsMRyl+RnKQk9JzGmaz/qMO2D7GnjoHOg4YMy+/X0DC51/XgX7P4ZT/ge+uQ3OvgvyKyLfV9nRcPFfoGmH9sXg7egvoxtp6KLucnEZLui2/iqOkVLj7hpzDZfBDLSjU26XyYiUMqLGFsMx2WPRLYmeQEwRAo69CfIr4elr4Q+nwqWPw5TDR35fwA9dTdB5QHOFdByAzoMDj9oPoL0WnLPhvF/Bwi9qvvFomXEKfOFP8MQV8PilVFb+jO5eP40dXgojqM3S0OElJyMtqkSekXBlac2iff5AxBmoNe5ulpXnjeu4Farq4qSmpbuPnr5AVBZ6Wb6dxg4vnl4/GVZjPw8TgYgEXQixEvglYAYekFL+X5hxnweeApZJKYcPtE4Ec8/WfNl/vRgeXAln3QlWR4hYNwTF+yB0HITuJpDD+N1tOZBZCEXz4Zyfwawzh/rGo2XeufC5++DZ6zir9zZ+wFVUN3VFKOjGxqDrFGbZkBLcXb0RFf3q9QXY3+ahrGB8vVmz09NwZtpULHoYOnr6xuXSSnb666CPIalIpzSkjO7soixD5zURGFXQhRBm4F7gdKAW2CCEWCOl3D5oXBbwdWB9LCY6bqYugq+8Bo9dDM/fOPC6yQKOQk2os4th2mLILBp4ZE3RtmUWQdrYL7AxseiL0NuB85+38PO0HvY2LeKoyoJR32ZUc+jBhHYuikTQa1u6CUiYPk6XC2h+dBXpMpStdW2s+s07/PGqZayYU5jo6cSEulbNZRKtywVgX7MS9HAsB3ZJKasAhBCPA+cD2weN+xFwJ/AtQ2doJNlT4Zp/Qd0H2sJpZhFk5BtnZRvBsmvx93Rw/qvf5+ONt8OyhzXX0Qg0tHtZXpFv+FQObRadM+p4PRmq3GmAoLscvLz94Lj3k2q8uaORgIR7XtnJybNdSdekxQjqWrVF/vEI+mT1o0eiZMXAvpDfa4Ov9SOEWAKUSilHLH0ohLhOCLFRCLGxsbFxzJM1hLQMKD8eihaAw5lcYh7EfMI3eTTtCxzR8Dy89D8j1n6RUgZ97bFxuUDk6f96DHpZlElFoVQ4Hbi7emnrniD1eeLEuio3JgGb9rXyzq6mRE8nJtS1eLBbzeTax+5WyndYcVjNStCjRQhhAu4GbhltrJTyfinlUinlUpfLNd5DpzSvTbue563nwnu/gbfuCjuutbuPXn/A0CxRHWfmGAW9uRu71WxITfaBSBflR9fp8wf4oKaFLy4rZUp2Or95bVeipxQT9JDFaO4+hBBakS4l6GGpA0pDfi8JvqaTBRwGvCGE2AMcDawRQowShK0YiXJnJt/2XIZcdAm8fgesu2/YcXqtlVgsiqanmclOt0Rcz6XG3c30AochboBKl2oYPZgtdW109/o5YZaL606sZH11Mxv2NCd6WoYTbciizmQOXYxE0DcAs4QQFUIIK3AxsEbfKKVsk1I6pZTlUspyYB2wKqmiXCYgFU473X2ShhU/g3mr4F+3wYePDBkXq6QincLsyJOLatxdhiyIgvahNAkl6KGsq3IDsLwin0uWl1HgsKaklV7f6okqwkVHF/Roum1NdEYVdCmlD7gJWAt8AjwhpdwmhPihEGJVrCc4WZmuF+lq9sLnH4AZp2o137c+c8g4PakokvDGaIi0nos/INnX7BlXyn8oVotWAkHFog+wvqqZWYWZODNtZFjNXHN8BW/uaGRLbVuip2YYnl4/7q7ecVnopfl2evoCUTc5n8hE5EOXUr4gpZwtpZwhpbwj+NrtUso1w4w9WVnn40f3Ie9p6gKLDb74KJQeDc98BXa81D8uli4X0Ou5jP7BONDeQ68/EHXZ3OGodDpUtmgQnz/Axj3NHFU5EM10xTHTyU638JvXdyZwZsYSTdncwYSGLk42ki/EQwFoZUOtZtNAf1GrXctyLToMHr8Unv0q1H9EQ0cPDqsZhy02Sb+FWZE1i9YjXKJtbDEcFc5M9jSp/qIAW+vb6er1c3RIXkJWehpXHVvO2m0H2XGwI4GzM45oyuYOpnQShy4qQU9SzCZBaX4GNaFFutJztAqNS6+GT/4O95/Ml7Z9hS9mbIhZ+z1Xlg1Pn5+u3pErH+qFtMZbxyWUSpcDT5+fA6q/KOtD/OehXH1cBXarmXtfTw1fer+FPg4feknwvXvdHkPmNJFQgp7EVASLdB2CPV8rAHbzJ7Dy/3D0NXO792da2d637tJq0BhIf3LRKKJa09xNmlmMy7IaTKVz7M0+UpV1VW4qXY4h4al5DitfOno6f99UH1Vz8WSjvtWD2SQoGocLMT3NzJTsdGWhK5KL6QWaoA/rckjPhqNv4GLbvfyu+CdQOA9e+1+4e75Wl33/JkPmoAvIaAujNe4uSvPsmE0jhCz6euH9P2ilgt+8Cxp3jLjP/iJdKSBU40Hzn7cc4m4J5doTKrCYTdz3RhK1XoySuhYPU7LTIy4GF46ySRqLrgQ9iSl3OujpC3AwTJMJKSUHO/ponHqy5oq58X1Ycjlsew5+f6JWiGzbs+Nyx/TXcxklYqDG3R1+QdTvg4/+Ar85El64Fdy74PX/hXuXwb1Hwxv/pzUIGeSnn5KdTkaamarGyZ1ctH1/Ox1eH0eFKe9QmJXOxctKeeaj2n4fdNLi82rtIXuH/5KuHWcMuk7pJI1FV4KexFQU6JEuw1+YnV4fnj7/QISLaw6c83O4eTuc+RPo2A9PXgW/XARv/xy63GOew4DLJbygSynZ6+4eGoMeCGhfKPcdA89/Taubc9nT8PXNmsvorJ9qLqQ3/k9rEHLvcu0u48AWkFL1Fw2yvkpLHgpnoQNcf9IMpIT736qK17TGRlsdvPoj7Q7yobO1a/K9e6Hv0C8gLUt0/CG4Zfl2DrT30NM3ubpepXY99AmOXuRqj7uLY2YM/TD3hywOruOSkQvHfA2Ouh52vgzrfwev/hDeuBMWXgjLvqJVn4wgozM3I9gsegQLvbmrlw6vrz92Hilh50vw2o80cXbNhYsegXnnDRwze5o2v6Ou10oWf/p32P689sXz1l2QPwPmn8+JWXN4oSGGVQWl1KzG3i7o7YS+7oHnvd3Dvy4DMP14qDwp9hU4gfXVbiqcjhErXhbnZrB6STGPvb+XG1fMNLzZSVRICTX/hvfv1xbxZQBmr4T558Omx2Dt/4N3fwUn3gpLrsBvsnKgrWdcC6I6ZQXaPmpbPMwszBz3/iYKStCTmKk5WuhiuMWu/qSicHVcTGaYs1J7NHyqfbA2PQYfPQq5ZVo999lnasXKwgiTySRwZtpGtNAP6SNa/ZZmidW+rzXDvuB+OPwL2lzCkVUEy67VHp2N8Ok/NHF/95fcJv1cKl341l6MZcEFULwk/BdRX49Wy76rUbsb6W7SFon7f7q1n57moDiHCHSkmINC+e9fQ5odZp4Kc87RzqPd+IqX/oBkfXUz5y6cOurYG06eyVMf1PLAO1V8+6x5hs8lYnq7YcuT2nrJwS2QnqsZGMuu1a4JgCMugT3vwGt3aG64d+6hY9nXIVBkyMJ6WUhddCXoiqTAbBKUFdjDuhzGlPZfOBfOvRtO/a7mY9/5Enz8F9jwB7BkaNbmrDM0Yco5tEGFK8s2ooW+193NEWIXx7z7W6h9B7Kmwbn3wOIvaa0Ax0KmSwvLXHo1dDfz4UuP0vbBU5Suvw/e+zXklGoi6u8bKta9YXztJgvYC8DuBEcBZB8GtiywZmrx/VZH8LlDE2n9uTX0uQPSHGC2aIu7e96GT/8Jn72oWZ/CDGXHwNxztIYqunCNk0/2t9PR4+OoitHr4lc4HZy7cBqPvlfDDSfNINc+/iJpY6JlD2x4QCtR0dOq5Uyc9ys4/ELtXA6m/Hi4+gWoeh1eu4PcV7/Fa1YX3c23gP8r2rmOktJJmlykBD3JKS9w9NcZH0xjv8tlDD7HjLwBwezr0ayknWthx1rY8S/4J1C4AGafoVnwJcsozLL116gewoGtHP72bTxnexvZ7IQzfwxLvzy+lnw69nxMR17B1etm8MfVMzlVfKBZ7luf0QTZXqCVQM6fof3Uf7c7Q34WaBaikXXDLVbtS2XmqdqaRf1H8NkLmsCv/bb2KFygCfvcc2DqEVEfX6/fEpohOhI3rpjJmk31/OndPXzz9NlRHXNMSKkJ8vr7tetHmDTX2lHXa19wo/3dQmgtGCtXsG7tYzj+fSeHr78Ndj0AJ90Gh60e+e4uDK5MG+lppqGNxgMBrX2kLVvL60ixevJK0JOcCqedt3c2EghITINCAg+292CzmMhOj/LfmJYOs07THmf9VGtUvWOtZr3/+9fwzi8gI4+bbEt5sn0+dC8YcCs07YI3fgxbn2aaKZPfmy/l+q/fBTZjb2/1Egg72y2cetKlcMSlhu5/3AihuYGKl2iNwpurg+L+wsB6QHYxzDkL5pwN5SdoXwjDISX4eqCnHbzt0NNGx7aNXJnTxNRdTdDTpr3u7QB/b/Dh034G+sDvY46/lxdzm/G868Ff7cAc6IOAT7uj8fdqzwN+bZ3F4dK++ByuQc8LB57bsoYXPW8HfPyY5sZz79S+PE+8FY68GnKKh46P4Dx+mL6cn/bewWeX+bG9fSc8cy28/TM4+TaYd/6YehcIIZiZZ0bUfwgfvK+t5RzYAge2Ql/wjjfNoa3l5BRr/6PsacFH8cDPjLwJJfpK0JOc6QUOvL4AB9p7hvgW9dZzhnStEUKLknHNgeP+UxOP3a/BjpeYve1F7gi8jLzr14iS5drFvv15sKTDCbdw/adH0ZuWzfUGizlATkYazkwr1ROlSFd+BRxzo/bocmt3P5/+Ez7+q+aOsGVDxYnaWG/7IeJNT7smzCF8U3/yd/2J0ETWbA0+LNpPU5rm3jKnUZZjYVOXiTpPGmUul+ZyMlv7tyNM4GnRXFUHtmhrDj1hCnyZbUOFXwjYvgZ6O2DaErjg97DgAq3m0Dioa/GQZ7diO/wMWHAebH9Oi4B68iooOhxWfFv7Uhzueu9yw4HNQdHWfq5p34GpPQD1aOd9yuFaWK9rrrZ+0l4P7XXaz6o3tKiwwesploxhhH5asEVloXY+MosMN2SiRQl6khNapGuIoLd7Y9LYAtBuRxdcAAsu4Okp1Ty9Zg1/ObEVx95XtVvr5dfBCTdDZiHb33uFU+caV8NlMBVOx8RsdOEo0O4ojrhUC8+rekMT95p3NaFMz9YEoWCGdr5t2dprtmxIz2Vvt4Wbn6/iq2cu5rTFs7XXrZmjWqoO4HcPvs/2+jbevuEUMqwRuCx83uCicWPw0XTo884G7XnDJ5p1PvdsWH49lBxpyKmCgcYWgPY3HrZai4jZ+jS88ROthtG0xXDCLdpdRr/VvQU66gd2lF0CUw7nbcsxPF2Xzy+/cTkir3x0S9vvg66GAaFvqxsQ/PZ6LWKno167yxlMmj0o7oXBHsWugV7Fh7xeGP6uxwCUoCc55bqgu7s5duah2xo6euLSCNeVlcHHcibVC4/nsLO+p7kGghdkp9dHU6eX6Qb0EQ1HpTOTVz+d4P1F0zKCbpezIn7Lq+9Ws1FamXfEMZAztsiPm1bM5KLfv8fjG/Zy9XEVo7/BYhuwPhNEXatnaHE3kxkWXgQLVsPmx+HNO+FvX9K2CbNmbVecqFnf+iPoFqx6t5o11dv5nnUaBZEIqNkScg7C9OcJ+LUvts6DWkRWV8PAl11ng/Z7yx4tyqurCRgmy9uSrrk4j7wy0lMTMUrQk5yp2enYLKahNV3QXC7Hz3TGfA6uwb1FQz4c+qLTdAP6iIajwuWgaWMvbZ4+cjLG3mdyorKuyk1pfkZUmZPLK/JZXpHP/W9VcelRZdgsY19YjCdSSupaPBwX7no2W7SoqcMv0u50Ml3gmjfi4ntow+iCTIPi8k1myJqiPUYj4NfuejobtC+AUNEvjE1YqRL0JMdkEkwfJnSxp89PR48vZo0tQhmpWfTeZm1eRjW2GI6KkCJdR5Tmxuw4yUQgIHm/uplT5xVFvY+bVszkigff55kP67hkeZmBszOedo+Prl7/6F9eFqsWgRUBoWV0F5fljXeKY8dk1lwsmYVoXTrjcMi4HEUxLqYXOIYkF+mJPvHICOxP/x+mpswevWxuDAV9hksX9AnoR4+SHQ0dtHT3jZjuPxonzHKyqCSH+97Yjc8/huSpBFDbql1HRtRx0SnNm3yx6ErQJwAVTgc1zd2HVF3UxXWkdHCjSE8zk5VuGdZCr3F3k++wkp0eO1dIqd5fdKJEuhiAXr8lXEGuSBBCcOOKmext7ubvm+tHf0MCqQ/mORhZfjnDasaVZZtURbqUoE8Aygsc9PoC7A+pSX6wP+0/PjU7CsNki+5t7jK0qcVw2CxmSvLs7J5ERbrWVbkpzs3odxtEy2nzipg7JYt7X9+d1J2f6lqCFroBdVxCKZtkVReVoE8A+ot0hQjamNL+DcCVNXw9lz1N3TH1n+tUuhyTxkKXUvOfR5odOhImk+BrK2ayq6GTtdsOGDC72FDfpiXJFTiMLVeg1UVP8pLCBqIEfQKgh3JVHyLoXiwmQV6c6nW4stKHWOi9vgD72zwDVRZjiF5GN5mtTKPY1dCJu6uXoyOo3xIJ5xw+lQqng9+8vmvU3rCJoq5Fq4NuSJJcCKX5durbPPT6knsNwSiUoE8Apuihi6GC3u7FlWUbUg4gVujNokOpbekmIBlaBz0GVLoy8fT5wzb7SCX0+i3jWRANxWwS3HDyDLbVt/PGjkZD9mk0ta0ew90toFnoUg70Kk11lKBPAEwmQXmBoz+iBDSXS7zcLaC5XLp7/XR6B7LkDimbG2P6+4tOArfLuupmpuakU5pvnMBdsLiY4twMfvNaclrp9a0epo0xeSoSQmPRJwNK0CcI5U77IclFjR1eXLFK+x8GV+bQWPSaJj0GPT4uFyDlF0allKyvcnN0ZYGh7oc0s4mvnlTJBzUtrAtG0CQLPX1+Gju8MbPQYfKELipBnyCUFzjY6+7GH/Qh64W54oV+rEMEvbkbu9WMMzP2fny9v2iqW+i7G7to6uwdV7hiOC5cWoory8ZvXt9p+L7Hw4E240MWdQqzbFgtJiXoiuSi3Omg1x+gvlVb4Gnu6qUonhb6MMlFe93dlOXbDV/IGg6TSVDudKR8ctFA/XNj/OehpKeZue6ESt7d5WbDnuSx0nX/tpFJRTomk6A0L0O5XBTJhR7pUuPu7o82iaeFPpzLZY+7a2gxpRhS6XRQleIul/XVzRRl2yiP0brEZUeXMTUnne+v2dZ/t5do6lo0QS+JgcsFJlcsuhL0CUJ/PRN3Fw3t8Y1BB8izW7GYRL+gBwKSfS2euCyI6lS6HOxr7k7ZEDTdf35UhbH+81DsVgvfOWce2+rb+ev7e2NyjLFS1+pBiNhlPZfl29nr7k7KxWCjUYI+QSjK1lpq7WnqokFvPRdHl0t/s+jgsQ+099DrC8S0hstgKpwOAjJ1Ixaqg/9bo8IVw3HO4VM5dkYBP1v7Gc1dvTE9ViTUtXooykrHaomNHJXm2+nw+mjz9I0+eIKjBH2CIEQwdDFU0OPocoFgs+jgsfWIm1iWzR2MfpdS1ZiafvT11cH6LQZkiI6EEIIfrFpAl9fHT//1aUyPFQlaY4vYGSdGhi729Pm581+fJu0iqxL0CUR5gYNqdxeN7T0IgeFp0qMRmlzUXwc9ni4Xp9bma3Ap4VRhXZUbV5atP+Y+lswqyuLq48r528Z9fLyvNebHG4m6Vg/FebG7jvS7SCME/e6Xd3DfG7v5w9tV495XLFCCPoEod2o+5P1tPRQ4bFjM8f33ubIGXC41zd2kmUVMQs3CkWNPo8BhTUlB1/znzRxVkR+XqCGAr582G1emjduf35qwkgqBgGR/a09MLXS9jO54BX19lZs/vF2FzWJizab6pFzLUYI+gahw2unzSzbVtsZ1QVTHlWWjucuLPyDZ6+6mJM+OOU6lB3QqnA6qUjAWvcbdzYH2npj7z0PJtGkLpJtr2/jbxn1xO24oTZ1eev0BSmJoGDhsFgoc1nG5STq9Pm55chOleXZ+ftEiWrv7eOOzBgNnaQxK0CcQekbmjoOdFMXZfw6ayyUgwd3lZY+7K67uFp1KV2qGLq6v1uu3xNZ/PphVi6axvCKfn/7rU1q7479AWqvHoMcoZFGndJyhi//7j+3UtXq4+6JFrFwwBWemlWc+rDNwhsYQkaALIVYKIT4TQuwSQtw2zPabhRDbhRCbhRCvCiGmGz9VRUWIbzWeES46/clF7V72urvjUpRrMBXOTJo6vbT3pFbEwvqqZpyZVma4MuN6XCEEPzx/Ae09Pn720mdxPTZoC6IQmyzRUMYTi/7qJwd5fMM+rj9xBkvL87GYTaxaVMxrnzYk5EtwJEYVdCGEGbgXOAuYD1wihJg/aNhHwFIp5ULgKeCnRk9UoVnIdqvW7DfeES4wIOg7DnbQ4fVRFsekIp25U7IAeOS9mrgfO1ZIKVkX4/jzkZg7JZsrjpnOX9bvZWtdW1yPrScVxSJLNJSyfDv1rT30jbEVX3NXL//99BbmTsnim6fP6n999ZJiev0B/rF5v9FTHReRWOjLgV1SyiopZS/wOHB+6AAp5etSSv3rbx1QYuw0FaBZU7rbJRE+dP2uYMOeFoCYZTOOxEmzXZy3aBp3rf2MZz6sjfvxY0Fti4f6tp6YhyuOxDdOm02Bw8p347xAWt/qISvdQlYMWxiCJuj+4AJspEgp+c6zW2jz9HL3RUdgs5j7ty2Yls3sosykuwYjEfRiIHTFpDb4Wji+DLw43AYhxHVCiI1CiI2NjclZlznZ0UU0npUWdZzB9P8ParR46UT40E0mwc8uXMgxlQX811ObeXvnxL+O3jO4/nk05GSkcdtZ8/hobytPxVGk6lo9MbfOgf5WfmNxuzz/cT0vbj3AN0+fzfxp2YdsE0KwekkJH+5tHdLAPZEYuigqhPgSsBS4a7jtUsr7pZRLpZRLXS6XkYeeNJQH/eiJcLlkWM1k2SzsONiJEFASw9jhkbBZzPz+iiOZWZjJVx/5IO5uAqNZX9VMvsPKrML4+s8Hs3pxMUdOz+POFz+NW1ZlbYsnZjVcQtFj0fe1RCbo+9s8fPf5rRw5PY/rT5wx7JjPHVGMEPDMR8mzOBqJoNcBpSG/lwRfOwQhxGnAd4BVUsqhzScVhrCwOAer2RTzxszhcAW/SKZkp5OeZh5ldOzITk/j4WuWk2u3ctWfNiRt5l4kaP7z+MWfh8Nk0jJIW7p7+cXLO+JyTC1LNPaCPiU7nTSziMhCDwQk33pyMz6/5OcXLgobmjslJ53jZjh59qPapKkTE4mgbwBmCSEqhBBW4GJgTegAIcRi4PdoYp58wZkpxMrDpvDubaf0uz/ijV51MRHulsEUZafz8DXL6PMHuOLB95OiLslYqW3ppq7VE5P659FwWHEOlx01nT+/t4ft9e0xPVZHTx/tPb64uFzMJkFJXmSRLo+ur+GdXU1855x5/XfE4Vi9pJh9zR421rQYNdVxMaqgSyl9wE3AWuAT4Akp5TYhxA+FEKuCw+4CMoEnhRAfCyHWhNmdYpwIIfqjTRKBfux41nAZiZmFWfzxyqXUt3q45qENeHr9iZ7SmFhfpddvSZz/fDC3njGHXLuV763ZGlPLs741do0thqM03z7qnVxVYyc/fuETTpzt4rKjykbd55kLpmC3mpNmcTQiH7qU8gUp5Wwp5Qwp5R3B126XUq4JPj9NSlkkpTwi+Fg18h4VExU90iWeVRZHY2l5Pr+8eDGba1u56a8f4htjaFoiWVflJteexpyirERPpZ8cexr/vXIOG/a08NzHsfMP17Vq4hrrpCKdsvyRG134/AFufmITNouZn35+YUQuMIfNwsoFU/jH5v309CXemFCZoooxoVvo8WxsEQkrD5vCD84/jFc/beC7z8fWsjSS9dXNLC/PxxTnEgqjceGRpSwqzeXHL3xKR4ySuOqCFno8XC6ghS62dveFXfD93Zu7+XhfKz/63GFMyYk8imz1khI6eny8+knivc1K0BVjYkpOUNCdyWOh61x+9HRuXDGDx97fxy9fTa6+mcNR3+phb3N3QsMVw2EyCX50/gKaOr3c80pszmVdiwer2dS/LhNrRmoYvbWujXte2cm5C6eyatG0Me33mBkFFGXbePajxLtdlKArxsRZh03lN5cuZv7U7NEHJ4Bbz5jD55eUcM8rO3k8STryhEOv35LIhKKRWFiSy8XLynjo33vYcbDD8P3XtXqYmpset7uT0jCC3tPn5+YnPibfYeVH5x825v2aTYLPLS7mjc8aaepMbICfEnTFmEhPM3PuwmkJD7ELhxCC//v84Zw028V3ntvKq58cTPSUwrJudzM5GWnMm5KcX44A3zpzDlnpFm6PgRurvtXDtJz4lV8Ol1x098s72HGwkzu/sJC8KHsMrF5cgi8g+fum+nHPczwoQVekHGlmE7+9bAkLpmVz418/5KO9yRFSNpj11W6WJaH/PJR8h5Vbz5jDuqpm/m5w3ZK6Fk/cFkRBy13Is6cdIuh6jfNLjypjxZzCqPc9Z0oWC6Zl82yCk4yUoCtSEofNwoNXLaMoO51rHtqQdG3rDrT1sMfdHfdyudFwyfIyDivO5o5/bqfT6zNkn33+AAc7euLaIAUOrboYWuP8O2fPG/e+Vy8pYXNtG7sajHdPRYoSdEXK4sy08fDVyzEJwZV/ep+GjsgLM8WagfrnybcgOhizSfDD8w/jYLuXX79mzALpgbYepCSmjS2GoyQkFj20xrnDZhn3vlctmobZJBJaJ10JuiKlKXc6ePCqZTR19HLNQxsMszDHy7qqZrLSLcxL0sXlwSwpy+PCI0v449vV7GoY/91ObUt8GlsMpizfTm2Lh5e2HTikxrkRuLJsnDjLybMf1SWspZ8SdEXKs6g0l99+aQmf7O/ghkc/SIpekOur3Cwvz497C7/x8N9nzcVuNfP9NdvGvUAar8YWgynLt+MLSG5+YtOQGudGsHpJCfvbelgXrKAZb5SgKyYFK+YU8pPVh/P2ziZue3oz/gRZUAAN7T1UNXUlbbhiOJyZNm45Yw7v7GriF6/sHJeo1wUFfeoYEniMQI9F9/r8Q2qcG8Hp84vIslkSVoFRCbpi0nDR0lJuOX02z3xUxyX3r2OvOzEVGtdVa/VbJoL/fDBfOno6n19Swq9e3cm3ntoc9d1OfasHZ6Yt7hU7ZxVmYjEJbj1jzpAa50aQnmbm7MOn8uKW/QmpK6QEXTGpuOmUmfz8wkV8sr+dlb98i7+u3xv3MgHrq9xk2ixJm5w1EuZgg5FvnDaLpz6o5ZqHNkTV37WuNb4hizqF2el88D+nc/1Jw9c4N4LVS4rp6vXz0vYDMTtGOJSgKyYVQgg+f2QJ//rmiSwuy+X/PbuFqx/awMH2+EXArK9uZll5HhbzxPz4CSH4xmmzuesLC1lX5ebC+97r94lHSl2Lh+Lc+HfdAq34WCxZVp5PcW4GTycg2mViXlEKxTgpzs3gkWuO4gerFrCuys0Zv3iLNXHI8ttxsINdDZ1JVS43Wi5cWspDVy+nvtXDBb99l231kXWOklLGrfVcIjCZBKuXFPPOzkYa4mgogBJ0xSTGZBJceWw5L/znCVS6HPznYx9x418/pMXgRhlSSjbuaearj3zAmfe8hc1i4rR5RYYeI1EcP8vJkzccg0kILvrde7zx2egVB91dvXh9gZQVdIALFhcTkFpf0niiBF0x6al0ZfLk9cfwrTPn8NK2A5xxz1u89un4a8D4/AH+sbmeC377b77wu/d4r8rNDSfN4M1vrWBmgvuHGsncKdk8d+NxTC9w8OWHN/LYKEXREhWyGE8qXZkcUZrL03FufKEEXaEALGYTN66YyfM3Hk+Bw8o1D23ktqc3R5WI1N7TxwNvV3HSXW9w018/orW7lx+dv4D3vn0K/7Vy7phqbU8UirLTeeKrx3D8TCfffmYLd639NOxic12CkorizeeXFPPpgY6Yt/ILRQm6QhHC/GnZPH/Tcdxw8gye2LiPlfe8FXGSSG1LN//7j+0c+5PX+N9/fkJxXgb3X34kr95yMpcfU47dOv708mQm02bhgSuXcsnyUu59fTff+NvHeH1DQ/f0GPRUdrkAnLtwGmlmEdc66al9hSkUUWCzmPnvlXM5bV4hNz+xiUv+sI4vH1fBrWfOGTZu+qO9LTzwTjX/2qqFqZ27cCpfPr6ChSW5cZ554kkzm/jxBYdTkmfnrrWfcaCth/svX3pIZEldqweH1UxORmyjTRJNnsPKijmFPPdxPf+9cm5copqUoCsUYThyej4vfv0EfvLCpzzwTjVv7Gjk7osWsbAkF39A8vL2AzzwdjUba1rISrdw7QkVXHlMeUr7hiNBCMGNK2ZSkpfBt57czOr73uWhq5f31yPXy+Yma019I1m9pJiXth/k3d1uTprtivnxlKArFCNgt1r40ecO4/T5RfzXU5u54Lf/5sIjS3h3dxP7mj2U5mfwvfPmc+HSUjINqNiXSpx/RDFF2elc9+eNXPDbd3nwqmUsLMmlvs0zab70VswtJCcjjWc+rI2LoCsfukIRASfOdrH2GyeyatE0Ht+wj6KsdH73pSW8cesKrj6uQol5GI6uLOCZrx1LepqZL/5+Ha9sPxhMKpocgm6zmDlv0VTWbjsQl0qfStAVigjJsafxiy8ewbYfnMlTNxzLysOmTqhqiYliZmEWz3ztWGYVZXLdIxtp6e6bNBY6wAWLS+jpC/DiFmM7Pg2HEnSFYowY0QxhslGYlc7j1x3NKXO1Nm961cPJwJKyXMoL7HFpfKEEXaFQxAW71cLvL1/KA1cs5fT5qZEpGwlCCFYvKWFdtbs/ZDNWKEFXKBRxw2wSnDa/KO5lcxPNBYuLkRKei3GddCXoCoVCEWNK8+0sL8/n2Y/qYlquWQm6QqFQxIELlhSzq6GTLXWRVaWMBiXoCoVCEQfOPnwqVosppoujStAVCoUiDuRkpHH6/CLWbKqnzx+bRuVK0BUKhSJOrF5cTHNXL29+1hiT/StBVygUijhx4mwXp8wtxJYWG+lVGRIKhUIRJ9LMJh68alnM9q8sdIVCoUgRIhJ0IcRKIcRnQohdQojbhtluE0L8Lbh9vRCi3PCZKhQKhWJERhV0IYQZuBc4C5gPXCKEmD9o2JeBFinlTOAXwJ1GT1ShUCgUIxOJhb4c2CWlrJJS9gKPA+cPGnM+8HDw+VPAqWIyVK9XKBSKJCISQS8G9oX8Xht8bdgxUkof0AYUDN6REOI6IcRGIcTGxsbYhO0oFArFZCWui6JSyvullEullEtdrth371AoFIrJRCSCXgeUhvxeEnxt2DFCCAuQA0TWKl2hUCgUhhCJoG8AZgkhKoQQVuBiYM2gMWuAK4PPvwC8JmNZUkyhUCgUQxCR6K4Q4mzgHsAMPCilvEMI8UNgo5RyjRAiHXgEWAw0AxdLKatG2WcjUBPlvJ1AU5TvjQdqfuNDzW/8JPsc1fyiZ7qUclifdUSCnmwIITZKKZcmeh7hUPMbH2p+4yfZ56jmFxtUpqhCoVCkCErQFQqFIkWYqIJ+f6InMApqfuNDzW/8JPsc1fxiwIT0oSsUCoViKBPVQlcoFArFIJSgKxQKRYqQ1IKezGV7hRClQojXhRDbhRDbhBBfH2bMyUKINiHEx8HH7fGaX/D4e4QQW4LH3jjMdiGE+FXw/G0WQiyJ49zmhJyXj4UQ7UKIbwwaE/fzJ4R4UAjRIITYGvJavhDiZSHEzuDPvDDvvTI4ZqcQ4srhxsRgbncJIT4N/v+eFULkhnnviNdCjOf4fSFEXcj/8eww7x3x8x7D+f0tZG57hBAfh3lvXM7huJBSJuUDLYlpN1AJWIFNwPxBY74G/C74/GLgb3Gc31RgSfB5FrBjmPmdDPwjgedwD+AcYfvZwIuAAI4G1ifwf30ALWEioecPOBFYAmwNee2nwG3B57cBdw7zvnygKvgzL/g8Lw5zOwOwBJ/fOdzcIrkWYjzH7wO3RnANjPh5j9X8Bm3/OXB7Is/heB7JbKEnddleKeV+KeWHwecdwCcMrUKZ7JwP/FlqrANyhRBTEzCPU4HdUspoM4cNQ0r5Flq2cyih19nDwOeGeeuZwMtSymYpZQvwMrAy1nOTUr4ktQqnAOvQai0ljDDnLxIi+byPm5HmF9SOi4DHjD5uvEhmQTesbG+sCbp6FgPrh9l8jBBikxDiRSHEgvjODAm8JIT4QAhx3TDbIznH8eBiwn+IEnn+dIqklPuDzw8ARcOMSYZzeQ3aHddwjHYtxJqbgm6hB8O4rJLh/J0AHJRS7gyzPdHncFSSWdAnBEKITOBp4BtSyvZBmz9EcyMsAn4NPBfn6R0vpVyC1m3qRiHEiXE+/qgIreDbKuDJYTYn+vwNQWr33kkX6yuE+A7gA/4SZkgir4X7gBnAEcB+NLdGMnIJI1vnSf95SmZBT/qyvUKINDQx/4uU8pnB26WU7VLKzuDzF4A0IYQzXvOTUtYFfzYAz6Ld1oYSyTmONWcBH0opDw7ekOjzF8JB3RUV/NkwzJiEnUshxFXAucBlwS+cIURwLcQMKeVBKaVfShkA/hDm2Am9FoP6sRr4W7gxiTyHkZLMgp7UZXuD/rY/Ap9IKe8OM2aK7tMXQixHO99x+cIRQjiEEFn6c7TFs62Dhq0BrghGuxwNtIW4FuJFWKsokedvEKHX2ZXA88OMWQucIYTIC7oUzgi+FlOEECuB/wJWSSm7w4yJ5FqI5RxD12UuCHPsSD7vseQ04FMpZe1wGxN9DiMm0auyIz3QojB2oK1+fyf42g/RLl6AdLRb9V3A+0BlHOd2PNqt92bg4+DjbOCrwFeDY24CtqGt2K8Djo3j/CqDx90UnIN+/kLnJ9AagO8GtgBL4/z/daAJdE7Iawk9f2hfLvuBPjQ/7pfR1mVeBXYCrwD5wbFLgQdC3ntN8FrcBVwdp7ntQvM969egHvU1DXhhpGshjufvkeD1tRlNpKcOnmPw9yGf93jML/j6Q/p1FzI2IedwPA+V+q9QKBQpQjK7XBQKhUIxBpSgKxQKRYqgBF2hUChSBCXoCoVCkSIoQVcoFIoUQQm6QqFQpAhK0BUKhSJF+P9I8vcaN+P6sQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(eps,t_loss)\n",
    "plt.plot(eps,d_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "95f7cc04-ce28-417b-a1d4-41cc3bb75eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'sstcls_{}.dat'.format(ep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b707ac33-63aa-4e81-b71e-604078a51291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
