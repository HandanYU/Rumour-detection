{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a00ed975-afc9-4cbe-89e9-651cd7187fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "import sampler as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f3821f7-0888-4ca0-a0b5-ed088ca2b77f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1579 entries, 0 to 1578\n",
      "Data columns (total 66 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   Unnamed: 0                           1579 non-null   int64  \n",
      " 1   reply_contributors                   1579 non-null   float64\n",
      " 2   reply_possibly_sensitive             1579 non-null   float64\n",
      " 3   reply_possibly_sensitive_appealable  1579 non-null   float64\n",
      " 4   reply_retweet_count                  1579 non-null   float64\n",
      " 5   reply_favorite_count                 1579 non-null   float64\n",
      " 6   reply_mentioned_url_num              1579 non-null   float64\n",
      " 7   reply_id_num                         1579 non-null   float64\n",
      " 8   reply_followers_count                1579 non-null   float64\n",
      " 9   reply_friends_count                  1579 non-null   float64\n",
      " 10  reply_listed_count                   1579 non-null   float64\n",
      " 11  reply_favourites_count               1579 non-null   float64\n",
      " 12  reply_statuses_count                 1579 non-null   float64\n",
      " 13  reply_has_url                        1579 non-null   float64\n",
      " 14  reply_senti_score                    1579 non-null   float64\n",
      " 15  reply_truncated                      1579 non-null   float64\n",
      " 16  reply_is_quote_status                1579 non-null   float64\n",
      " 17  reply_favorited                      1579 non-null   float64\n",
      " 18  reply_retweeted                      1579 non-null   float64\n",
      " 19  reply_protected                      1579 non-null   float64\n",
      " 20  reply_geo_enabled                    1579 non-null   float64\n",
      " 21  reply_verified                       1579 non-null   float64\n",
      " 22  reply_contributors_enabled           1579 non-null   float64\n",
      " 23  reply_isweekday                      1579 non-null   float64\n",
      " 24  reply_contributors_enabled.1         1579 non-null   float64\n",
      " 25  reply_is_translator                  1579 non-null   float64\n",
      " 26  reply_is_translation_enabled         1579 non-null   float64\n",
      " 27  reply_has_extended_profile           1579 non-null   float64\n",
      " 28  reply_default_profile                1579 non-null   float64\n",
      " 29  reply_default_profile_image          1579 non-null   float64\n",
      " 30  reply_following                      1579 non-null   float64\n",
      " 31  reply_follow_request_sent            1579 non-null   float64\n",
      " 32  reply_notifications                  1579 non-null   float64\n",
      " 33  contributors                         0 non-null      float64\n",
      " 34  possibly_sensitive                   1579 non-null   float64\n",
      " 35  possibly_sensitive_appealable        1579 non-null   float64\n",
      " 36  retweet_count                        1579 non-null   float64\n",
      " 37  favorite_count                       1579 non-null   float64\n",
      " 38  mentioned_url_num                    1579 non-null   float64\n",
      " 39  id_num                               1579 non-null   float64\n",
      " 40  followers_count                      1579 non-null   float64\n",
      " 41  friends_count                        1579 non-null   float64\n",
      " 42  listed_count                         1579 non-null   float64\n",
      " 43  favourites_count                     1579 non-null   float64\n",
      " 44  statuses_count                       1579 non-null   float64\n",
      " 45  has_url                              1579 non-null   float64\n",
      " 46  senti_score                          1579 non-null   float64\n",
      " 47  truncated                            1579 non-null   float64\n",
      " 48  is_quote_status                      1579 non-null   float64\n",
      " 49  favorited                            1579 non-null   float64\n",
      " 50  retweeted                            1579 non-null   float64\n",
      " 51  protected                            1579 non-null   float64\n",
      " 52  geo_enabled                          1579 non-null   float64\n",
      " 53  verified                             1579 non-null   float64\n",
      " 54  contributors_enabled                 1579 non-null   float64\n",
      " 55  isweekday                            1579 non-null   float64\n",
      " 56  reply_count                          1579 non-null   float64\n",
      " 57  contributors_enabled.1               1579 non-null   float64\n",
      " 58  is_translator                        1579 non-null   float64\n",
      " 59  is_translation_enabled               1579 non-null   float64\n",
      " 60  has_extended_profile                 1579 non-null   float64\n",
      " 61  default_profile                      1579 non-null   float64\n",
      " 62  default_profile_image                1579 non-null   float64\n",
      " 63  following                            1579 non-null   float64\n",
      " 64  follow_request_sent                  1579 non-null   float64\n",
      " 65  notifications                        1579 non-null   float64\n",
      "dtypes: float64(65), int64(1)\n",
      "memory usage: 814.3 KB\n"
     ]
    }
   ],
   "source": [
    "train_stat = pd.read_csv('./sep_data/train_scaled_stat_feat_df.csv')\n",
    "dev_stat = pd.read_csv('./sep_data/dev_scaled_stat_feat_df.csv')\n",
    "\n",
    "train_tweet = pd.read_csv('./sep_data/train_tweet_df.csv')\n",
    "dev_tweet = pd.read_csv('./sep_data/dev_tweet_df.csv')\n",
    "\n",
    "train_stat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "088391fe-c7bc-45a9-ac29-1c42b62e7f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 536 entries, 0 to 535\n",
      "Data columns (total 66 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   Unnamed: 0                           536 non-null    int64  \n",
      " 1   reply_contributors                   536 non-null    float64\n",
      " 2   reply_possibly_sensitive             536 non-null    float64\n",
      " 3   reply_possibly_sensitive_appealable  536 non-null    float64\n",
      " 4   reply_retweet_count                  536 non-null    float64\n",
      " 5   reply_favorite_count                 536 non-null    float64\n",
      " 6   reply_mentioned_url_num              536 non-null    float64\n",
      " 7   reply_id_num                         536 non-null    float64\n",
      " 8   reply_followers_count                536 non-null    float64\n",
      " 9   reply_friends_count                  536 non-null    float64\n",
      " 10  reply_listed_count                   536 non-null    float64\n",
      " 11  reply_favourites_count               536 non-null    float64\n",
      " 12  reply_statuses_count                 536 non-null    float64\n",
      " 13  reply_has_url                        536 non-null    float64\n",
      " 14  reply_senti_score                    536 non-null    float64\n",
      " 15  reply_truncated                      536 non-null    float64\n",
      " 16  reply_is_quote_status                536 non-null    float64\n",
      " 17  reply_favorited                      536 non-null    float64\n",
      " 18  reply_retweeted                      536 non-null    float64\n",
      " 19  reply_protected                      536 non-null    float64\n",
      " 20  reply_geo_enabled                    536 non-null    float64\n",
      " 21  reply_verified                       536 non-null    float64\n",
      " 22  reply_contributors_enabled           536 non-null    float64\n",
      " 23  reply_isweekday                      536 non-null    float64\n",
      " 24  reply_contributors_enabled.1         536 non-null    float64\n",
      " 25  reply_is_translator                  536 non-null    float64\n",
      " 26  reply_is_translation_enabled         536 non-null    float64\n",
      " 27  reply_has_extended_profile           536 non-null    float64\n",
      " 28  reply_default_profile                536 non-null    float64\n",
      " 29  reply_default_profile_image          536 non-null    float64\n",
      " 30  reply_following                      536 non-null    float64\n",
      " 31  reply_follow_request_sent            536 non-null    float64\n",
      " 32  reply_notifications                  536 non-null    float64\n",
      " 33  contributors                         0 non-null      float64\n",
      " 34  possibly_sensitive                   536 non-null    float64\n",
      " 35  possibly_sensitive_appealable        536 non-null    float64\n",
      " 36  retweet_count                        536 non-null    float64\n",
      " 37  favorite_count                       536 non-null    float64\n",
      " 38  mentioned_url_num                    536 non-null    float64\n",
      " 39  id_num                               536 non-null    float64\n",
      " 40  followers_count                      536 non-null    float64\n",
      " 41  friends_count                        536 non-null    float64\n",
      " 42  listed_count                         536 non-null    float64\n",
      " 43  favourites_count                     536 non-null    float64\n",
      " 44  statuses_count                       536 non-null    float64\n",
      " 45  has_url                              536 non-null    float64\n",
      " 46  senti_score                          536 non-null    float64\n",
      " 47  truncated                            536 non-null    float64\n",
      " 48  is_quote_status                      536 non-null    float64\n",
      " 49  favorited                            536 non-null    float64\n",
      " 50  retweeted                            536 non-null    float64\n",
      " 51  protected                            536 non-null    float64\n",
      " 52  geo_enabled                          536 non-null    float64\n",
      " 53  verified                             536 non-null    float64\n",
      " 54  contributors_enabled                 536 non-null    float64\n",
      " 55  isweekday                            536 non-null    float64\n",
      " 56  reply_count                          536 non-null    float64\n",
      " 57  contributors_enabled.1               536 non-null    float64\n",
      " 58  is_translator                        536 non-null    float64\n",
      " 59  is_translation_enabled               536 non-null    float64\n",
      " 60  has_extended_profile                 536 non-null    float64\n",
      " 61  default_profile                      536 non-null    float64\n",
      " 62  default_profile_image                536 non-null    float64\n",
      " 63  following                            536 non-null    float64\n",
      " 64  follow_request_sent                  536 non-null    float64\n",
      " 65  notifications                        536 non-null    float64\n",
      "dtypes: float64(65), int64(1)\n",
      "memory usage: 276.5 KB\n"
     ]
    }
   ],
   "source": [
    "dev_stat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f4a9f9-bc11-4c50-8627-eb05210bfbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reply_contributors</th>\n",
       "      <th>reply_possibly_sensitive</th>\n",
       "      <th>reply_possibly_sensitive_appealable</th>\n",
       "      <th>reply_retweet_count</th>\n",
       "      <th>reply_favorite_count</th>\n",
       "      <th>reply_mentioned_url_num</th>\n",
       "      <th>reply_id_num</th>\n",
       "      <th>reply_followers_count</th>\n",
       "      <th>reply_friends_count</th>\n",
       "      <th>reply_listed_count</th>\n",
       "      <th>...</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>contributors_enabled.1</th>\n",
       "      <th>is_translator</th>\n",
       "      <th>is_translation_enabled</th>\n",
       "      <th>has_extended_profile</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "      <th>following</th>\n",
       "      <th>follow_request_sent</th>\n",
       "      <th>notifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.146906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.048668</td>\n",
       "      <td>-0.039468</td>\n",
       "      <td>-0.359423</td>\n",
       "      <td>-0.262777</td>\n",
       "      <td>-0.125634</td>\n",
       "      <td>-0.396180</td>\n",
       "      <td>-0.142023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.504152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>-0.722953</td>\n",
       "      <td>1.392986</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.146906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.048668</td>\n",
       "      <td>-0.039494</td>\n",
       "      <td>-0.279803</td>\n",
       "      <td>-0.240359</td>\n",
       "      <td>-0.112251</td>\n",
       "      <td>0.057344</td>\n",
       "      <td>-0.102036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.297330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.736649</td>\n",
       "      <td>-0.722953</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.146906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.048668</td>\n",
       "      <td>-0.039442</td>\n",
       "      <td>-0.359423</td>\n",
       "      <td>-0.330033</td>\n",
       "      <td>-0.125729</td>\n",
       "      <td>-0.429035</td>\n",
       "      <td>-0.142861</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.504152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>1.383215</td>\n",
       "      <td>1.392986</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.146906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.048530</td>\n",
       "      <td>-0.039494</td>\n",
       "      <td>-0.279803</td>\n",
       "      <td>-0.374870</td>\n",
       "      <td>-0.123535</td>\n",
       "      <td>-0.292513</td>\n",
       "      <td>-0.141622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>1.383215</td>\n",
       "      <td>1.392986</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.146906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.048668</td>\n",
       "      <td>-0.039520</td>\n",
       "      <td>-0.120565</td>\n",
       "      <td>-0.374870</td>\n",
       "      <td>-0.125598</td>\n",
       "      <td>-0.383978</td>\n",
       "      <td>-0.142788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>1.383215</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   reply_contributors  reply_possibly_sensitive  \\\n",
       "0                 0.0                 -0.146906   \n",
       "1                 0.0                 -0.146906   \n",
       "2                 0.0                 -0.146906   \n",
       "3                 0.0                 -0.146906   \n",
       "4                 0.0                 -0.146906   \n",
       "\n",
       "   reply_possibly_sensitive_appealable  reply_retweet_count  \\\n",
       "0                                  0.0            -0.048668   \n",
       "1                                  0.0            -0.048668   \n",
       "2                                  0.0            -0.048668   \n",
       "3                                  0.0            -0.048530   \n",
       "4                                  0.0            -0.048668   \n",
       "\n",
       "   reply_favorite_count  reply_mentioned_url_num  reply_id_num  \\\n",
       "0             -0.039468                -0.359423     -0.262777   \n",
       "1             -0.039494                -0.279803     -0.240359   \n",
       "2             -0.039442                -0.359423     -0.330033   \n",
       "3             -0.039494                -0.279803     -0.374870   \n",
       "4             -0.039520                -0.120565     -0.374870   \n",
       "\n",
       "   reply_followers_count  reply_friends_count  reply_listed_count  ...  \\\n",
       "0              -0.125634            -0.396180           -0.142023  ...   \n",
       "1              -0.112251             0.057344           -0.102036  ...   \n",
       "2              -0.125729            -0.429035           -0.142861  ...   \n",
       "3              -0.123535            -0.292513           -0.141622  ...   \n",
       "4              -0.125598            -0.383978           -0.142788  ...   \n",
       "\n",
       "   reply_count  contributors_enabled.1  is_translator  is_translation_enabled  \\\n",
       "0    -0.504152                     0.0            0.0               -0.365410   \n",
       "1    -0.297330                     0.0            0.0                2.736649   \n",
       "2    -0.504152                     0.0            0.0               -0.365410   \n",
       "3    -0.452447                     0.0            0.0               -0.365410   \n",
       "4    -0.452447                     0.0            0.0               -0.365410   \n",
       "\n",
       "   has_extended_profile  default_profile  default_profile_image  following  \\\n",
       "0             -0.722953         1.392986              -0.050395        0.0   \n",
       "1             -0.722953        -0.717882              -0.050395        0.0   \n",
       "2              1.383215         1.392986              -0.050395        0.0   \n",
       "3              1.383215         1.392986              -0.050395        0.0   \n",
       "4              1.383215        -0.717882              -0.050395        0.0   \n",
       "\n",
       "   follow_request_sent  notifications  \n",
       "0                  0.0            0.0  \n",
       "1                  0.0            0.0  \n",
       "2                  0.0            0.0  \n",
       "3                  0.0            0.0  \n",
       "4                  0.0            0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stat.drop(columns=['Unnamed: 0', 'contributors'], inplace=True)\n",
    "train_stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd76937-ef04-4177-be23-3a112f9f09db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reply_contributors</th>\n",
       "      <th>reply_possibly_sensitive</th>\n",
       "      <th>reply_possibly_sensitive_appealable</th>\n",
       "      <th>reply_retweet_count</th>\n",
       "      <th>reply_favorite_count</th>\n",
       "      <th>reply_mentioned_url_num</th>\n",
       "      <th>reply_id_num</th>\n",
       "      <th>reply_followers_count</th>\n",
       "      <th>reply_friends_count</th>\n",
       "      <th>reply_listed_count</th>\n",
       "      <th>...</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>contributors_enabled.1</th>\n",
       "      <th>is_translator</th>\n",
       "      <th>is_translation_enabled</th>\n",
       "      <th>has_extended_profile</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "      <th>following</th>\n",
       "      <th>follow_request_sent</th>\n",
       "      <th>notifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.146906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.048668</td>\n",
       "      <td>-0.039494</td>\n",
       "      <td>-0.439042</td>\n",
       "      <td>-0.285196</td>\n",
       "      <td>-0.124821</td>\n",
       "      <td>-0.374651</td>\n",
       "      <td>-0.141950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>1.383215</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.146906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.043015</td>\n",
       "      <td>-0.038642</td>\n",
       "      <td>-0.200184</td>\n",
       "      <td>-0.016173</td>\n",
       "      <td>-0.124948</td>\n",
       "      <td>-0.415883</td>\n",
       "      <td>-0.141841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.349036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>1.383215</td>\n",
       "      <td>1.392986</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.146906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.048530</td>\n",
       "      <td>-0.039494</td>\n",
       "      <td>-0.359423</td>\n",
       "      <td>-0.195521</td>\n",
       "      <td>-0.125671</td>\n",
       "      <td>-0.413382</td>\n",
       "      <td>-0.142788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>-0.722953</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.146906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.044256</td>\n",
       "      <td>-0.034150</td>\n",
       "      <td>-0.040946</td>\n",
       "      <td>-0.374870</td>\n",
       "      <td>-0.124325</td>\n",
       "      <td>-0.325243</td>\n",
       "      <td>-0.134441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>1.383215</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.146906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.048668</td>\n",
       "      <td>-0.039520</td>\n",
       "      <td>-0.439042</td>\n",
       "      <td>-0.307614</td>\n",
       "      <td>-0.125557</td>\n",
       "      <td>-0.308740</td>\n",
       "      <td>-0.142059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.736649</td>\n",
       "      <td>-0.722953</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   reply_contributors  reply_possibly_sensitive  \\\n",
       "0                 0.0                 -0.146906   \n",
       "1                 0.0                 -0.146906   \n",
       "2                 0.0                 -0.146906   \n",
       "3                 0.0                 -0.146906   \n",
       "4                 0.0                 -0.146906   \n",
       "\n",
       "   reply_possibly_sensitive_appealable  reply_retweet_count  \\\n",
       "0                                  0.0            -0.048668   \n",
       "1                                  0.0            -0.043015   \n",
       "2                                  0.0            -0.048530   \n",
       "3                                  0.0            -0.044256   \n",
       "4                                  0.0            -0.048668   \n",
       "\n",
       "   reply_favorite_count  reply_mentioned_url_num  reply_id_num  \\\n",
       "0             -0.039494                -0.439042     -0.285196   \n",
       "1             -0.038642                -0.200184     -0.016173   \n",
       "2             -0.039494                -0.359423     -0.195521   \n",
       "3             -0.034150                -0.040946     -0.374870   \n",
       "4             -0.039520                -0.439042     -0.307614   \n",
       "\n",
       "   reply_followers_count  reply_friends_count  reply_listed_count  ...  \\\n",
       "0              -0.124821            -0.374651           -0.141950  ...   \n",
       "1              -0.124948            -0.415883           -0.141841  ...   \n",
       "2              -0.125671            -0.413382           -0.142788  ...   \n",
       "3              -0.124325            -0.325243           -0.134441  ...   \n",
       "4              -0.125557            -0.308740           -0.142059  ...   \n",
       "\n",
       "   reply_count  contributors_enabled.1  is_translator  is_translation_enabled  \\\n",
       "0    -0.452447                     0.0            0.0               -0.365410   \n",
       "1    -0.349036                     0.0            0.0               -0.365410   \n",
       "2    -0.452447                     0.0            0.0               -0.365410   \n",
       "3    -0.193920                     0.0            0.0               -0.365410   \n",
       "4    -0.452447                     0.0            0.0                2.736649   \n",
       "\n",
       "   has_extended_profile  default_profile  default_profile_image  following  \\\n",
       "0              1.383215        -0.717882              -0.050395        0.0   \n",
       "1              1.383215         1.392986              -0.050395        0.0   \n",
       "2             -0.722953        -0.717882              -0.050395        0.0   \n",
       "3              1.383215        -0.717882              -0.050395        0.0   \n",
       "4             -0.722953        -0.717882              -0.050395        0.0   \n",
       "\n",
       "   follow_request_sent  notifications  \n",
       "0                  0.0            0.0  \n",
       "1                  0.0            0.0  \n",
       "2                  0.0            0.0  \n",
       "3                  0.0            0.0  \n",
       "4                  0.0            0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_stat.drop(columns=['Unnamed: 0', 'contributors'], inplace=True)\n",
    "dev_stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da86e0c-0bd4-4574-a2e5-a446b9ed4add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reply_contributors                     0.000000e+00\n",
       "reply_possibly_sensitive               1.314504e-13\n",
       "reply_possibly_sensitive_appealable    0.000000e+00\n",
       "reply_retweet_count                    9.947598e-14\n",
       "reply_favorite_count                   7.815970e-14\n",
       "                                           ...     \n",
       "default_profile                        2.842171e-14\n",
       "default_profile_image                  7.460699e-14\n",
       "following                              0.000000e+00\n",
       "follow_request_sent                    0.000000e+00\n",
       "notifications                          0.000000e+00\n",
       "Length: 64, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stat.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1eebe27-571b-4af8-81a9-0078176bcbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reply_contributors', 'reply_possibly_sensitive_appealable', 'reply_favorited', 'reply_retweeted', 'reply_protected', 'reply_contributors_enabled', 'reply_contributors_enabled.1', 'reply_is_translator', 'reply_following', 'reply_follow_request_sent', 'reply_notifications', 'possibly_sensitive_appealable', 'favorited', 'retweeted', 'protected', 'contributors_enabled', 'contributors_enabled.1', 'is_translator', 'following', 'follow_request_sent', 'notifications']\n"
     ]
    }
   ],
   "source": [
    "dev_zero = []\n",
    "for column in dev_stat.columns:\n",
    "    if dev_stat[column].sum() == 0:\n",
    "        dev_zero.append(column)\n",
    "print(dev_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df1866c7-f1b8-4c35-a89f-7c94d6ad3262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reply_contributors', 'reply_possibly_sensitive_appealable', 'reply_favorited', 'reply_retweeted', 'reply_protected', 'reply_contributors_enabled', 'reply_contributors_enabled.1', 'reply_is_translator', 'reply_following', 'reply_follow_request_sent', 'reply_notifications', 'possibly_sensitive_appealable', 'retweet_count', 'statuses_count', 'favorited', 'retweeted', 'protected', 'contributors_enabled', 'contributors_enabled.1', 'is_translator', 'following', 'follow_request_sent', 'notifications']\n"
     ]
    }
   ],
   "source": [
    "train_zero = []\n",
    "for column in train_stat.columns:\n",
    "    if train_stat[column].sum() == 0:\n",
    "        train_zero.append(column)\n",
    "print(train_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "765eba63-9cac-40cf-af78-318cf99aa35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stat.drop(columns=train_zero, inplace=True)\n",
    "dev_stat.drop(columns=dev_zero, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c5145a7-616e-4dbe-9030-4b91370ea858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>reply_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1240727985491193862</td>\n",
       "      <td>covid viru transmit area hot humid world healt...</td>\n",
       "      <td>humid good demonstr virus surviv temperatur hi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>634943791934406657</td>\n",
       "      <td>marilyn monro jame dean smoke new york citi http</td>\n",
       "      <td>icon [SEP] http [SEP] yo puedo demostrar que e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1243967693297987584</td>\n",
       "      <td>symptom covid jcinigeria</td>\n",
       "      <td>symptom usual mild gradual common [SEP] infect...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1233175449980874752</td>\n",
       "      <td>coronaviru wear mask protect covid</td>\n",
       "      <td>thank [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1245592346344841216</td>\n",
       "      <td>symptom covid let watch new episod q covid know</td>\n",
       "      <td>infect peopl around world believ togeth stop [...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1240727985491193862  covid viru transmit area hot humid world healt...   \n",
       "1   634943791934406657   marilyn monro jame dean smoke new york citi http   \n",
       "2  1243967693297987584                           symptom covid jcinigeria   \n",
       "3  1233175449980874752                 coronaviru wear mask protect covid   \n",
       "4  1245592346344841216    symptom covid let watch new episod q covid know   \n",
       "\n",
       "                                          reply_text  label  \n",
       "0  humid good demonstr virus surviv temperatur hi...      0  \n",
       "1  icon [SEP] http [SEP] yo puedo demostrar que e...      1  \n",
       "2  symptom usual mild gradual common [SEP] infect...      0  \n",
       "3                                       thank [SEP]       0  \n",
       "4  infect peopl around world believ togeth stop [...      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d9d7b-b4cc-4144-8a0b-ac2e1f50d586",
   "metadata": {},
   "source": [
    "### Fill NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e477626-165a-4dd4-8b98-b70c007f79a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 536 entries, 0 to 535\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_id    536 non-null    int64 \n",
      " 1   text        529 non-null    object\n",
      " 2   reply_text  517 non-null    object\n",
      " 3   label       536 non-null    int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 16.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dev_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62faa088-f952-4217-8d4d-9d51ca76de70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1579 entries, 0 to 1578\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_id    1579 non-null   int64 \n",
      " 1   text        1561 non-null   object\n",
      " 2   reply_text  1508 non-null   object\n",
      " 3   label       1579 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 49.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "439ce649-ba89-4df2-b886-f55ce3b07f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tweet.reply_text.fillna('', inplace=True)\n",
    "train_tweet.reply_text.fillna('', inplace=True)\n",
    "dev_tweet.text.fillna('', inplace=True)\n",
    "train_tweet.text.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "580c969b-f940-445c-bc8a-bc699a5220a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 536 entries, 0 to 535\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_id    536 non-null    int64 \n",
      " 1   text        536 non-null    object\n",
      " 2   reply_text  536 non-null    object\n",
      " 3   label       536 non-null    int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 16.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dev_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eda359ca-ef95-4ddc-ba40-3a0c1a93c585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'humid good demonstr virus surviv temperatur high [SEP] mean warm weather good elimin'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_tweet.iloc[0].reply_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d11469-56b1-4ba0-b50f-96208aabf747",
   "metadata": {},
   "source": [
    "### Get Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12e5792f-a409-41de-9317-45adb20e7aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/536 [00:00<?, ?it/s]C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_17924\\2640282967.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dev_tweet.text.iloc[i] = '[CLS] ' + str(dev_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(dev_tweet.reply_text.iloc[i]).strip() + ' [SEP]'\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 536/536 [00:07<00:00, 75.32it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(dev_tweet))):\n",
    "    dev_tweet.text.iloc[i] = '[CLS] ' + str(dev_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(dev_tweet.reply_text.iloc[i]).strip() + ' [SEP]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e24eefb-945f-4aee-a8ce-620ecbad2e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1579 [00:00<?, ?it/s]C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_17924\\1422859891.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_tweet.text.iloc[i] = '[CLS] ' + str(train_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(train_tweet.reply_text.iloc[i]).strip() + ' [SEP]'\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1579/1579 [00:17<00:00, 89.31it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(train_tweet))):\n",
    "    train_tweet.text.iloc[i] = '[CLS] ' + str(train_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(train_tweet.reply_text.iloc[i]).strip() + ' [SEP]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "161eac3b-6e96-4538-b00c-3960902964f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] covid viru transmit area hot humid world health organ [SEP] humid good demonstr virus surviv temperatur high [SEP] mean warm weather good elimin [SEP]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_tweet.iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d7f58c5-7808-46b1-b541-63062280a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "# bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf57658d-7846-448f-90e9-a11e2849e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee25759-322a-420b-8a7d-84b2be197b6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aadc52e-0850-448b-8282-6b35952d9d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 522/522 [02:50<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1542/1542 [08:05<00:00,  3.18it/s]\n"
     ]
    }
   ],
   "source": [
    "max_len = 256\n",
    "dev_tokens = []\n",
    "train_tokens = []\n",
    "\n",
    "for i in tqdm(range(len(dev_tweet))):\n",
    "    txt = dev_tweet.text.iloc[i]\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    if len(tokens) < max_len:\n",
    "         padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "    else:\n",
    "        padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "    attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "    seg_ids = [1 if token == '[SEP]' else 0 for token in padded_tokens]\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    token_ids_t = torch.tensor(token_ids).unsqueeze(0) #Shape : [1, 12]\n",
    "    attn_mask_t = torch.tensor(attn_mask).unsqueeze(0) #Shape : [1, 12]\n",
    "    seg_ids_t   = torch.tensor(seg_ids).unsqueeze(0) #Shape : [1, 12]\n",
    "    outputs = bert_model(token_ids_t, attention_mask = attn_mask_t,\\\n",
    "                                  token_type_ids = seg_ids_t, return_dict=True)\n",
    "    cont_reps = outputs.last_hidden_state\n",
    "    cls_rep = cont_reps[:, 0]\n",
    "    dev_tokens.append(cls_rep.detach().numpy())\n",
    "\n",
    "for i in tqdm(range(len(train_tweet))):\n",
    "    txt = train_tweet.text.iloc[i]\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    if len(tokens) < max_len:\n",
    "         padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "    else:\n",
    "        padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "    attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "    seg_ids = [1 if token == '[SEP]' else 0 for token in padded_tokens]\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    token_ids_t = torch.tensor(token_ids).unsqueeze(0)\n",
    "    attn_mask_t = torch.tensor(attn_mask).unsqueeze(0)\n",
    "    seg_ids_t   = torch.tensor(seg_ids).unsqueeze(0)\n",
    "    outputs = bert_model(token_ids_t, attention_mask = attn_mask_t,\\\n",
    "                                  token_type_ids = seg_ids_t, return_dict=True)\n",
    "    cont_reps = outputs.last_hidden_state\n",
    "    cls_rep = cont_reps[:, 0]\n",
    "    train_tokens.append(cls_rep.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6fad0a-794c-4b6c-8958-07e9a4da423d",
   "metadata": {},
   "source": [
    "### BERT seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9adfbd5-67e1-4334-8ccf-4cb9af1b7580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 536/536 [00:01<00:00, 302.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1579/1579 [00:04<00:00, 353.84it/s]\n"
     ]
    }
   ],
   "source": [
    "max_len = 256\n",
    "dev_seq = []\n",
    "train_seq = []\n",
    "dev_mask = []\n",
    "train_mask = []\n",
    "dev_seg = []\n",
    "train_seg = []\n",
    "\n",
    "for i in tqdm(range(len(dev_tweet))):\n",
    "    txt = dev_tweet.text.iloc[i]\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    if len(tokens) < max_len:\n",
    "         padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "    else:\n",
    "        padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "    attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "    seg_ids = []\n",
    "    seg_idx = 0\n",
    "    for token in padded_tokens:\n",
    "        seg_ids.append(seg_idx)\n",
    "        if token == '[SEP]':\n",
    "            seg_idx += 1\n",
    "    # seg_ids = [1 if token == '[SEP]' else 0 for token in padded_tokens]\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    \n",
    "    dev_seq.append(token_ids)\n",
    "    dev_mask.append(attn_mask)\n",
    "    dev_seg.append(seg_ids)\n",
    "\n",
    "for i in tqdm(range(len(train_tweet))):\n",
    "    txt = train_tweet.text.iloc[i]\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    if len(tokens) < max_len:\n",
    "         padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "    else:\n",
    "        padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "    attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "    seg_ids = []\n",
    "    seg_idx = 0\n",
    "    for token in padded_tokens:\n",
    "        seg_ids.append(seg_idx)\n",
    "        if token == '[SEP]':\n",
    "            seg_idx += 1\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    \n",
    "    train_seq.append(token_ids)\n",
    "    train_mask.append(attn_mask)\n",
    "    train_seg.append(seg_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0c85e1-9dd7-467c-a3f4-3d49fdbc43a2",
   "metadata": {},
   "source": [
    "### test BERT adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d14e6939-428d-4eb8-b857-e85c5999baa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdTweetDataset(Data.Dataset):\n",
    "    def __init__(self, seq, mask, seg, y):\n",
    "        self.seq = torch.tensor(seq)\n",
    "        self.mask = torch.tensor(mask)\n",
    "        self.seg = torch.tensor(seg)\n",
    "        self.y = torch.tensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.seq.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.seq[idx],self.mask[idx],self.seg[idx], self.y[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c982771-f7de-4e1b-b6ca-25dc0b33d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_tweet['label']\n",
    "y_dev = dev_tweet['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23186e80-a34a-4888-b065-20a04b64826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "train_set = AdTweetDataset(train_seq, train_mask, train_seg,y_train)\n",
    "dev_set = AdTweetDataset(dev_seq, dev_mask, dev_seg, y_dev)\n",
    "\n",
    "sampler_s = sp.StratifiedSampler(class_vector=torch.from_numpy(np.array(y_train)), batch_size=64)\n",
    "\n",
    "train_loader = Data.DataLoader(train_set, sampler=sampler_s,batch_size=64)\n",
    "dev_loader = Data.DataLoader(dev_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "223b9706-ea79-481e-bb13-8ffe7bff9e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1579, 41)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac4ee5f3-9a21-4305-9296-146e7ae607a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RumorClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RumorClassifier, self).__init__()\n",
    "        #Instantiating BERT model object \n",
    "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        self.ffnn = nn.Sequential(nn.Linear(809,128),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(0.3),\n",
    "                                 nn.Linear(128,64),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(0.3),\n",
    "                                  nn.Linear(64,1),\n",
    "                                  nn.Sigmoid()\n",
    "                                 )\n",
    "\n",
    "    def forward(self, seq, attn_masks, seg, stats):\n",
    "        '''\n",
    "        Inputs:\n",
    "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
    "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
    "        '''\n",
    "\n",
    "        #Feeding the input to BERT model to obtain contextualized representations\n",
    "        outputs = self.bert_layer(seq, attention_mask = attn_masks, return_dict=True)\n",
    "        cont_reps = outputs.last_hidden_state\n",
    "\n",
    "        #Obtaining the representation of [CLS] head (the first token)\n",
    "        cls_rep = cont_reps[:, 0]\n",
    "        \n",
    "        x = torch.cat((cls_rep,stats),dim=1)\n",
    "        #Feeding cls_rep to the classifier layer\n",
    "        logits = self.ffnn(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a15bb73-449a-438b-9037-7e7db3321991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache ()\n",
    "net = RumorClassifier()\n",
    "# net = net.to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "opti = optim.Adam(net.parameters(), lr = 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99dd698a-ed70-46b8-a860-bb755cba759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "def get_accuracy_from_logits(logits, labels):\n",
    "    probs = logits.unsqueeze(-1)\n",
    "    soft_probs = (probs > 0.5).long()\n",
    "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
    "    return acc\n",
    "\n",
    "def get_f1_from_logits(logits, labels):\n",
    "    preds = (logits > 0.5).astype(int)\n",
    "    p, r, f, _ = precision_recall_fscore_support(labels, preds, pos_label=1, average=\"binary\")\n",
    "    return f\n",
    "\n",
    "def evaluate(net, criterion, dataloader, device):\n",
    "    net.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "    all_log = np.array([])\n",
    "    all_labels = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for seq, mask, seg, labels, idx in dataloader:\n",
    "            # seq, labels = seq.to(device), labels.to(device)\n",
    "            stats = np.array(train_stat)\n",
    "            stats = torch.tensor(stats[idx]).float()\n",
    "            #Obtaining the logits from the model\n",
    "            logits = net(seq, mask, seg, stats)\n",
    "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
    "            # mean_acc += get_accuracy_from_logits(logits, labels)\n",
    "            \n",
    "            all_log = np.hstack((all_log, logits.squeeze()))\n",
    "            all_labels = np.hstack((all_labels, labels.numpy()))\n",
    "            count += 1\n",
    "        \n",
    "        f = get_f1_from_logits(all_log, all_labels)\n",
    "    return f, mean_loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9666cce-201a-4823-ba27-db02fc97e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "best_acc = 0\n",
    "st = time.time()\n",
    "eps = []\n",
    "t_loss = []\n",
    "d_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeadff2-f94c-405b-a565-edc35d3313c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 of epoch 0 complete. \n",
      " Loss: 0.713007926940918; Accuracy: 0.234375; Time taken (s): 846.3967208862305\n"
     ]
    }
   ],
   "source": [
    "for ep in range(20):\n",
    "    eps.append(ep)\n",
    "    net.train()\n",
    "    for it, (seq, mask, seg, labels,idx) in enumerate(train_loader):\n",
    "        \n",
    "        #Clear gradients\n",
    "        opti.zero_grad()\n",
    "        #Converting these to cuda tensors\n",
    "        # seq, mask, seg, labels = seq.to(device), mask.to(device), seg.to(device), labels.to(device)\n",
    "        \n",
    "        stats = np.array(train_stat)\n",
    "        stats = torch.tensor(stats[idx]).float()\n",
    "        #Obtaining the logits from the model\n",
    "        logits = net(seq, mask, seg, stats)\n",
    "        #Computing loss\n",
    "        loss = criterion(logits.squeeze(), labels.float())\n",
    "\n",
    "        #Backpropagating the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #Optimization step\n",
    "        opti.step()\n",
    "\n",
    "        if it % 10 == 0:\n",
    "\n",
    "            acc = get_accuracy_from_logits(logits, labels)\n",
    "            print(\"Iteration {} of epoch {} complete. \\n Loss: {}; Accuracy: {}; Time taken (s): {}\".format(it, ep, loss.item(), acc, (time.time()-st)))\n",
    "            st = time.time()\n",
    "\n",
    "        \n",
    "    dev_acc, dev_loss = evaluate(net, criterion, dev_loader, 'cpu')\n",
    "    t_loss.append(loss.item())\n",
    "    d_loss.append(dev_loss)\n",
    "    print(\"Development F1: {}; Development Loss: {}\".format(dev_acc, dev_loss))\n",
    "    torch.save(net.state_dict(), 'D:\\\\bertcls_{}.dat'.format(ep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a29684-320a-4f85-aa16-51ce4e227314",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Text Only Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d35c4291-4528-4ff0-853b-36d828760796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRumorClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TextRumorClassifier, self).__init__()\n",
    "        #Instantiating BERT model object \n",
    "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        self.ffnn = nn.Sequential(nn.Linear(768,128),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(0.3),\n",
    "                                 nn.Linear(128,64),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(0.3),\n",
    "                                  nn.Linear(64,1),\n",
    "                                  nn.Sigmoid()\n",
    "                                 )\n",
    "\n",
    "    def forward(self, seq, attn_masks, seg):\n",
    "        '''\n",
    "        Inputs:\n",
    "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
    "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
    "        '''\n",
    "\n",
    "        #Feeding the input to BERT model to obtain contextualized representations\n",
    "        outputs = self.bert_layer(seq, attention_mask = attn_masks, return_dict=True)\n",
    "        cont_reps = outputs.last_hidden_state\n",
    "\n",
    "        #Obtaining the representation of [CLS] head (the first token)\n",
    "        cls_rep = cont_reps[:, 0]\n",
    "        \n",
    "        # x = torch.cat((cls_rep,stats),dim=1)\n",
    "        #Feeding cls_rep to the classifier layer\n",
    "        logits = self.ffnn(cls_rep)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fe7e7a2-650c-4e24-aeb3-ee256bdcae7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "net = TextRumorClassifier()\n",
    "# net = net.to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "opti = optim.Adam(net.parameters(), lr = 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f46bc5bb-8c33-4806-85ca-2b0e1380b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_evaluate(net, criterion, dataloader, device):\n",
    "    net.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq, mask, seg, labels, idx in dataloader:\n",
    "            # seq, labels = seq.to(device), labels.to(device)\n",
    "            # stats = np.array(train_stat.iloc[:,1:])\n",
    "            # stats = torch.tensor(stats[idx]).float()\n",
    "            #Obtaining the logits from the model\n",
    "            logits = net(seq, mask, seg)\n",
    "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
    "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
    "            count += 1\n",
    "\n",
    "    return mean_acc / count, mean_loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09e88416-c6ea-457f-94c7-be1087fc15f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "best_acc = 0\n",
    "st = time.time()\n",
    "eps = []\n",
    "t_loss = []\n",
    "d_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a32a1b2f-72a6-4f05-a43a-9d9b94694e3f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 of epoch 0 complete. \n",
      " Loss: 0.6802356839179993; Accuracy: 0.671875; Time taken (s): 81.13227605819702\n",
      "Iteration 10 of epoch 0 complete. \n",
      " Loss: 0.5898295044898987; Accuracy: 0.78125; Time taken (s): 299.43943309783936\n",
      "Iteration 20 of epoch 0 complete. \n",
      " Loss: 0.5761324763298035; Accuracy: 0.75; Time taken (s): 298.0222783088684\n",
      "Development Accuracy: 0.7715277671813965; Development Loss: 0.5319444206025865\n",
      "Iteration 0 of epoch 1 complete. \n",
      " Loss: 0.5774604678153992; Accuracy: 0.734375; Time taken (s): 220.4582164287567\n",
      "Iteration 10 of epoch 1 complete. \n",
      " Loss: 0.4819682836532593; Accuracy: 0.8125; Time taken (s): 296.9613416194916\n",
      "Iteration 20 of epoch 1 complete. \n",
      " Loss: 0.45131972432136536; Accuracy: 0.796875; Time taken (s): 297.24166321754456\n",
      "Development Accuracy: 0.7996528148651123; Development Loss: 0.43302328056759304\n",
      "Iteration 0 of epoch 2 complete. \n",
      " Loss: 0.4024360477924347; Accuracy: 0.8125; Time taken (s): 225.989727973938\n",
      "Iteration 10 of epoch 2 complete. \n",
      " Loss: 0.4486580789089203; Accuracy: 0.765625; Time taken (s): 297.42676305770874\n",
      "Iteration 20 of epoch 2 complete. \n",
      " Loss: 0.4015752673149109; Accuracy: 0.765625; Time taken (s): 302.4298474788666\n",
      "Development Accuracy: 0.7715277671813965; Development Loss: 0.40253406431939864\n",
      "Iteration 0 of epoch 3 complete. \n",
      " Loss: 0.3700542151927948; Accuracy: 0.859375; Time taken (s): 221.20544385910034\n",
      "Iteration 10 of epoch 3 complete. \n",
      " Loss: 0.3114929795265198; Accuracy: 0.875; Time taken (s): 296.1478228569031\n",
      "Iteration 20 of epoch 3 complete. \n",
      " Loss: 0.4102683663368225; Accuracy: 0.703125; Time taken (s): 297.2571277618408\n",
      "Development Accuracy: 0.7809027433395386; Development Loss: 0.3777681522899204\n",
      "Iteration 0 of epoch 4 complete. \n",
      " Loss: 0.3427141010761261; Accuracy: 0.890625; Time taken (s): 218.97034573554993\n",
      "Iteration 10 of epoch 4 complete. \n",
      " Loss: 0.3261837065219879; Accuracy: 0.859375; Time taken (s): 297.1521053314209\n",
      "Iteration 20 of epoch 4 complete. \n",
      " Loss: 0.1853872537612915; Accuracy: 1.0; Time taken (s): 297.5361819267273\n",
      "Development Accuracy: 0.8743055462837219; Development Loss: 0.3650273084640503\n",
      "Iteration 0 of epoch 5 complete. \n",
      " Loss: 0.23465262353420258; Accuracy: 0.953125; Time taken (s): 220.8443422317505\n",
      "Iteration 10 of epoch 5 complete. \n",
      " Loss: 0.2828870117664337; Accuracy: 0.90625; Time taken (s): 296.63211154937744\n",
      "Iteration 20 of epoch 5 complete. \n",
      " Loss: 0.23903009295463562; Accuracy: 0.9375; Time taken (s): 296.602587223053\n",
      "Development Accuracy: 0.8656250238418579; Development Loss: 0.31499414808220333\n",
      "Iteration 0 of epoch 6 complete. \n",
      " Loss: 0.2568912208080292; Accuracy: 0.90625; Time taken (s): 220.6560664176941\n",
      "Iteration 10 of epoch 6 complete. \n",
      " Loss: 0.247569739818573; Accuracy: 0.953125; Time taken (s): 297.4129750728607\n",
      "Iteration 20 of epoch 6 complete. \n",
      " Loss: 0.21808868646621704; Accuracy: 0.953125; Time taken (s): 303.97619438171387\n",
      "Development Accuracy: 0.8732638955116272; Development Loss: 0.384066647125615\n",
      "Iteration 0 of epoch 7 complete. \n",
      " Loss: 0.19976870715618134; Accuracy: 0.9375; Time taken (s): 220.87582063674927\n",
      "Iteration 10 of epoch 7 complete. \n",
      " Loss: 0.27573078870773315; Accuracy: 0.921875; Time taken (s): 296.1779816150665\n",
      "Iteration 20 of epoch 7 complete. \n",
      " Loss: 0.18678443133831024; Accuracy: 0.953125; Time taken (s): 297.39706158638\n",
      "Development Accuracy: 0.9340277910232544; Development Loss: 0.22147591825988558\n",
      "Iteration 0 of epoch 8 complete. \n",
      " Loss: 0.10352814942598343; Accuracy: 0.984375; Time taken (s): 220.7351589202881\n",
      "Iteration 10 of epoch 8 complete. \n",
      " Loss: 0.22030408680438995; Accuracy: 0.953125; Time taken (s): 296.3964297771454\n",
      "Iteration 20 of epoch 8 complete. \n",
      " Loss: 0.19165925681591034; Accuracy: 0.953125; Time taken (s): 296.3505527973175\n",
      "Development Accuracy: 0.9211804866790771; Development Loss: 0.24064936406082577\n",
      "Iteration 0 of epoch 9 complete. \n",
      " Loss: 0.150380939245224; Accuracy: 0.96875; Time taken (s): 218.93811440467834\n",
      "Iteration 10 of epoch 9 complete. \n",
      " Loss: 0.18152907490730286; Accuracy: 0.96875; Time taken (s): 331.6500794887543\n",
      "Iteration 20 of epoch 9 complete. \n",
      " Loss: 0.1733761727809906; Accuracy: 0.96875; Time taken (s): 296.8183481693268\n",
      "Development Accuracy: 0.9083333611488342; Development Loss: 0.22732179363568625\n",
      "Iteration 0 of epoch 10 complete. \n",
      " Loss: 0.09950870275497437; Accuracy: 0.984375; Time taken (s): 221.98526763916016\n",
      "Iteration 10 of epoch 10 complete. \n",
      " Loss: 0.09946000576019287; Accuracy: 1.0; Time taken (s): 296.6942472457886\n",
      "Iteration 20 of epoch 10 complete. \n",
      " Loss: 0.08078835904598236; Accuracy: 0.984375; Time taken (s): 297.30266857147217\n",
      "Development Accuracy: 0.9281249642372131; Development Loss: 0.22359735684262383\n",
      "Iteration 0 of epoch 11 complete. \n",
      " Loss: 0.16118431091308594; Accuracy: 0.96875; Time taken (s): 221.00080060958862\n",
      "Iteration 10 of epoch 11 complete. \n",
      " Loss: 0.18316838145256042; Accuracy: 0.96875; Time taken (s): 303.366548538208\n",
      "Iteration 20 of epoch 11 complete. \n",
      " Loss: 0.11347579956054688; Accuracy: 0.96875; Time taken (s): 297.30295848846436\n",
      "Development Accuracy: 0.9322916865348816; Development Loss: 0.20730443360904852\n",
      "Iteration 0 of epoch 12 complete. \n",
      " Loss: 0.1285964399576187; Accuracy: 0.984375; Time taken (s): 218.70448565483093\n",
      "Iteration 10 of epoch 12 complete. \n",
      " Loss: 0.11941289901733398; Accuracy: 0.984375; Time taken (s): 296.63081550598145\n",
      "Iteration 20 of epoch 12 complete. \n",
      " Loss: 0.058265190571546555; Accuracy: 1.0; Time taken (s): 297.2467796802521\n",
      "Development Accuracy: 0.9281249642372131; Development Loss: 0.25157110227478874\n",
      "Iteration 0 of epoch 13 complete. \n",
      " Loss: 0.060456059873104095; Accuracy: 0.984375; Time taken (s): 220.57226514816284\n",
      "Iteration 10 of epoch 13 complete. \n",
      " Loss: 0.1359124779701233; Accuracy: 0.96875; Time taken (s): 296.16311144828796\n",
      "Iteration 20 of epoch 13 complete. \n",
      " Loss: 0.24394303560256958; Accuracy: 0.9375; Time taken (s): 296.1930947303772\n",
      "Development Accuracy: 0.9315971732139587; Development Loss: 0.2178215417597029\n",
      "Iteration 0 of epoch 14 complete. \n",
      " Loss: 0.043951794505119324; Accuracy: 1.0; Time taken (s): 219.92360663414001\n",
      "Iteration 10 of epoch 14 complete. \n",
      " Loss: 0.03783406689763069; Accuracy: 1.0; Time taken (s): 295.7859377861023\n",
      "Iteration 20 of epoch 14 complete. \n",
      " Loss: 0.10898635536432266; Accuracy: 0.984375; Time taken (s): 295.7577893733978\n",
      "Development Accuracy: 0.9409722089767456; Development Loss: 0.2148100563014547\n",
      "Iteration 0 of epoch 15 complete. \n",
      " Loss: 0.03337579220533371; Accuracy: 1.0; Time taken (s): 220.61015558242798\n",
      "Iteration 10 of epoch 15 complete. \n",
      " Loss: 0.031077606603503227; Accuracy: 1.0; Time taken (s): 301.6768755912781\n",
      "Iteration 20 of epoch 15 complete. \n",
      " Loss: 0.030278261750936508; Accuracy: 1.0; Time taken (s): 294.6953103542328\n",
      "Development Accuracy: 0.9281249642372131; Development Loss: 0.29197897513707477\n",
      "Iteration 0 of epoch 16 complete. \n",
      " Loss: 0.18090198934078217; Accuracy: 0.96875; Time taken (s): 220.5163128376007\n",
      "Iteration 10 of epoch 16 complete. \n",
      " Loss: 0.037820782512426376; Accuracy: 1.0; Time taken (s): 294.73997259140015\n",
      "Iteration 20 of epoch 16 complete. \n",
      " Loss: 0.031452666968107224; Accuracy: 1.0; Time taken (s): 295.52116107940674\n",
      "Development Accuracy: 0.9246527552604675; Development Loss: 0.2850782523552577\n",
      "Iteration 0 of epoch 17 complete. \n",
      " Loss: 0.08480245620012283; Accuracy: 0.984375; Time taken (s): 220.00190448760986\n",
      "Iteration 10 of epoch 17 complete. \n",
      " Loss: 0.038943544030189514; Accuracy: 1.0; Time taken (s): 294.96084427833557\n",
      "Iteration 20 of epoch 17 complete. \n",
      " Loss: 0.08793707191944122; Accuracy: 0.984375; Time taken (s): 296.37982153892517\n",
      "Development Accuracy: 0.9409722089767456; Development Loss: 0.23112470884290007\n",
      "Iteration 0 of epoch 18 complete. \n",
      " Loss: 0.09463363140821457; Accuracy: 0.984375; Time taken (s): 218.76718187332153\n",
      "Iteration 10 of epoch 18 complete. \n",
      " Loss: 0.07292123138904572; Accuracy: 0.984375; Time taken (s): 297.42747044563293\n",
      "Iteration 20 of epoch 18 complete. \n",
      " Loss: 0.09867572039365768; Accuracy: 0.984375; Time taken (s): 297.27133989334106\n",
      "Development Accuracy: 0.9392361044883728; Development Loss: 0.21728208433422777\n",
      "Iteration 0 of epoch 19 complete. \n",
      " Loss: 0.085542231798172; Accuracy: 0.984375; Time taken (s): 221.0791130065918\n",
      "Iteration 10 of epoch 19 complete. \n",
      " Loss: 0.110785573720932; Accuracy: 0.984375; Time taken (s): 296.2733783721924\n",
      "Iteration 20 of epoch 19 complete. \n",
      " Loss: 0.031884439289569855; Accuracy: 1.0; Time taken (s): 303.8342869281769\n",
      "Development Accuracy: 0.9315971732139587; Development Loss: 0.25821830415063435\n"
     ]
    }
   ],
   "source": [
    "for ep in range(20):\n",
    "    eps.append(ep)\n",
    "    net.train()\n",
    "    for it, (seq, mask, seg, labels,idx) in enumerate(train_loader):\n",
    "\n",
    "        #Clear gradients\n",
    "        opti.zero_grad()\n",
    "        #Converting these to cuda tensors\n",
    "        # seq, mask, seg, labels = seq.to(device), mask.to(device), seg.to(device), labels.to(device)\n",
    "\n",
    "        # stats = np.array(train_stat.iloc[:,1:])\n",
    "        # stats = torch.tensor(stats[idx]).float()\n",
    "        #Obtaining the logits from the model\n",
    "        logits = net(seq, mask, seg)\n",
    "\n",
    "        #Computing loss\n",
    "        loss = criterion(logits.squeeze(), labels.float())\n",
    "\n",
    "        #Backpropagating the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #Optimization step\n",
    "        opti.step()\n",
    "\n",
    "        if it % 10 == 0:\n",
    "\n",
    "            acc = get_accuracy_from_logits(logits, labels)\n",
    "            print(\"Iteration {} of epoch {} complete. \\n Loss: {}; Accuracy: {}; Time taken (s): {}\".format(it, ep, loss.item(), acc, (time.time()-st)))\n",
    "            st = time.time()\n",
    "\n",
    "\n",
    "    dev_acc, dev_loss = text_evaluate(net, criterion, dev_loader, 'cpu')\n",
    "    t_loss.append(loss.item())\n",
    "    d_loss.append(dev_loss)\n",
    "    print(\"Development Accuracy: {}; Development Loss: {}\".format(dev_acc, dev_loss))\n",
    "    torch.save(net.state_dict(), 'D:\\\\bertcls_{}.dat'.format(ep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadfc51b-742c-4c70-8752-4fb30faf7ba8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Text Only Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47479f40-9744-4907-87fa-6a1d151aa79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = TextRumorClassifier()\n",
    "text_model.load_state_dict(torch.load('D:\\\\bertcls_14.dat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a20adf9e-5a46-40e8-b365-bc0e52ad1397",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet = pd.read_csv('./sep_data/test_tweet_df.csv')\n",
    "test_stat = pd.read_csv('./sep_data/test_stat_feat_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20176d53-9f25-43b5-bf3d-1bb0279eb141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/558 [00:00<?, ?it/s]C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_6104\\3174842241.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_tweet.text.iloc[i] = '[CLS] ' + str(test_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(test_tweet.reply_text.iloc[i]).strip()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 558/558 [00:08<00:00, 68.94it/s]\n"
     ]
    }
   ],
   "source": [
    "test_tweet.text.fillna('', inplace=True)\n",
    "test_tweet.reply_text.fillna('', inplace=True)\n",
    "for i in tqdm(range(len(test_tweet))):\n",
    "    test_tweet.text.iloc[i] = '[CLS] ' + str(test_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(test_tweet.reply_text.iloc[i]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4afdab8d-8f34-4e24-999d-517f8407b5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 558/558 [00:02<00:00, 270.06it/s]\n"
     ]
    }
   ],
   "source": [
    "max_len = 256\n",
    "test_seq = []\n",
    "test_mask = []\n",
    "test_seg = []\n",
    "\n",
    "for i in tqdm(range(len(test_tweet))):\n",
    "    try:\n",
    "        txt = test_tweet.text.iloc[i]\n",
    "        tokens = tokenizer.tokenize(txt)\n",
    "        if len(tokens) < max_len:\n",
    "             padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "        else:\n",
    "            padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "        attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "        seg_ids = []\n",
    "        seg_idx = 0\n",
    "        for token in padded_tokens:\n",
    "            seg_ids.append(seg_idx)\n",
    "            if token == '[SEP]':\n",
    "                seg_idx += 1\n",
    "        token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "\n",
    "        test_seq.append(token_ids)\n",
    "        test_mask.append(attn_mask)\n",
    "        test_seg.append(seg_ids)\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5521f55-9298-4586-ba4f-cb65883f31b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 558/558 [02:19<00:00,  4.01it/s]\n"
     ]
    }
   ],
   "source": [
    "text_model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_seq))):\n",
    "        seq = torch.tensor(test_seq[i]).unsqueeze(0)\n",
    "        mask = torch.tensor(test_mask[i]).unsqueeze(0)\n",
    "        seg = torch.tensor(test_seg[i]).unsqueeze(0)\n",
    "        \n",
    "        preds.append(text_model(seq,mask,seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d823e06d-a924-40a0-b4c4-610f79be8a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(preds)):\n",
    "    preds[i] = preds[i].squeeze().squeeze()\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    preds[i] = preds[i].numpy()\n",
    "\n",
    "predictions = preds[0]\n",
    "for i in range(1,len(preds)):\n",
    "    predictions = np.hstack((predictions,preds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5abe73fe-7769-40ed-858e-3ad1d862f41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {'Id':[i for i in range(len(predictions))], 'Predicted':predictions}\n",
    "pred_df = DataFrame(pred_dict)\n",
    "pred_df.Predicted = pred_df.Predicted.apply(lambda x: 1 if x > 0.5 else 0)\n",
    "pred_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f622652f-5545-4a44-8e17-4581e9852eff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### BERT TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1a22695-b546-4db3-b35f-dc59b70ef88c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RumorClassifier()\n",
    "model.load_state_dict(torch.load('D:\\\\bertcls_10.dat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "260e407b-3dfe-4c14-bfc0-9e2f4c3ae50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development F1: 0.7892376681614348; Development Loss: 0.27994822296831345\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "dev_acc, dev_loss = evaluate(model, criterion, dev_loader, 'cpu')\n",
    "print(\"Development F1: {}; Development Loss: {}\".format(dev_acc, dev_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "00683eb0-e793-4e20-8d29-d8a9530783db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_tweet = pd.read_csv('./sep_data/test_tweet_df.csv')\n",
    "test_stat = pd.read_csv('./sep_data/test_scaled_stat_feat_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a50c9a8c-f5e2-45a8-9f64-94331ce0dc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>reply_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1246482832316301319</td>\n",
       "      <td>covid spread txhdeupetg iyyirwcksp</td>\n",
       "      <td>thank wcco station trust media provid true new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1252279738099433473</td>\n",
       "      <td>hate keep say capit implod without zlzlcroxzl</td>\n",
       "      <td>believ look chang week [SEP] tell peopl protes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1236050255394877440</td>\n",
       "      <td>covid influenza virus differ coronaviru cpraumngq</td>\n",
       "      <td>covid influenza virus similar coronaviru [SEP]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1235582115900796928</td>\n",
       "      <td>una de le q coronavirus de la pàgina web de q ...</td>\n",
       "      <td>aquesta informació es basa sobr tot en un arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1258787515592572928</td>\n",
       "      <td>absolut blame politician whoever els involv ho...</td>\n",
       "      <td>forget racism institut peopl xuwlvqspdi [SEP] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>518827403452637184</td>\n",
       "      <td>hewlett packard plan split two compani wsj rep...</td>\n",
       "      <td>heward packlett [SEP] hewlett packard plan spl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>489829414704648192</td>\n",
       "      <td>http http qygkkjftiw</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>580348081100734464</td>\n",
       "      <td>germanw sorri confirm passeng crew board fligh...</td>\n",
       "      <td>sad news germanw sorri confirm passeng crew bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1248121143808098305</td>\n",
       "      <td>sure differ path mean differ</td>\n",
       "      <td>sometim still stop track believ insulin free w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1258487399014858752</td>\n",
       "      <td>depend get drive vehicl alreadi gass iigtbtqtlq</td>\n",
       "      <td>mayb miss someth would unsaf famili go away da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1246482832316301319                 covid spread txhdeupetg iyyirwcksp   \n",
       "1  1252279738099433473      hate keep say capit implod without zlzlcroxzl   \n",
       "2  1236050255394877440  covid influenza virus differ coronaviru cpraumngq   \n",
       "3  1235582115900796928  una de le q coronavirus de la pàgina web de q ...   \n",
       "4  1258787515592572928  absolut blame politician whoever els involv ho...   \n",
       "5   518827403452637184  hewlett packard plan split two compani wsj rep...   \n",
       "6   489829414704648192                               http http qygkkjftiw   \n",
       "7   580348081100734464  germanw sorri confirm passeng crew board fligh...   \n",
       "8  1248121143808098305                       sure differ path mean differ   \n",
       "9  1258487399014858752    depend get drive vehicl alreadi gass iigtbtqtlq   \n",
       "\n",
       "                                          reply_text  \n",
       "0  thank wcco station trust media provid true new...  \n",
       "1  believ look chang week [SEP] tell peopl protes...  \n",
       "2  covid influenza virus similar coronaviru [SEP]...  \n",
       "3  aquesta informació es basa sobr tot en un arti...  \n",
       "4  forget racism institut peopl xuwlvqspdi [SEP] ...  \n",
       "5  heward packlett [SEP] hewlett packard plan spl...  \n",
       "6                                                NaN  \n",
       "7  sad news germanw sorri confirm passeng crew bo...  \n",
       "8  sometim still stop track believ insulin free w...  \n",
       "9  mayb miss someth would unsaf famili go away da...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9e8d702b-131a-4018-8c63-dd9ad312693a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reply_possibly_sensitive</th>\n",
       "      <th>reply_retweet_count</th>\n",
       "      <th>reply_favorite_count</th>\n",
       "      <th>reply_mentioned_url_num</th>\n",
       "      <th>reply_id_num</th>\n",
       "      <th>reply_followers_count</th>\n",
       "      <th>reply_friends_count</th>\n",
       "      <th>reply_listed_count</th>\n",
       "      <th>reply_favourites_count</th>\n",
       "      <th>reply_statuses_count</th>\n",
       "      <th>...</th>\n",
       "      <th>truncated</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>geo_enabled</th>\n",
       "      <th>verified</th>\n",
       "      <th>isweekday</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>is_translation_enabled</th>\n",
       "      <th>has_extended_profile</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.146906</td>\n",
       "      <td>-0.048668</td>\n",
       "      <td>-0.039520</td>\n",
       "      <td>-0.359423</td>\n",
       "      <td>-0.352452</td>\n",
       "      <td>-0.125729</td>\n",
       "      <td>-0.430135</td>\n",
       "      <td>-0.142861</td>\n",
       "      <td>-0.468949</td>\n",
       "      <td>-0.439718</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.954789</td>\n",
       "      <td>-0.152745</td>\n",
       "      <td>0.929638</td>\n",
       "      <td>1.251990</td>\n",
       "      <td>-1.722596</td>\n",
       "      <td>-0.504152</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>-0.722953</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.146906</td>\n",
       "      <td>-0.048668</td>\n",
       "      <td>-0.039520</td>\n",
       "      <td>-0.040946</td>\n",
       "      <td>-0.217940</td>\n",
       "      <td>-0.125330</td>\n",
       "      <td>-0.260658</td>\n",
       "      <td>-0.140310</td>\n",
       "      <td>0.020302</td>\n",
       "      <td>-0.205033</td>\n",
       "      <td>...</td>\n",
       "      <td>1.047352</td>\n",
       "      <td>-0.152745</td>\n",
       "      <td>-1.075688</td>\n",
       "      <td>-0.798728</td>\n",
       "      <td>0.580519</td>\n",
       "      <td>-0.193920</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>-0.722953</td>\n",
       "      <td>1.392986</td>\n",
       "      <td>-0.050395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.146906</td>\n",
       "      <td>-0.048668</td>\n",
       "      <td>-0.039468</td>\n",
       "      <td>-0.279803</td>\n",
       "      <td>-0.374870</td>\n",
       "      <td>-0.123518</td>\n",
       "      <td>-0.428935</td>\n",
       "      <td>-0.139435</td>\n",
       "      <td>-0.466908</td>\n",
       "      <td>-0.436924</td>\n",
       "      <td>...</td>\n",
       "      <td>1.047352</td>\n",
       "      <td>-0.152745</td>\n",
       "      <td>0.929638</td>\n",
       "      <td>-0.798728</td>\n",
       "      <td>0.580519</td>\n",
       "      <td>-0.452447</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>-0.722953</td>\n",
       "      <td>1.392986</td>\n",
       "      <td>-0.050395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.146906</td>\n",
       "      <td>-0.048530</td>\n",
       "      <td>-0.039417</td>\n",
       "      <td>-0.200184</td>\n",
       "      <td>-0.374870</td>\n",
       "      <td>-0.125684</td>\n",
       "      <td>-0.424884</td>\n",
       "      <td>-0.142752</td>\n",
       "      <td>-0.468983</td>\n",
       "      <td>-0.439474</td>\n",
       "      <td>...</td>\n",
       "      <td>1.047352</td>\n",
       "      <td>-0.152745</td>\n",
       "      <td>-1.075688</td>\n",
       "      <td>-0.798728</td>\n",
       "      <td>0.580519</td>\n",
       "      <td>-0.400741</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>1.383215</td>\n",
       "      <td>1.392986</td>\n",
       "      <td>-0.050395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.146906</td>\n",
       "      <td>-0.047841</td>\n",
       "      <td>-0.039365</td>\n",
       "      <td>0.038673</td>\n",
       "      <td>-0.195521</td>\n",
       "      <td>-0.125523</td>\n",
       "      <td>-0.313216</td>\n",
       "      <td>-0.142570</td>\n",
       "      <td>-0.307555</td>\n",
       "      <td>-0.358209</td>\n",
       "      <td>...</td>\n",
       "      <td>1.047352</td>\n",
       "      <td>-0.152745</td>\n",
       "      <td>0.929638</td>\n",
       "      <td>-0.798728</td>\n",
       "      <td>0.580519</td>\n",
       "      <td>-0.245625</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>1.383215</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>0.823597</td>\n",
       "      <td>-0.048530</td>\n",
       "      <td>-0.039442</td>\n",
       "      <td>0.755244</td>\n",
       "      <td>0.252850</td>\n",
       "      <td>-0.123699</td>\n",
       "      <td>0.153559</td>\n",
       "      <td>-0.098318</td>\n",
       "      <td>0.214535</td>\n",
       "      <td>0.045030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.954789</td>\n",
       "      <td>-0.152745</td>\n",
       "      <td>0.929638</td>\n",
       "      <td>1.251990</td>\n",
       "      <td>0.580519</td>\n",
       "      <td>0.788482</td>\n",
       "      <td>2.736649</td>\n",
       "      <td>-0.722953</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>-0.146906</td>\n",
       "      <td>-0.048530</td>\n",
       "      <td>-0.039184</td>\n",
       "      <td>-0.200184</td>\n",
       "      <td>1.194431</td>\n",
       "      <td>-0.117722</td>\n",
       "      <td>0.571502</td>\n",
       "      <td>-0.100140</td>\n",
       "      <td>0.816771</td>\n",
       "      <td>0.688410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.954789</td>\n",
       "      <td>-0.152745</td>\n",
       "      <td>0.929638</td>\n",
       "      <td>1.251990</td>\n",
       "      <td>-1.722596</td>\n",
       "      <td>2.649876</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>1.383215</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>-0.146906</td>\n",
       "      <td>-0.048530</td>\n",
       "      <td>-0.039494</td>\n",
       "      <td>-0.200184</td>\n",
       "      <td>-0.061010</td>\n",
       "      <td>-0.123979</td>\n",
       "      <td>-0.051749</td>\n",
       "      <td>-0.121355</td>\n",
       "      <td>-0.254072</td>\n",
       "      <td>-0.131456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.954789</td>\n",
       "      <td>-0.152745</td>\n",
       "      <td>-1.075688</td>\n",
       "      <td>1.251990</td>\n",
       "      <td>0.580519</td>\n",
       "      <td>-0.038804</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>-0.722953</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>-0.146906</td>\n",
       "      <td>-0.041774</td>\n",
       "      <td>-0.036267</td>\n",
       "      <td>-0.200184</td>\n",
       "      <td>0.320106</td>\n",
       "      <td>1.855980</td>\n",
       "      <td>-0.329794</td>\n",
       "      <td>2.296395</td>\n",
       "      <td>-0.404845</td>\n",
       "      <td>-0.319952</td>\n",
       "      <td>...</td>\n",
       "      <td>1.047352</td>\n",
       "      <td>-0.152745</td>\n",
       "      <td>0.929638</td>\n",
       "      <td>1.251990</td>\n",
       "      <td>0.580519</td>\n",
       "      <td>-0.349036</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>1.383215</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>-0.146906</td>\n",
       "      <td>-0.048392</td>\n",
       "      <td>-0.039468</td>\n",
       "      <td>-0.279803</td>\n",
       "      <td>-0.352452</td>\n",
       "      <td>-0.125410</td>\n",
       "      <td>-0.380977</td>\n",
       "      <td>-0.142715</td>\n",
       "      <td>-0.349507</td>\n",
       "      <td>-0.406812</td>\n",
       "      <td>...</td>\n",
       "      <td>1.047352</td>\n",
       "      <td>-0.152745</td>\n",
       "      <td>-1.075688</td>\n",
       "      <td>-0.798728</td>\n",
       "      <td>-1.722596</td>\n",
       "      <td>-0.452447</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>-0.722953</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     reply_possibly_sensitive  reply_retweet_count  reply_favorite_count  \\\n",
       "0                   -0.146906            -0.048668             -0.039520   \n",
       "1                   -0.146906            -0.048668             -0.039520   \n",
       "2                   -0.146906            -0.048668             -0.039468   \n",
       "3                   -0.146906            -0.048530             -0.039417   \n",
       "4                   -0.146906            -0.047841             -0.039365   \n",
       "..                        ...                  ...                   ...   \n",
       "553                  0.823597            -0.048530             -0.039442   \n",
       "554                 -0.146906            -0.048530             -0.039184   \n",
       "555                 -0.146906            -0.048530             -0.039494   \n",
       "556                 -0.146906            -0.041774             -0.036267   \n",
       "557                 -0.146906            -0.048392             -0.039468   \n",
       "\n",
       "     reply_mentioned_url_num  reply_id_num  reply_followers_count  \\\n",
       "0                  -0.359423     -0.352452              -0.125729   \n",
       "1                  -0.040946     -0.217940              -0.125330   \n",
       "2                  -0.279803     -0.374870              -0.123518   \n",
       "3                  -0.200184     -0.374870              -0.125684   \n",
       "4                   0.038673     -0.195521              -0.125523   \n",
       "..                       ...           ...                    ...   \n",
       "553                 0.755244      0.252850              -0.123699   \n",
       "554                -0.200184      1.194431              -0.117722   \n",
       "555                -0.200184     -0.061010              -0.123979   \n",
       "556                -0.200184      0.320106               1.855980   \n",
       "557                -0.279803     -0.352452              -0.125410   \n",
       "\n",
       "     reply_friends_count  reply_listed_count  reply_favourites_count  \\\n",
       "0              -0.430135           -0.142861               -0.468949   \n",
       "1              -0.260658           -0.140310                0.020302   \n",
       "2              -0.428935           -0.139435               -0.466908   \n",
       "3              -0.424884           -0.142752               -0.468983   \n",
       "4              -0.313216           -0.142570               -0.307555   \n",
       "..                   ...                 ...                     ...   \n",
       "553             0.153559           -0.098318                0.214535   \n",
       "554             0.571502           -0.100140                0.816771   \n",
       "555            -0.051749           -0.121355               -0.254072   \n",
       "556            -0.329794            2.296395               -0.404845   \n",
       "557            -0.380977           -0.142715               -0.349507   \n",
       "\n",
       "     reply_statuses_count  ...  truncated  is_quote_status  geo_enabled  \\\n",
       "0               -0.439718  ...  -0.954789        -0.152745     0.929638   \n",
       "1               -0.205033  ...   1.047352        -0.152745    -1.075688   \n",
       "2               -0.436924  ...   1.047352        -0.152745     0.929638   \n",
       "3               -0.439474  ...   1.047352        -0.152745    -1.075688   \n",
       "4               -0.358209  ...   1.047352        -0.152745     0.929638   \n",
       "..                    ...  ...        ...              ...          ...   \n",
       "553              0.045030  ...  -0.954789        -0.152745     0.929638   \n",
       "554              0.688410  ...  -0.954789        -0.152745     0.929638   \n",
       "555             -0.131456  ...  -0.954789        -0.152745    -1.075688   \n",
       "556             -0.319952  ...   1.047352        -0.152745     0.929638   \n",
       "557             -0.406812  ...   1.047352        -0.152745    -1.075688   \n",
       "\n",
       "     verified  isweekday  reply_count  is_translation_enabled  \\\n",
       "0    1.251990  -1.722596    -0.504152               -0.365410   \n",
       "1   -0.798728   0.580519    -0.193920               -0.365410   \n",
       "2   -0.798728   0.580519    -0.452447               -0.365410   \n",
       "3   -0.798728   0.580519    -0.400741               -0.365410   \n",
       "4   -0.798728   0.580519    -0.245625               -0.365410   \n",
       "..        ...        ...          ...                     ...   \n",
       "553  1.251990   0.580519     0.788482                2.736649   \n",
       "554  1.251990  -1.722596     2.649876               -0.365410   \n",
       "555  1.251990   0.580519    -0.038804               -0.365410   \n",
       "556  1.251990   0.580519    -0.349036               -0.365410   \n",
       "557 -0.798728  -1.722596    -0.452447               -0.365410   \n",
       "\n",
       "     has_extended_profile  default_profile  default_profile_image  \n",
       "0               -0.722953        -0.717882              -0.050395  \n",
       "1               -0.722953         1.392986              -0.050395  \n",
       "2               -0.722953         1.392986              -0.050395  \n",
       "3                1.383215         1.392986              -0.050395  \n",
       "4                1.383215        -0.717882              -0.050395  \n",
       "..                    ...              ...                    ...  \n",
       "553             -0.722953        -0.717882              -0.050395  \n",
       "554              1.383215        -0.717882              -0.050395  \n",
       "555             -0.722953        -0.717882              -0.050395  \n",
       "556              1.383215        -0.717882              -0.050395  \n",
       "557             -0.722953        -0.717882              -0.050395  \n",
       "\n",
       "[558 rows x 43 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stat.drop(columns=train_zero, inplace=True)\n",
    "test_stat.drop(columns=['Unnamed: 0', 'contributors'], inplace=True)\n",
    "test_stat.fillna(train_stat.mean(), inplace=True)\n",
    "test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9f29bdc2-5848-4d0f-8339-b2f69fcc0b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 558 entries, 0 to 557\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_id    558 non-null    int64 \n",
      " 1   text        556 non-null    object\n",
      " 2   reply_text  545 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 13.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c7e3d74d-9603-4dec-b820-cbc49488afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet.text.fillna('', inplace=True)\n",
    "test_tweet.reply_text.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a1069919-5425-4456-9ac5-159877e11660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/558 [00:00<?, ?it/s]C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_2812\\3420928069.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_tweet.text.iloc[i] = '[CLS] ' + str(test_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(test_tweet.reply_text.iloc[i]).strip() + ' [SEP]'\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 558/558 [00:07<00:00, 71.60it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(test_tweet))):\n",
    "    test_tweet.text.iloc[i] = '[CLS] ' + str(test_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(test_tweet.reply_text.iloc[i]).strip() + ' [SEP]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ca68fd5e-aee4-4c2c-917a-43293615b737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 558/558 [00:01<00:00, 285.87it/s]\n"
     ]
    }
   ],
   "source": [
    "max_len = 256\n",
    "test_seq = []\n",
    "test_mask = []\n",
    "test_seg = []\n",
    "\n",
    "for i in tqdm(range(len(test_tweet))):\n",
    "    try:\n",
    "        txt = test_tweet.text.iloc[i]\n",
    "        tokens = tokenizer.tokenize(txt)\n",
    "        if len(tokens) < max_len:\n",
    "             padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "        else:\n",
    "            padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "        attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "        seg_ids = []\n",
    "        seg_idx = 0\n",
    "        for token in padded_tokens:\n",
    "            seg_ids.append(seg_idx)\n",
    "            if token == '[SEP]':\n",
    "                seg_idx += 1\n",
    "        token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "\n",
    "        test_seq.append(token_ids)\n",
    "        test_mask.append(attn_mask)\n",
    "        test_seg.append(seg_ids)\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d9e8b069-72a0-483b-80ef-5b9b0144f168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 558 entries, 0 to 557\n",
      "Data columns (total 43 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   reply_possibly_sensitive      558 non-null    float64\n",
      " 1   reply_retweet_count           558 non-null    float64\n",
      " 2   reply_favorite_count          558 non-null    float64\n",
      " 3   reply_mentioned_url_num       558 non-null    float64\n",
      " 4   reply_id_num                  558 non-null    float64\n",
      " 5   reply_followers_count         558 non-null    float64\n",
      " 6   reply_friends_count           558 non-null    float64\n",
      " 7   reply_listed_count            558 non-null    float64\n",
      " 8   reply_favourites_count        558 non-null    float64\n",
      " 9   reply_statuses_count          558 non-null    float64\n",
      " 10  reply_has_url                 558 non-null    float64\n",
      " 11  reply_senti_score             558 non-null    float64\n",
      " 12  reply_truncated               558 non-null    float64\n",
      " 13  reply_is_quote_status         558 non-null    float64\n",
      " 14  reply_geo_enabled             558 non-null    float64\n",
      " 15  reply_verified                558 non-null    float64\n",
      " 16  reply_isweekday               558 non-null    float64\n",
      " 17  reply_is_translation_enabled  558 non-null    float64\n",
      " 18  reply_has_extended_profile    558 non-null    float64\n",
      " 19  reply_default_profile         558 non-null    float64\n",
      " 20  reply_default_profile_image   558 non-null    float64\n",
      " 21  possibly_sensitive            558 non-null    float64\n",
      " 22  retweet_count                 558 non-null    float64\n",
      " 23  favorite_count                558 non-null    float64\n",
      " 24  mentioned_url_num             558 non-null    float64\n",
      " 25  id_num                        558 non-null    float64\n",
      " 26  followers_count               558 non-null    float64\n",
      " 27  friends_count                 558 non-null    float64\n",
      " 28  listed_count                  558 non-null    float64\n",
      " 29  favourites_count              558 non-null    float64\n",
      " 30  statuses_count                558 non-null    float64\n",
      " 31  has_url                       558 non-null    float64\n",
      " 32  senti_score                   558 non-null    float64\n",
      " 33  truncated                     558 non-null    float64\n",
      " 34  is_quote_status               558 non-null    float64\n",
      " 35  geo_enabled                   558 non-null    float64\n",
      " 36  verified                      558 non-null    float64\n",
      " 37  isweekday                     558 non-null    float64\n",
      " 38  reply_count                   558 non-null    float64\n",
      " 39  is_translation_enabled        558 non-null    float64\n",
      " 40  has_extended_profile          558 non-null    float64\n",
      " 41  default_profile               558 non-null    float64\n",
      " 42  default_profile_image         558 non-null    float64\n",
      "dtypes: float64(43)\n",
      "memory usage: 187.6 KB\n"
     ]
    }
   ],
   "source": [
    "test_stat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c8cbb8e-eee5-4b5c-86a5-2e0c90d1e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TestTweetDataset(Data.Dataset):\n",
    "#     def __init__(self, seq, mask, seg, stat):\n",
    "#         self.seq = torch.tensor(seq).long()\n",
    "#         self.mask = torch.tensor(mask).long()\n",
    "#         self.seg = torch.tensor(seg).long()\n",
    "#         self.stat = torch.tensor(stat).float()\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return self.seq.shape[0]\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.seq[idx],self.mask[idx],self.seg[idx], self.stat[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dac9a35a-5c60-4c32-971f-45a71480dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set = TestTweetDataset(test_seq, test_mask, test_seg, np.array(test_stat)[:,1:])\n",
    "# test_loader = Data.DataLoader(test_set, batch_size=32, shuffle=False, sampler=range(0,len(test_seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "312437ab-3532-449c-b63a-f77446597e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 558/558 [02:32<00:00,  3.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# import gc\n",
    "test_stat = np.array(test_stat)\n",
    "model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_seq))):\n",
    "        seq = torch.tensor(test_seq[i]).unsqueeze(0)\n",
    "        mask = torch.tensor(test_mask[i]).unsqueeze(0)\n",
    "        seg = torch.tensor(test_seg[i]).unsqueeze(0)\n",
    "        stat = torch.tensor(test_stat[i]).unsqueeze(0).float()\n",
    "        \n",
    "        preds.append(model(seq,mask,seg,stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "241ffe91-d5aa-4a3d-b66c-c739dd44f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(preds)):\n",
    "    preds[i] = preds[i].squeeze().squeeze()\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    preds[i] = preds[i].numpy()\n",
    "\n",
    "predictions = preds[0]\n",
    "for i in range(1,len(preds)):\n",
    "    predictions = np.hstack((predictions,preds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5e2c52ee-7db7-478b-8f67-bd7bf181764a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02049624, 0.05445008, 0.02042949, 0.02056108, 0.02043151,\n",
       "       0.6367259 , 0.03160333, 0.94592416, 0.01913229, 0.02037117,\n",
       "       0.9427211 , 0.93712544, 0.02052529, 0.02272073, 0.0202749 ,\n",
       "       0.02022082, 0.02190769, 0.02063054, 0.02045906, 0.02037625,\n",
       "       0.02095678, 0.02002073, 0.02025568, 0.94961464, 0.02098784,\n",
       "       0.02080244, 0.02038865, 0.19152975, 0.01953135, 0.94778734,\n",
       "       0.0203169 , 0.9439094 , 0.94616413, 0.02030841, 0.0202613 ,\n",
       "       0.02026968, 0.02006708, 0.0205175 , 0.02022131, 0.83791745,\n",
       "       0.02134744, 0.9369296 , 0.08428477, 0.668969  , 0.02119573,\n",
       "       0.0214751 , 0.0205654 , 0.02059297, 0.02029761, 0.02050123,\n",
       "       0.02062349, 0.02057444, 0.9496354 , 0.04388975, 0.02049617,\n",
       "       0.02180096, 0.9429223 , 0.02017157, 0.02063694, 0.02034412,\n",
       "       0.02007296, 0.05002595, 0.02005405, 0.02053064, 0.02052143,\n",
       "       0.02008709, 0.91779184, 0.94577414, 0.02024087, 0.02159186,\n",
       "       0.02040663, 0.02024384, 0.02026526, 0.94199544, 0.01882024,\n",
       "       0.88714397, 0.02044961, 0.94469583, 0.94232595, 0.02090957,\n",
       "       0.83420527, 0.02029525, 0.94746524, 0.01993305, 0.9456329 ,\n",
       "       0.02026398, 0.02045953, 0.02026962, 0.02054206, 0.02043874,\n",
       "       0.0209965 , 0.02027675, 0.01987721, 0.02042723, 0.0197051 ,\n",
       "       0.02287537, 0.02033387, 0.02013185, 0.7673419 , 0.02015077,\n",
       "       0.02017635, 0.02313556, 0.02040131, 0.9465498 , 0.02014583,\n",
       "       0.02035022, 0.79966366, 0.02323794, 0.02118922, 0.9428093 ,\n",
       "       0.9323657 , 0.02225022, 0.02011719, 0.0198354 , 0.3133285 ,\n",
       "       0.02475654, 0.02069119, 0.02031453, 0.02092707, 0.02119539,\n",
       "       0.945981  , 0.0201499 , 0.02091123, 0.02120354, 0.02019731,\n",
       "       0.94626254, 0.94835275, 0.9405172 , 0.02062747, 0.948065  ,\n",
       "       0.02113837, 0.02122893, 0.02364665, 0.02020346, 0.02036919,\n",
       "       0.0251653 , 0.02010449, 0.9431925 , 0.02084833, 0.01999902,\n",
       "       0.04170527, 0.02114387, 0.944173  , 0.02022371, 0.9401076 ,\n",
       "       0.0204784 , 0.02077519, 0.93310577, 0.02010215, 0.02017322,\n",
       "       0.0199301 , 0.6868439 , 0.02165286, 0.02041816, 0.9300535 ,\n",
       "       0.94349444, 0.02130094, 0.02014597, 0.9465804 , 0.01890077,\n",
       "       0.9459105 , 0.9410437 , 0.02229418, 0.02047256, 0.02218375,\n",
       "       0.02017595, 0.02276982, 0.02025216, 0.01931921, 0.02100648,\n",
       "       0.02012876, 0.94719213, 0.0204959 , 0.9400235 , 0.9418766 ,\n",
       "       0.02074969, 0.14427215, 0.02027821, 0.02035705, 0.02071076,\n",
       "       0.02012433, 0.02044155, 0.02033643, 0.02359623, 0.02158738,\n",
       "       0.0202726 , 0.02099598, 0.02015477, 0.9448536 , 0.04766282,\n",
       "       0.02855328, 0.01999575, 0.02054162, 0.02023568, 0.02001706,\n",
       "       0.0211162 , 0.42786297, 0.02019534, 0.02043681, 0.01878949,\n",
       "       0.02084528, 0.4641371 , 0.0204047 , 0.02014316, 0.93382627,\n",
       "       0.02026773, 0.6982802 , 0.02029784, 0.02054793, 0.01887619,\n",
       "       0.0266127 , 0.9425247 , 0.9411818 , 0.08590345, 0.95671064,\n",
       "       0.02137242, 0.02085879, 0.0204893 , 0.94135517, 0.14068903,\n",
       "       0.02040514, 0.84036446, 0.02024009, 0.02020479, 0.0214153 ,\n",
       "       0.01999961, 0.02013904, 0.02117686, 0.02009001, 0.02037718,\n",
       "       0.02017378, 0.02100779, 0.02069782, 0.02002453, 0.02038884,\n",
       "       0.02049778, 0.0201317 , 0.9451411 , 0.02018032, 0.94731873,\n",
       "       0.02036274, 0.02311649, 0.0205031 , 0.02017944, 0.02294254,\n",
       "       0.01999415, 0.02005011, 0.02045633, 0.02082144, 0.02031068,\n",
       "       0.02053145, 0.02021019, 0.94173956, 0.0207087 , 0.02006917,\n",
       "       0.02011182, 0.02363565, 0.9273431 , 0.01973717, 0.02025567,\n",
       "       0.02325288, 0.0229464 , 0.02151245, 0.0201692 , 0.02012524,\n",
       "       0.02129432, 0.02213254, 0.02018724, 0.9448269 , 0.02026124,\n",
       "       0.01981439, 0.9473545 , 0.02123616, 0.9399544 , 0.02024058,\n",
       "       0.9405431 , 0.02023617, 0.9448498 , 0.02015215, 0.02021838,\n",
       "       0.02153262, 0.02111916, 0.0201188 , 0.94900304, 0.93198377,\n",
       "       0.02008845, 0.02020966, 0.02023372, 0.94265664, 0.02005211,\n",
       "       0.02174317, 0.020184  , 0.9482401 , 0.02005527, 0.94101155,\n",
       "       0.02049851, 0.02012012, 0.02022685, 0.020223  , 0.02011683,\n",
       "       0.02365537, 0.02042603, 0.93596107, 0.94660425, 0.02037423,\n",
       "       0.02088735, 0.0200488 , 0.0218095 , 0.02207708, 0.02363355,\n",
       "       0.02030168, 0.02007495, 0.0201745 , 0.56237626, 0.019969  ,\n",
       "       0.02041706, 0.02017323, 0.02290083, 0.02582099, 0.02025689,\n",
       "       0.9467175 , 0.02017068, 0.9449885 , 0.19649062, 0.94356924,\n",
       "       0.02023402, 0.02035931, 0.02031898, 0.02014089, 0.02127417,\n",
       "       0.02004212, 0.02151536, 0.02062708, 0.02144285, 0.02033823,\n",
       "       0.94920665, 0.02030247, 0.9451809 , 0.02223092, 0.95202   ,\n",
       "       0.02454775, 0.02399241, 0.02392893, 0.01879253, 0.02020807,\n",
       "       0.9462585 , 0.94379103, 0.02044429, 0.0189057 , 0.02086586,\n",
       "       0.9482162 , 0.9518909 , 0.9470602 , 0.02011404, 0.0210655 ,\n",
       "       0.17796282, 0.02015321, 0.02041386, 0.9421247 , 0.02009687,\n",
       "       0.02022878, 0.02034342, 0.94295937, 0.0204611 , 0.02080833,\n",
       "       0.02048936, 0.02048969, 0.02041542, 0.9458892 , 0.02009464,\n",
       "       0.02015474, 0.02042827, 0.94469   , 0.94576347, 0.02040562,\n",
       "       0.40255332, 0.02018552, 0.02063526, 0.94551253, 0.02022378,\n",
       "       0.04104973, 0.02011191, 0.94156194, 0.02059411, 0.9459455 ,\n",
       "       0.02056945, 0.02019796, 0.02016851, 0.02093164, 0.94784003,\n",
       "       0.0208507 , 0.02025145, 0.02084851, 0.9493064 , 0.02308478,\n",
       "       0.02025995, 0.02099909, 0.02310863, 0.01986071, 0.02187207,\n",
       "       0.8896022 , 0.06284465, 0.02000533, 0.9367722 , 0.0202007 ,\n",
       "       0.02012259, 0.942987  , 0.02376472, 0.020196  , 0.02065907,\n",
       "       0.02128115, 0.9407031 , 0.94518614, 0.02041928, 0.9504133 ,\n",
       "       0.9420292 , 0.02076704, 0.02090103, 0.02029306, 0.01992552,\n",
       "       0.02201517, 0.0304485 , 0.9474586 , 0.16413991, 0.94286734,\n",
       "       0.022617  , 0.02029681, 0.3980352 , 0.02024723, 0.02038285,\n",
       "       0.02322905, 0.2996294 , 0.02272313, 0.01990258, 0.02059593,\n",
       "       0.02003896, 0.02071187, 0.02047152, 0.02092734, 0.94709074,\n",
       "       0.02035979, 0.880229  , 0.02080078, 0.02026393, 0.02094656,\n",
       "       0.02058262, 0.94212264, 0.02014104, 0.0203184 , 0.02350852,\n",
       "       0.02538477, 0.02035993, 0.02102903, 0.0204148 , 0.02133966,\n",
       "       0.93606704, 0.02022536, 0.05309305, 0.02032308, 0.02117189,\n",
       "       0.02036803, 0.02030896, 0.02634447, 0.02009868, 0.02006223,\n",
       "       0.0202843 , 0.02201436, 0.02066752, 0.02263201, 0.02058984,\n",
       "       0.02017975, 0.02055236, 0.02020074, 0.02029734, 0.94348115,\n",
       "       0.93941927, 0.94477445, 0.02069249, 0.0225795 , 0.02014296,\n",
       "       0.02035847, 0.02138228, 0.02030919, 0.02036159, 0.02028542,\n",
       "       0.02021447, 0.95098096, 0.02064286, 0.02015675, 0.02003317,\n",
       "       0.02015426, 0.02119829, 0.9438348 , 0.02116068, 0.02015904,\n",
       "       0.02003807, 0.02961351, 0.0201609 , 0.0207187 , 0.18855864,\n",
       "       0.02024003, 0.9406284 , 0.02057983, 0.12243063, 0.02003327,\n",
       "       0.02670427, 0.94438636, 0.02078078, 0.01994141, 0.01998861,\n",
       "       0.02038864, 0.78859216, 0.02025666, 0.05248811, 0.9435824 ,\n",
       "       0.02401862, 0.9415596 , 0.02235272, 0.9457797 , 0.02043478,\n",
       "       0.02024562, 0.02035306, 0.02024359, 0.94090843, 0.02011321,\n",
       "       0.02578013, 0.02018691, 0.09962283, 0.01999131, 0.04589485,\n",
       "       0.0202348 , 0.02020448, 0.02033678, 0.950842  , 0.94345784,\n",
       "       0.02058517, 0.02009163, 0.02029077, 0.94099617, 0.02005186,\n",
       "       0.02002161, 0.0199952 , 0.01966614, 0.02045968, 0.0210545 ,\n",
       "       0.02100955, 0.0488135 , 0.9441621 , 0.0200508 , 0.9457506 ,\n",
       "       0.94069266, 0.02350033, 0.9507989 , 0.02367323, 0.02177071,\n",
       "       0.9439429 , 0.02016357, 0.02007453], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "58b84233-9e78-44c6-b99d-932f91109f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {'Id':[i for i in range(len(predictions))], 'Predicted':predictions}\n",
    "pred_df = DataFrame(pred_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3574adbd-b4af-4ce4-b873-b03161c54ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.020496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.054450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.020561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.020432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>553</td>\n",
       "      <td>0.023673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>554</td>\n",
       "      <td>0.021771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>555</td>\n",
       "      <td>0.943943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>556</td>\n",
       "      <td>0.020164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>557</td>\n",
       "      <td>0.020075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Predicted\n",
       "0      0   0.020496\n",
       "1      1   0.054450\n",
       "2      2   0.020429\n",
       "3      3   0.020561\n",
       "4      4   0.020432\n",
       "..   ...        ...\n",
       "553  553   0.023673\n",
       "554  554   0.021771\n",
       "555  555   0.943943\n",
       "556  556   0.020164\n",
       "557  557   0.020075\n",
       "\n",
       "[558 rows x 2 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8de5c313-831d-4d7f-bbe2-7ee219671ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.Predicted = pred_df.Predicted.apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d67d4be5-0389-48af-af69-3471cbc6bdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.Predicted.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6c4b7f3f-999d-4a6b-9b1a-a0adf646462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3fe9a67-e3d7-4dc3-aaa3-1cd5232428a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('predictions1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9e3e681-7d3e-403e-85d3-e669ae16c956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(a)):\n",
    "    if a.iloc[i].Predicted != pred_df.iloc[i].Predicted:\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70c29698-030b-4be7-918d-b8942f828d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(558, 256)\n",
      "(558, 24)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(test_seq).shape)\n",
    "print(np.array(test_stat).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e4a48f8-54cb-4ec0-a742-c9d19d74f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = torch.tensor(test_seq).long()\n",
    "test_mask = torch.tensor(test_mask).long()\n",
    "test_seg = torch.tensor(test_seg).long()\n",
    "test_stat = torch.tensor(np.array(test_stat)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b8c5b1-37c1-4333-a42b-ece0470ed583",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "test_stat = np.array(test_stat)\n",
    "for i in range(len(test_seq)):\n",
    "    seq = torch.tensor(test_seq[i]).long().unsqueeze(0)\n",
    "    mask = torch.tensor(test_mask[i]).long().unsqueeze(0)\n",
    "    seg = torch.tensor(test_seg[i]).long().unsqueeze(0)\n",
    "    stat = torch.tensor(test_stat[i,1:]).float().unsqueeze(0)\n",
    "    preds.append(model(seq, mask, seg, stat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e460c87-f926-4d28-bef7-93dc439938af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Create Train and Dev Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "feecfa1f-4cfe-498b-acdd-7ea02a534380",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_dev = []\n",
    "for i in range(train_stat.shape[0]):\n",
    "    X_train.append(list(train_tokens[i].reshape(-1)))\n",
    "    for j in range(1,train_stat.shape[1]):\n",
    "        X_train[i].append(train_stat.iloc[i,j])\n",
    "\n",
    "for i in range(dev_stat.shape[0]):\n",
    "    X_dev.append(list(dev_tokens[i].reshape(-1)))\n",
    "    for j in range(1,dev_stat.shape[1]):\n",
    "        X_dev[i].append(dev_stat.iloc[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4450b35a-db76-45dc-8139-435a7f25e6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1542"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "442b807a-76ac-4cb9-b6a1-f3c0fed6ad63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "791"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3382aaff-cdec-4aa9-9f64-4ae2cafae6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_tweet['label']\n",
    "y_dev = dev_tweet['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e435d-c046-4abf-bc48-8363c3aa35ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Test on simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e804cab2-226c-4c48-b725-5940eba222d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1e0a2bed-a9c8-4176-a6e9-dff543d9272b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.867816091954023"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(predictions, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7a2b01c3-66e6-45f3-bf3e-a0f6259d66fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.943579766536965"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = lr.predict(X_train)\n",
    "accuracy_score(train_preds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "030b153a-0955-4dbc-9a82-38a0ca5f640b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6609195402298851"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "accuracy_score(gnb.predict(X_dev), y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9bdb3ba2-1573-4a79-94d2-371ccedffd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('X_train.pkl', 'wb') as file:\n",
    "    pickle.dump(X_train, file)\n",
    "with open('X_dev.pkl', 'wb') as file:\n",
    "    pickle.dump(X_dev, file)\n",
    "with open('y_train.pkl', 'wb') as file:\n",
    "    pickle.dump(list(y_train), file)\n",
    "with open('y_dev.pkl', 'wb') as file:\n",
    "    pickle.dump(list(y_dev), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a39838-4e40-4d32-a268-0445606cd164",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Test simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4d72b566-f8d7-4da6-8933-78a1bdd0ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mlp, self).__init__()\n",
    "        self.ffnn = nn.Sequential(nn.Linear(791,128),\n",
    "                                  nn.ReLU(),\n",
    "                                  # nn.Dropout(0.3),\n",
    "                                 nn.Linear(128,64),\n",
    "                                  nn.ReLU(),\n",
    "                                  # nn.Dropout(0.3),\n",
    "                                  nn.Linear(64,1),\n",
    "                                  nn.Sigmoid()\n",
    "                                 )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.ffnn(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ef89ef1c-17d2-416b-974e-71a914a25c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b334580150>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d50aff54-ec06-4038-8187-b2d2dc4e6033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "EPOCH = 5\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8d055d7b-773e-4d50-b92e-0155c0a54037",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_dev = np.array(X_dev)\n",
    "y_train = np.array(y_train)\n",
    "y_dev = np.array(y_dev)\n",
    "X = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "y = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "dev_X = torch.from_numpy(X_dev).type(torch.FloatTensor)\n",
    "dev_y = torch.from_numpy(y_dev).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "70a0b495-7d5c-40b5-bffb-76c7aaa151b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1542"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e33cc3f4-b096-4594-974b-ee9995d5c9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "296dc716-edd7-4ce6-b663-efb7fe28f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TweetDataset(X,y)\n",
    "dev_set = TweetDataset(dev_X, dev_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f355687f-8290-42c9-9dda-f8e72d35acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_loader = Data.DataLoader(dev_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "78c34c8c-9150-4c49-9ba5-e08d0e4d0d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, criterion, dataloader, device):\n",
    "    net.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq, labels in dataloader:\n",
    "            seq, labels = seq.to(device), labels.to(device)\n",
    "            logits = net(seq)\n",
    "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
    "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
    "            count += 1\n",
    "\n",
    "    return mean_acc / count, mean_loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7749fc1b-31f6-4621-977f-1b0815999566",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mlp()\n",
    "net = net.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "opti = optim.Adam(net.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "14e9825f-acd4-417d-8e84-57894369eed6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 of epoch 0 complete. \n",
      " Loss: 0.02590068057179451; Accuracy: 1.0; Time taken (s): 0.004000186920166016\n",
      "Development Accuracy: 0.8802083134651184; Development Loss: 0.434159043762419\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "best_acc = 0\n",
    "st = time.time()\n",
    "eps = []\n",
    "t_loss = []\n",
    "d_loss = []\n",
    "for ep in range(1):\n",
    "    eps.append(ep)\n",
    "    net.train()\n",
    "    for it, (seq, labels) in enumerate(train_loader):\n",
    "        \n",
    "        #Clear gradients\n",
    "        opti.zero_grad()\n",
    "        #Converting these to cuda tensors\n",
    "        seq, labels = seq.to(device), labels.to(device)\n",
    "\n",
    "        #Obtaining the logits from the model\n",
    "        logits = net(seq)\n",
    "        \n",
    "        #Computing loss\n",
    "        loss = criterion(logits.squeeze(), labels.float())\n",
    "\n",
    "        #Backpropagating the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #Optimization step\n",
    "        opti.step()\n",
    "\n",
    "        if it % 100 == 0:\n",
    "\n",
    "            acc = get_accuracy_from_logits(logits, labels)\n",
    "            print(\"Iteration {} of epoch {} complete. \\n Loss: {}; Accuracy: {}; Time taken (s): {}\".format(it, ep, loss.item(), acc, (time.time()-st)))\n",
    "            st = time.time()\n",
    "\n",
    "        \n",
    "    dev_acc, dev_loss = evaluate(net, criterion, dev_loader, device)\n",
    "    t_loss.append(loss.item())\n",
    "    d_loss.append(dev_loss)\n",
    "    print(\"Development Accuracy: {}; Development Loss: {}\".format(dev_acc, dev_loss))\n",
    "    if dev_acc > best_acc:\n",
    "        # print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, dev_acc))\n",
    "        best_acc = dev_acc\n",
    "        # torch.save(net.state_dict(), 'sstcls_{}.dat'.format(ep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "289e761b-9b28-4e76-a02c-31eabbc776a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(eps,t_loss)\n",
    "plt.plot(eps,d_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "95f7cc04-ce28-417b-a1d4-41cc3bb75eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'sstcls_{}.dat'.format(ep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b707ac33-63aa-4e81-b71e-604078a51291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
