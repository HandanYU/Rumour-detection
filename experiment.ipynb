{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a00ed975-afc9-4cbe-89e9-651cd7187fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f3821f7-0888-4ca0-a0b5-ed088ca2b77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>reply_reply_count</th>\n",
       "      <th>reply_like_count</th>\n",
       "      <th>reply_retweet_count</th>\n",
       "      <th>reply_quote_count</th>\n",
       "      <th>reply_possibly_sensitive</th>\n",
       "      <th>reply_has_url</th>\n",
       "      <th>reply_mentioned_url_num</th>\n",
       "      <th>reply_id_num</th>\n",
       "      <th>reply_isweekday</th>\n",
       "      <th>...</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>has_url</th>\n",
       "      <th>mentioned_url_num</th>\n",
       "      <th>id_num</th>\n",
       "      <th>isweekday</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>senti_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1249004694950817796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.051326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1267552274819227649</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.011393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1235238334722699265</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>1.959079e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.088659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1248746792914546688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.530263e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.013806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>523820806917603328</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>1.306053e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114537</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021542</td>\n",
       "      <td>0.037443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id  reply_reply_count  reply_like_count  \\\n",
       "0  1249004694950817796           0.000000      0.000000e+00   \n",
       "1  1267552274819227649           0.000048      0.000000e+00   \n",
       "2  1235238334722699265           0.000215      1.959079e-06   \n",
       "3  1248746792914546688           0.000000      6.530263e-07   \n",
       "4   523820806917603328           0.000119      1.306053e-06   \n",
       "\n",
       "   reply_retweet_count  reply_quote_count  reply_possibly_sensitive  \\\n",
       "0             0.000000           0.000000                       0.0   \n",
       "1             0.000000           0.000000                       0.0   \n",
       "2             0.000007           0.000024                       0.0   \n",
       "3             0.000000           0.000000                       0.0   \n",
       "4             0.000004           0.000000                       0.0   \n",
       "\n",
       "   reply_has_url  reply_mentioned_url_num  reply_id_num  reply_isweekday  ...  \\\n",
       "0       0.004405                 0.000000      0.001066         0.000000  ...   \n",
       "1       0.008811                 0.000000      0.004264         0.012048  ...   \n",
       "2       0.013216                 0.000000      0.000000         0.060241  ...   \n",
       "3       0.004405                 0.000000      0.001066         0.000000  ...   \n",
       "4       0.114537                 0.054348      0.062900         0.024096  ...   \n",
       "\n",
       "   quote_count  possibly_sensitive  has_url  mentioned_url_num    id_num  \\\n",
       "0          0.0                 0.0      1.0           0.333333  0.000000   \n",
       "1          0.0                 0.0      1.0           0.000000  0.020408   \n",
       "2          0.0                 0.0      0.0           0.000000  0.000000   \n",
       "3          0.0                 0.0      0.0           0.000000  0.000000   \n",
       "4          0.0                 0.0      1.0           0.666667  0.020408   \n",
       "\n",
       "   isweekday  followers_count  tweet_count  verified  senti_score  \n",
       "0        0.0         0.000557     0.051326       0.0          1.0  \n",
       "1        1.0         0.000012     0.011393       0.0          0.0  \n",
       "2        1.0         0.000048     0.088659       0.0          0.0  \n",
       "3        1.0         0.000015     0.013806       0.0          0.0  \n",
       "4        0.0         0.021542     0.037443       1.0          0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stat = pd.read_csv('./sep_data/train_stat_feat_df.csv')\n",
    "dev_stat = pd.read_csv('./sep_data/dev_stat_feat_df.csv')\n",
    "\n",
    "dev_stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5145a7-616e-4dbe-9030-4b91370ea858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet_id.1</th>\n",
       "      <th>label</th>\n",
       "      <th>reply</th>\n",
       "      <th>reply_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1249004694950817796</td>\n",
       "      <td>covid fact hand dryer effect kill new coronavi...</td>\n",
       "      <td>2020-04-11T16:01:39.000Z</td>\n",
       "      <td>35761403</td>\n",
       "      <td>1249004694950817796</td>\n",
       "      <td>0</td>\n",
       "      <td>1249011200068730880</td>\n",
       "      <td>fact germ breed [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1267552274819227649</td>\n",
       "      <td>expect result husband pend antibodi test pleas...</td>\n",
       "      <td>2020-06-01T20:23:06.000Z</td>\n",
       "      <td>2734457193</td>\n",
       "      <td>1267552274819227649</td>\n",
       "      <td>0</td>\n",
       "      <td>1270394169836568576,1270502071175909376</td>\n",
       "      <td>hi luck boat [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1235238334722699265</td>\n",
       "      <td>covid spread peopl catch covid other diseas sp...</td>\n",
       "      <td>2020-03-04T16:19:03.000Z</td>\n",
       "      <td>53980699</td>\n",
       "      <td>1235238334722699265</td>\n",
       "      <td>0</td>\n",
       "      <td>1235234904281165825,1235234927937048577,123523...</td>\n",
       "      <td>read lot corona viru late think share highligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1248746792914546688</td>\n",
       "      <td>everi news outlet use headlin like antibiot ef...</td>\n",
       "      <td>2020-04-10T22:56:50.000Z</td>\n",
       "      <td>393187879</td>\n",
       "      <td>1248746792914546688</td>\n",
       "      <td>0</td>\n",
       "      <td>1248775858120097792</td>\n",
       "      <td>appar headlin question answer usual [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>523820806917603328</td>\n",
       "      <td>research encount goliath birdeat world largest...</td>\n",
       "      <td>2014-10-19T12:59:47.000Z</td>\n",
       "      <td>39585367</td>\n",
       "      <td>523820806917603328</td>\n",
       "      <td>0</td>\n",
       "      <td>523821510042353664,523822210071658496,52382235...</td>\n",
       "      <td>eu tenho uma dessa em casa são ótima para coça...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1249004694950817796  covid fact hand dryer effect kill new coronavi...   \n",
       "1  1267552274819227649  expect result husband pend antibodi test pleas...   \n",
       "2  1235238334722699265  covid spread peopl catch covid other diseas sp...   \n",
       "3  1248746792914546688  everi news outlet use headlin like antibiot ef...   \n",
       "4   523820806917603328  research encount goliath birdeat world largest...   \n",
       "\n",
       "                 created_at     user_id           tweet_id.1  label  \\\n",
       "0  2020-04-11T16:01:39.000Z    35761403  1249004694950817796      0   \n",
       "1  2020-06-01T20:23:06.000Z  2734457193  1267552274819227649      0   \n",
       "2  2020-03-04T16:19:03.000Z    53980699  1235238334722699265      0   \n",
       "3  2020-04-10T22:56:50.000Z   393187879  1248746792914546688      0   \n",
       "4  2014-10-19T12:59:47.000Z    39585367   523820806917603328      0   \n",
       "\n",
       "                                               reply  \\\n",
       "0                                1249011200068730880   \n",
       "1            1270394169836568576,1270502071175909376   \n",
       "2  1235234904281165825,1235234927937048577,123523...   \n",
       "3                                1248775858120097792   \n",
       "4  523821510042353664,523822210071658496,52382235...   \n",
       "\n",
       "                                          reply_text  \n",
       "0                              fact germ breed [SEP]  \n",
       "1                                 hi luck boat [SEP]  \n",
       "2  read lot corona viru late think share highligh...  \n",
       "3          appar headlin question answer usual [SEP]  \n",
       "4  eu tenho uma dessa em casa são ótima para coça...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweet = pd.read_csv('./sep_data/train_tweet_df.csv')\n",
    "dev_tweet = pd.read_csv('./sep_data/dev_tweet_df.csv')\n",
    "\n",
    "dev_tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d9d7b-b4cc-4144-8a0b-ac2e1f50d586",
   "metadata": {},
   "source": [
    "### Fill NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e477626-165a-4dd4-8b98-b70c007f79a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 522 entries, 0 to 521\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_id    522 non-null    int64 \n",
      " 1   text        522 non-null    object\n",
      " 2   created_at  522 non-null    object\n",
      " 3   user_id     522 non-null    int64 \n",
      " 4   tweet_id.1  522 non-null    int64 \n",
      " 5   label       522 non-null    int64 \n",
      " 6   reply       522 non-null    object\n",
      " 7   reply_text  518 non-null    object\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 32.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dev_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62faa088-f952-4217-8d4d-9d51ca76de70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1542 entries, 0 to 1541\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_id    1542 non-null   int64 \n",
      " 1   text        1542 non-null   object\n",
      " 2   created_at  1542 non-null   object\n",
      " 3   user_id     1542 non-null   int64 \n",
      " 4   tweet_id.1  1542 non-null   int64 \n",
      " 5   label       1542 non-null   int64 \n",
      " 6   reply       1542 non-null   object\n",
      " 7   reply_text  1532 non-null   object\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 96.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "439ce649-ba89-4df2-b886-f55ce3b07f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tweet.reply_text.fillna('', inplace=True)\n",
    "train_tweet.reply_text.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "580c969b-f940-445c-bc8a-bc699a5220a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 522 entries, 0 to 521\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_id    522 non-null    int64 \n",
      " 1   text        522 non-null    object\n",
      " 2   created_at  522 non-null    object\n",
      " 3   user_id     522 non-null    int64 \n",
      " 4   tweet_id.1  522 non-null    int64 \n",
      " 5   label       522 non-null    int64 \n",
      " 6   reply       522 non-null    object\n",
      " 7   reply_text  522 non-null    object\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 32.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dev_tweet.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d11469-56b1-4ba0-b50f-96208aabf747",
   "metadata": {},
   "source": [
    "### Get Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e5792f-a409-41de-9317-45adb20e7aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/522 [00:00<?, ?it/s]C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_18288\\1498738565.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dev_tweet.text.iloc[i] = '[CLS] ' + str(dev_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(dev_tweet.reply_text.iloc[i]).strip()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 522/522 [00:07<00:00, 71.99it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(dev_tweet))):\n",
    "    dev_tweet.text.iloc[i] = '[CLS] ' + str(dev_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(dev_tweet.reply_text.iloc[i]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e24eefb-945f-4aee-a8ce-620ecbad2e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1542 [00:00<?, ?it/s]C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_18288\\569037025.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_tweet.text.iloc[i] = '[CLS]' + str(train_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(train_tweet.reply_text.iloc[i]).strip()\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1542/1542 [00:17<00:00, 85.96it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(train_tweet))):\n",
    "    train_tweet.text.iloc[i] = '[CLS]' + str(train_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(train_tweet.reply_text.iloc[i]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62fa74a3-39cd-4058-9837-b064bf613183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] expect result husband pend antibodi test pleas may [SEP] hi luck boat [SEP]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_tweet.text.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d7f58c5-7808-46b1-b541-63062280a714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf57658d-7846-448f-90e9-a11e2849e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aadc52e-0850-448b-8282-6b35952d9d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 522/522 [02:50<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1542/1542 [08:05<00:00,  3.18it/s]\n"
     ]
    }
   ],
   "source": [
    "max_len = 256\n",
    "dev_tokens = []\n",
    "train_tokens = []\n",
    "for i in tqdm(range(len(dev_tweet))):\n",
    "    txt = dev_tweet.text.iloc[i]\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    if len(tokens) < max_len:\n",
    "         padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "    else:\n",
    "        padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "    attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "    seg_ids = [1 if token == '[SEP]' else 0 for token in padded_tokens]\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    token_ids_t = torch.tensor(token_ids).unsqueeze(0) #Shape : [1, 12]\n",
    "    attn_mask_t = torch.tensor(attn_mask).unsqueeze(0) #Shape : [1, 12]\n",
    "    seg_ids_t   = torch.tensor(seg_ids).unsqueeze(0) #Shape : [1, 12]\n",
    "    outputs = bert_model(token_ids_t, attention_mask = attn_mask_t,\\\n",
    "                                  token_type_ids = seg_ids_t, return_dict=True)\n",
    "    cont_reps = outputs.last_hidden_state\n",
    "    cls_rep = cont_reps[:, 0]\n",
    "    dev_tokens.append(cls_rep.detach().numpy())\n",
    "\n",
    "for i in tqdm(range(len(train_tweet))):\n",
    "    txt = train_tweet.text.iloc[i]\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    if len(tokens) < max_len:\n",
    "         padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "    else:\n",
    "        padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "    attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "    seg_ids = [1 if token == '[SEP]' else 0 for token in padded_tokens]\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    token_ids_t = torch.tensor(token_ids).unsqueeze(0)\n",
    "    attn_mask_t = torch.tensor(attn_mask).unsqueeze(0)\n",
    "    seg_ids_t   = torch.tensor(seg_ids).unsqueeze(0)\n",
    "    outputs = bert_model(token_ids_t, attention_mask = attn_mask_t,\\\n",
    "                                  token_type_ids = seg_ids_t, return_dict=True)\n",
    "    cont_reps = outputs.last_hidden_state\n",
    "    cls_rep = cont_reps[:, 0]\n",
    "    train_tokens.append(cls_rep.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d42f5e29-511c-4030-bf45-bfd9c1e46033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_tokens[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e460c87-f926-4d28-bef7-93dc439938af",
   "metadata": {},
   "source": [
    "### Create Train and Dev Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "feecfa1f-4cfe-498b-acdd-7ea02a534380",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_dev = []\n",
    "for i in range(train_stat.shape[0]):\n",
    "    X_train.append(list(train_tokens[i].reshape(-1)))\n",
    "    for j in range(1,train_stat.shape[1]):\n",
    "        X_train[i].append(train_stat.iloc[i,j])\n",
    "\n",
    "for i in range(dev_stat.shape[0]):\n",
    "    X_dev.append(list(dev_tokens[i].reshape(-1)))\n",
    "    for j in range(1,dev_stat.shape[1]):\n",
    "        X_dev[i].append(dev_stat.iloc[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4450b35a-db76-45dc-8139-435a7f25e6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1542"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "442b807a-76ac-4cb9-b6a1-f3c0fed6ad63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "791"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3382aaff-cdec-4aa9-9f64-4ae2cafae6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_tweet['label']\n",
    "y_dev = dev_tweet['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e435d-c046-4abf-bc48-8363c3aa35ec",
   "metadata": {},
   "source": [
    "### Test on simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e804cab2-226c-4c48-b725-5940eba222d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e0a2bed-a9c8-4176-a6e9-dff543d9272b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.867816091954023"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(predictions, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "030b153a-0955-4dbc-9a82-38a0ca5f640b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6609195402298851"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "accuracy_score(gnb.predict(X_dev), y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9bdb3ba2-1573-4a79-94d2-371ccedffd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('X_train.pkl', 'wb') as file:\n",
    "    pickle.dump(X_train, file)\n",
    "with open('X_dev.pkl', 'wb') as file:\n",
    "    pickle.dump(X_dev, file)\n",
    "with open('y_train.pkl', 'wb') as file:\n",
    "    pickle.dump(list(y_train), file)\n",
    "with open('y_dev.pkl', 'wb') as file:\n",
    "    pickle.dump(list(y_dev), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d72b566-f8d7-4da6-8933-78a1bdd0ed7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
