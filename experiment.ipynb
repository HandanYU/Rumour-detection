{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a00ed975-afc9-4cbe-89e9-651cd7187fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f3821f7-0888-4ca0-a0b5-ed088ca2b77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1579 entries, 0 to 1578\n",
      "Data columns (total 66 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   Unnamed: 0                           1579 non-null   int64  \n",
      " 1   reply_contributors                   1579 non-null   float64\n",
      " 2   reply_possibly_sensitive             1579 non-null   float64\n",
      " 3   reply_possibly_sensitive_appealable  1579 non-null   float64\n",
      " 4   reply_retweet_count                  1579 non-null   float64\n",
      " 5   reply_favorite_count                 1579 non-null   float64\n",
      " 6   reply_mentioned_url_num              1579 non-null   float64\n",
      " 7   reply_id_num                         1579 non-null   float64\n",
      " 8   reply_followers_count                1579 non-null   float64\n",
      " 9   reply_friends_count                  1579 non-null   float64\n",
      " 10  reply_listed_count                   1579 non-null   float64\n",
      " 11  reply_favourites_count               1579 non-null   float64\n",
      " 12  reply_statuses_count                 1579 non-null   float64\n",
      " 13  reply_has_url                        1579 non-null   float64\n",
      " 14  reply_senti_score                    1579 non-null   float64\n",
      " 15  reply_truncated                      1579 non-null   float64\n",
      " 16  reply_is_quote_status                1579 non-null   float64\n",
      " 17  reply_favorited                      1579 non-null   float64\n",
      " 18  reply_retweeted                      1579 non-null   float64\n",
      " 19  reply_protected                      1579 non-null   float64\n",
      " 20  reply_geo_enabled                    1579 non-null   float64\n",
      " 21  reply_verified                       1579 non-null   float64\n",
      " 22  reply_contributors_enabled           1579 non-null   float64\n",
      " 23  reply_isweekday                      1579 non-null   float64\n",
      " 24  reply_contributors_enabled.1         1579 non-null   float64\n",
      " 25  reply_is_translator                  1579 non-null   float64\n",
      " 26  reply_is_translation_enabled         1579 non-null   float64\n",
      " 27  reply_has_extended_profile           1579 non-null   float64\n",
      " 28  reply_default_profile                1579 non-null   float64\n",
      " 29  reply_default_profile_image          1579 non-null   float64\n",
      " 30  reply_following                      1579 non-null   float64\n",
      " 31  reply_follow_request_sent            1579 non-null   float64\n",
      " 32  reply_notifications                  1579 non-null   float64\n",
      " 33  contributors                         0 non-null      float64\n",
      " 34  possibly_sensitive                   1579 non-null   float64\n",
      " 35  possibly_sensitive_appealable        1579 non-null   float64\n",
      " 36  retweet_count                        1579 non-null   float64\n",
      " 37  favorite_count                       1579 non-null   float64\n",
      " 38  mentioned_url_num                    1579 non-null   float64\n",
      " 39  id_num                               1579 non-null   float64\n",
      " 40  followers_count                      1579 non-null   float64\n",
      " 41  friends_count                        1579 non-null   float64\n",
      " 42  listed_count                         1579 non-null   float64\n",
      " 43  favourites_count                     1579 non-null   float64\n",
      " 44  statuses_count                       1579 non-null   float64\n",
      " 45  has_url                              1579 non-null   float64\n",
      " 46  senti_score                          1579 non-null   float64\n",
      " 47  truncated                            1579 non-null   float64\n",
      " 48  is_quote_status                      1579 non-null   float64\n",
      " 49  favorited                            1579 non-null   float64\n",
      " 50  retweeted                            1579 non-null   float64\n",
      " 51  protected                            1579 non-null   float64\n",
      " 52  geo_enabled                          1579 non-null   float64\n",
      " 53  verified                             1579 non-null   float64\n",
      " 54  contributors_enabled                 1579 non-null   float64\n",
      " 55  isweekday                            1579 non-null   float64\n",
      " 56  reply_count                          1579 non-null   float64\n",
      " 57  contributors_enabled.1               1579 non-null   float64\n",
      " 58  is_translator                        1579 non-null   float64\n",
      " 59  is_translation_enabled               1579 non-null   float64\n",
      " 60  has_extended_profile                 1579 non-null   float64\n",
      " 61  default_profile                      1579 non-null   float64\n",
      " 62  default_profile_image                1579 non-null   float64\n",
      " 63  following                            1579 non-null   float64\n",
      " 64  follow_request_sent                  1579 non-null   float64\n",
      " 65  notifications                        1579 non-null   float64\n",
      "dtypes: float64(65), int64(1)\n",
      "memory usage: 814.3 KB\n"
     ]
    }
   ],
   "source": [
    "train_stat = pd.read_csv('./sep_data/train_scaled_stat_feat_df.csv')\n",
    "dev_stat = pd.read_csv('./sep_data/dev_scaled_stat_feat_df.csv')\n",
    "\n",
    "train_stat = train_stat.fillna(train_stat.mean())\n",
    "dev_stat = dev_stat.fillna(dev_stat.mean())\n",
    "train_stat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9f4a9f9-bc11-4c50-8627-eb05210bfbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reply_contributors</th>\n",
       "      <th>reply_possibly_sensitive</th>\n",
       "      <th>reply_possibly_sensitive_appealable</th>\n",
       "      <th>reply_retweet_count</th>\n",
       "      <th>reply_favorite_count</th>\n",
       "      <th>reply_mentioned_url_num</th>\n",
       "      <th>reply_id_num</th>\n",
       "      <th>reply_followers_count</th>\n",
       "      <th>reply_friends_count</th>\n",
       "      <th>reply_listed_count</th>\n",
       "      <th>...</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>contributors_enabled.1</th>\n",
       "      <th>is_translator</th>\n",
       "      <th>is_translation_enabled</th>\n",
       "      <th>has_extended_profile</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "      <th>following</th>\n",
       "      <th>follow_request_sent</th>\n",
       "      <th>notifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.178398e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.466035e-17</td>\n",
       "      <td>3.904607e-17</td>\n",
       "      <td>4.813118e-17</td>\n",
       "      <td>-2.693797e-17</td>\n",
       "      <td>2.517366e-17</td>\n",
       "      <td>2.513063e-17</td>\n",
       "      <td>7.701634e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.504152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>-0.722953</td>\n",
       "      <td>1.392986</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.533986e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.106740e-02</td>\n",
       "      <td>-4.153092e-02</td>\n",
       "      <td>-3.204961e-01</td>\n",
       "      <td>-2.766346e-01</td>\n",
       "      <td>-1.180378e-01</td>\n",
       "      <td>-1.121073e-02</td>\n",
       "      <td>-1.126588e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.297330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.736649</td>\n",
       "      <td>-0.722953</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.178398e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.466035e-17</td>\n",
       "      <td>3.904607e-17</td>\n",
       "      <td>4.813118e-17</td>\n",
       "      <td>-2.693797e-17</td>\n",
       "      <td>2.517366e-17</td>\n",
       "      <td>2.513063e-17</td>\n",
       "      <td>7.701634e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.504152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>1.383215</td>\n",
       "      <td>1.392986</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.533986e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.094274e-02</td>\n",
       "      <td>-4.153092e-02</td>\n",
       "      <td>-3.204961e-01</td>\n",
       "      <td>-3.995551e-01</td>\n",
       "      <td>-1.282902e-01</td>\n",
       "      <td>-3.318359e-01</td>\n",
       "      <td>-1.485160e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>1.383215</td>\n",
       "      <td>1.392986</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.533986e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.907282e-02</td>\n",
       "      <td>-4.127419e-02</td>\n",
       "      <td>-3.934518e-01</td>\n",
       "      <td>5.018618e-01</td>\n",
       "      <td>-1.202372e-01</td>\n",
       "      <td>1.765633e+00</td>\n",
       "      <td>-8.165513e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.365410</td>\n",
       "      <td>-0.722953</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   reply_contributors  reply_possibly_sensitive  \\\n",
       "0                 0.0              4.178398e-17   \n",
       "1                 0.0             -1.533986e-01   \n",
       "2                 0.0              4.178398e-17   \n",
       "3                 0.0             -1.533986e-01   \n",
       "4                 0.0             -1.533986e-01   \n",
       "\n",
       "   reply_possibly_sensitive_appealable  reply_retweet_count  \\\n",
       "0                                  0.0         7.466035e-17   \n",
       "1                                  0.0        -5.106740e-02   \n",
       "2                                  0.0         7.466035e-17   \n",
       "3                                  0.0        -5.094274e-02   \n",
       "4                                  0.0        -4.907282e-02   \n",
       "\n",
       "   reply_favorite_count  reply_mentioned_url_num  reply_id_num  \\\n",
       "0          3.904607e-17             4.813118e-17 -2.693797e-17   \n",
       "1         -4.153092e-02            -3.204961e-01 -2.766346e-01   \n",
       "2          3.904607e-17             4.813118e-17 -2.693797e-17   \n",
       "3         -4.153092e-02            -3.204961e-01 -3.995551e-01   \n",
       "4         -4.127419e-02            -3.934518e-01  5.018618e-01   \n",
       "\n",
       "   reply_followers_count  reply_friends_count  reply_listed_count  ...  \\\n",
       "0           2.517366e-17         2.513063e-17        7.701634e-17  ...   \n",
       "1          -1.180378e-01        -1.121073e-02       -1.126588e-01  ...   \n",
       "2           2.517366e-17         2.513063e-17        7.701634e-17  ...   \n",
       "3          -1.282902e-01        -3.318359e-01       -1.485160e-01  ...   \n",
       "4          -1.202372e-01         1.765633e+00       -8.165513e-02  ...   \n",
       "\n",
       "   reply_count  contributors_enabled.1  is_translator  is_translation_enabled  \\\n",
       "0    -0.504152                     0.0            0.0               -0.365410   \n",
       "1    -0.297330                     0.0            0.0                2.736649   \n",
       "2    -0.504152                     0.0            0.0               -0.365410   \n",
       "3    -0.452447                     0.0            0.0               -0.365410   \n",
       "4     0.840188                     0.0            0.0               -0.365410   \n",
       "\n",
       "   has_extended_profile  default_profile  default_profile_image  following  \\\n",
       "0             -0.722953         1.392986              -0.050395        0.0   \n",
       "1             -0.722953        -0.717882              -0.050395        0.0   \n",
       "2              1.383215         1.392986              -0.050395        0.0   \n",
       "3              1.383215         1.392986              -0.050395        0.0   \n",
       "4             -0.722953        -0.717882              -0.050395        0.0   \n",
       "\n",
       "   follow_request_sent  notifications  \n",
       "0                  0.0            0.0  \n",
       "1                  0.0            0.0  \n",
       "2                  0.0            0.0  \n",
       "3                  0.0            0.0  \n",
       "4                  0.0            0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stat.drop(columns=['Unnamed: 0', 'contributors'], inplace=True)\n",
    "train_stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7bd76937-ef04-4177-be23-3a112f9f09db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reply_contributors</th>\n",
       "      <th>reply_possibly_sensitive</th>\n",
       "      <th>reply_possibly_sensitive_appealable</th>\n",
       "      <th>reply_retweet_count</th>\n",
       "      <th>reply_favorite_count</th>\n",
       "      <th>reply_mentioned_url_num</th>\n",
       "      <th>reply_id_num</th>\n",
       "      <th>reply_followers_count</th>\n",
       "      <th>reply_friends_count</th>\n",
       "      <th>reply_listed_count</th>\n",
       "      <th>...</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>contributors_enabled.1</th>\n",
       "      <th>is_translator</th>\n",
       "      <th>is_translation_enabled</th>\n",
       "      <th>has_extended_profile</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "      <th>following</th>\n",
       "      <th>follow_request_sent</th>\n",
       "      <th>notifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.153399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.051067</td>\n",
       "      <td>-0.041531</td>\n",
       "      <td>-0.466408</td>\n",
       "      <td>-0.317608</td>\n",
       "      <td>-0.129459</td>\n",
       "      <td>-0.407111</td>\n",
       "      <td>-0.148813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.36541</td>\n",
       "      <td>1.383215</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.153399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.050943</td>\n",
       "      <td>-0.041531</td>\n",
       "      <td>-0.393452</td>\n",
       "      <td>-0.317608</td>\n",
       "      <td>-0.129921</td>\n",
       "      <td>-0.444119</td>\n",
       "      <td>-0.147129</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.36541</td>\n",
       "      <td>-0.722953</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.153399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.045956</td>\n",
       "      <td>-0.040761</td>\n",
       "      <td>-0.247540</td>\n",
       "      <td>-0.071767</td>\n",
       "      <td>-0.129574</td>\n",
       "      <td>-0.444898</td>\n",
       "      <td>-0.148714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.349036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.36541</td>\n",
       "      <td>1.383215</td>\n",
       "      <td>1.392986</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.153399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.050943</td>\n",
       "      <td>-0.041531</td>\n",
       "      <td>-0.393452</td>\n",
       "      <td>-0.235661</td>\n",
       "      <td>-0.130231</td>\n",
       "      <td>-0.442606</td>\n",
       "      <td>-0.149573</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.36541</td>\n",
       "      <td>-0.722953</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.153399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.047078</td>\n",
       "      <td>-0.036700</td>\n",
       "      <td>-0.101629</td>\n",
       "      <td>-0.399555</td>\n",
       "      <td>-0.129009</td>\n",
       "      <td>-0.361831</td>\n",
       "      <td>-0.142011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.36541</td>\n",
       "      <td>1.383215</td>\n",
       "      <td>-0.717882</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   reply_contributors  reply_possibly_sensitive  \\\n",
       "0                 0.0                 -0.153399   \n",
       "1                 0.0                 -0.153399   \n",
       "2                 0.0                 -0.153399   \n",
       "3                 0.0                 -0.153399   \n",
       "4                 0.0                 -0.153399   \n",
       "\n",
       "   reply_possibly_sensitive_appealable  reply_retweet_count  \\\n",
       "0                                  0.0            -0.051067   \n",
       "1                                  0.0            -0.050943   \n",
       "2                                  0.0            -0.045956   \n",
       "3                                  0.0            -0.050943   \n",
       "4                                  0.0            -0.047078   \n",
       "\n",
       "   reply_favorite_count  reply_mentioned_url_num  reply_id_num  \\\n",
       "0             -0.041531                -0.466408     -0.317608   \n",
       "1             -0.041531                -0.393452     -0.317608   \n",
       "2             -0.040761                -0.247540     -0.071767   \n",
       "3             -0.041531                -0.393452     -0.235661   \n",
       "4             -0.036700                -0.101629     -0.399555   \n",
       "\n",
       "   reply_followers_count  reply_friends_count  reply_listed_count  ...  \\\n",
       "0              -0.129459            -0.407111           -0.148813  ...   \n",
       "1              -0.129921            -0.444119           -0.147129  ...   \n",
       "2              -0.129574            -0.444898           -0.148714  ...   \n",
       "3              -0.130231            -0.442606           -0.149573  ...   \n",
       "4              -0.129009            -0.361831           -0.142011  ...   \n",
       "\n",
       "   reply_count  contributors_enabled.1  is_translator  is_translation_enabled  \\\n",
       "0    -0.452447                     0.0            0.0                -0.36541   \n",
       "1    -0.400741                     0.0            0.0                -0.36541   \n",
       "2    -0.349036                     0.0            0.0                -0.36541   \n",
       "3    -0.452447                     0.0            0.0                -0.36541   \n",
       "4    -0.193920                     0.0            0.0                -0.36541   \n",
       "\n",
       "   has_extended_profile  default_profile  default_profile_image  following  \\\n",
       "0              1.383215        -0.717882              -0.050395        0.0   \n",
       "1             -0.722953        -0.717882              -0.050395        0.0   \n",
       "2              1.383215         1.392986              -0.050395        0.0   \n",
       "3             -0.722953        -0.717882              -0.050395        0.0   \n",
       "4              1.383215        -0.717882              -0.050395        0.0   \n",
       "\n",
       "   follow_request_sent  notifications  \n",
       "0                  0.0            0.0  \n",
       "1                  0.0            0.0  \n",
       "2                  0.0            0.0  \n",
       "3                  0.0            0.0  \n",
       "4                  0.0            0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_stat.drop(columns=['Unnamed: 0', 'contributors'], inplace=True)\n",
    "dev_stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3da86e0c-0bd4-4574-a2e5-a446b9ed4add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reply_contributors                     0.000000e+00\n",
       "reply_possibly_sensitive               1.119105e-13\n",
       "reply_possibly_sensitive_appealable    0.000000e+00\n",
       "reply_retweet_count                    8.526513e-14\n",
       "reply_favorite_count                   6.039613e-14\n",
       "                                           ...     \n",
       "default_profile                        4.263256e-14\n",
       "default_profile_image                  1.012523e-13\n",
       "following                              0.000000e+00\n",
       "follow_request_sent                    0.000000e+00\n",
       "notifications                          0.000000e+00\n",
       "Length: 64, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stat.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1eebe27-571b-4af8-81a9-0078176bcbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reply_contributors', 'reply_possibly_sensitive_appealable', 'reply_favorited', 'reply_retweeted', 'reply_protected', 'reply_contributors_enabled', 'reply_contributors_enabled.1', 'reply_is_translator', 'reply_following', 'reply_follow_request_sent', 'reply_notifications', 'possibly_sensitive_appealable', 'favorited', 'retweeted', 'protected', 'contributors_enabled', 'contributors_enabled.1', 'is_translator', 'following', 'follow_request_sent', 'notifications']\n"
     ]
    }
   ],
   "source": [
    "dev_zero = []\n",
    "for column in dev_stat.columns:\n",
    "    if dev_stat[column].sum() == 0:\n",
    "        dev_zero.append(column)\n",
    "print(dev_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df1866c7-f1b8-4c35-a89f-7c94d6ad3262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reply_contributors', 'reply_possibly_sensitive_appealable', 'reply_favorited', 'reply_retweeted', 'reply_protected', 'reply_contributors_enabled', 'reply_contributors_enabled.1', 'reply_is_translator', 'reply_following', 'reply_follow_request_sent', 'reply_notifications', 'possibly_sensitive_appealable', 'favorited', 'retweeted', 'protected', 'contributors_enabled', 'contributors_enabled.1', 'is_translator', 'following', 'follow_request_sent', 'notifications']\n"
     ]
    }
   ],
   "source": [
    "train_zero = []\n",
    "for column in train_stat.columns:\n",
    "    if train_stat[column].sum() == 0:\n",
    "        train_zero.append(column)\n",
    "print(train_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "765eba63-9cac-40cf-af78-318cf99aa35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stat.drop(columns=train_zero, inplace=True)\n",
    "dev_stat.drop(columns=dev_zero, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c5145a7-616e-4dbe-9030-4b91370ea858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>reply_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1240727985491193862</td>\n",
       "      <td>covid viru transmit area hot humid world healt...</td>\n",
       "      <td>humid good demonstr virus surviv temperatur hi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>634943791934406657</td>\n",
       "      <td>marilyn monro jame dean smoke new york citi</td>\n",
       "      <td>icon [SEP]  [SEP] yo puedo demostrar que era h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1243967693297987584</td>\n",
       "      <td>symptom covid jcinigeria</td>\n",
       "      <td>symptom usual mild gradual common [SEP] infect...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1233175449980874752</td>\n",
       "      <td>coronaviru wear mask protect covid</td>\n",
       "      <td>thank [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1245592346344841216</td>\n",
       "      <td>symptom covid let watch new episod q covid know</td>\n",
       "      <td>infect peopl around world believ togeth stop [...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1240727985491193862  covid viru transmit area hot humid world healt...   \n",
       "1   634943791934406657        marilyn monro jame dean smoke new york citi   \n",
       "2  1243967693297987584                           symptom covid jcinigeria   \n",
       "3  1233175449980874752                 coronaviru wear mask protect covid   \n",
       "4  1245592346344841216    symptom covid let watch new episod q covid know   \n",
       "\n",
       "                                          reply_text  label  \n",
       "0  humid good demonstr virus surviv temperatur hi...      0  \n",
       "1  icon [SEP]  [SEP] yo puedo demostrar que era h...      1  \n",
       "2  symptom usual mild gradual common [SEP] infect...      0  \n",
       "3                                       thank [SEP]       0  \n",
       "4  infect peopl around world believ togeth stop [...      0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweet = pd.read_csv('./sep_data/train_tweet_df.csv')\n",
    "dev_tweet = pd.read_csv('./sep_data/dev_tweet_df.csv')\n",
    "\n",
    "dev_tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d9d7b-b4cc-4144-8a0b-ac2e1f50d586",
   "metadata": {},
   "source": [
    "### Fill NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e477626-165a-4dd4-8b98-b70c007f79a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 536 entries, 0 to 535\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_id    536 non-null    int64 \n",
      " 1   text        528 non-null    object\n",
      " 2   reply_text  439 non-null    object\n",
      " 3   label       536 non-null    int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 16.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dev_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62faa088-f952-4217-8d4d-9d51ca76de70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1579 entries, 0 to 1578\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_id    1579 non-null   int64 \n",
      " 1   text        1559 non-null   object\n",
      " 2   reply_text  1290 non-null   object\n",
      " 3   label       1579 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 49.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "439ce649-ba89-4df2-b886-f55ce3b07f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tweet.reply_text.fillna('', inplace=True)\n",
    "train_tweet.reply_text.fillna('', inplace=True)\n",
    "dev_tweet.text.fillna('', inplace=True)\n",
    "train_tweet.text.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "580c969b-f940-445c-bc8a-bc699a5220a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 536 entries, 0 to 535\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_id    536 non-null    int64 \n",
      " 1   text        536 non-null    object\n",
      " 2   reply_text  536 non-null    object\n",
      " 3   label       536 non-null    int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 16.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dev_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eda359ca-ef95-4ddc-ba40-3a0c1a93c585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'humid good demonstr virus surviv temperatur high [SEP] mean warm weather good elimin'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_tweet.iloc[0].reply_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d11469-56b1-4ba0-b50f-96208aabf747",
   "metadata": {},
   "source": [
    "### Get Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "12e5792f-a409-41de-9317-45adb20e7aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/536 [00:00<?, ?it/s]C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_2812\\2640282967.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dev_tweet.text.iloc[i] = '[CLS] ' + str(dev_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(dev_tweet.reply_text.iloc[i]).strip() + ' [SEP]'\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 536/536 [00:07<00:00, 69.05it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(dev_tweet))):\n",
    "    dev_tweet.text.iloc[i] = '[CLS] ' + str(dev_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(dev_tweet.reply_text.iloc[i]).strip() + ' [SEP]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e24eefb-945f-4aee-a8ce-620ecbad2e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1579 [00:00<?, ?it/s]C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_2812\\1422859891.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_tweet.text.iloc[i] = '[CLS] ' + str(train_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(train_tweet.reply_text.iloc[i]).strip() + ' [SEP]'\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1579/1579 [00:19<00:00, 80.79it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(train_tweet))):\n",
    "    train_tweet.text.iloc[i] = '[CLS] ' + str(train_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(train_tweet.reply_text.iloc[i]).strip() + ' [SEP]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "161eac3b-6e96-4538-b00c-3960902964f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] covid viru transmit area hot humid world health organ [SEP] humid good demonstr virus surviv temperatur high [SEP] mean warm weather good elimin [SEP]'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_tweet.iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d7f58c5-7808-46b1-b541-63062280a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "# bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf57658d-7846-448f-90e9-a11e2849e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee25759-322a-420b-8a7d-84b2be197b6c",
   "metadata": {},
   "source": [
    "### BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aadc52e-0850-448b-8282-6b35952d9d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 522/522 [02:50<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1542/1542 [08:05<00:00,  3.18it/s]\n"
     ]
    }
   ],
   "source": [
    "max_len = 256\n",
    "dev_tokens = []\n",
    "train_tokens = []\n",
    "\n",
    "for i in tqdm(range(len(dev_tweet))):\n",
    "    txt = dev_tweet.text.iloc[i]\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    if len(tokens) < max_len:\n",
    "         padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "    else:\n",
    "        padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "    attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "    seg_ids = [1 if token == '[SEP]' else 0 for token in padded_tokens]\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    token_ids_t = torch.tensor(token_ids).unsqueeze(0) #Shape : [1, 12]\n",
    "    attn_mask_t = torch.tensor(attn_mask).unsqueeze(0) #Shape : [1, 12]\n",
    "    seg_ids_t   = torch.tensor(seg_ids).unsqueeze(0) #Shape : [1, 12]\n",
    "    outputs = bert_model(token_ids_t, attention_mask = attn_mask_t,\\\n",
    "                                  token_type_ids = seg_ids_t, return_dict=True)\n",
    "    cont_reps = outputs.last_hidden_state\n",
    "    cls_rep = cont_reps[:, 0]\n",
    "    dev_tokens.append(cls_rep.detach().numpy())\n",
    "\n",
    "for i in tqdm(range(len(train_tweet))):\n",
    "    txt = train_tweet.text.iloc[i]\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    if len(tokens) < max_len:\n",
    "         padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "    else:\n",
    "        padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "    attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "    seg_ids = [1 if token == '[SEP]' else 0 for token in padded_tokens]\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    token_ids_t = torch.tensor(token_ids).unsqueeze(0)\n",
    "    attn_mask_t = torch.tensor(attn_mask).unsqueeze(0)\n",
    "    seg_ids_t   = torch.tensor(seg_ids).unsqueeze(0)\n",
    "    outputs = bert_model(token_ids_t, attention_mask = attn_mask_t,\\\n",
    "                                  token_type_ids = seg_ids_t, return_dict=True)\n",
    "    cont_reps = outputs.last_hidden_state\n",
    "    cls_rep = cont_reps[:, 0]\n",
    "    train_tokens.append(cls_rep.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6fad0a-794c-4b6c-8958-07e9a4da423d",
   "metadata": {},
   "source": [
    "### BERT seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9adfbd5-67e1-4334-8ccf-4cb9af1b7580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 536/536 [00:01<00:00, 320.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1579/1579 [00:04<00:00, 358.82it/s]\n"
     ]
    }
   ],
   "source": [
    "max_len = 256\n",
    "dev_seq = []\n",
    "train_seq = []\n",
    "dev_mask = []\n",
    "train_mask = []\n",
    "dev_seg = []\n",
    "train_seg = []\n",
    "\n",
    "for i in tqdm(range(len(dev_tweet))):\n",
    "    txt = dev_tweet.text.iloc[i]\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    if len(tokens) < max_len:\n",
    "         padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "    else:\n",
    "        padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "    attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "    seg_ids = []\n",
    "    seg_idx = 0\n",
    "    for token in padded_tokens:\n",
    "        seg_ids.append(seg_idx)\n",
    "        if token == '[SEP]':\n",
    "            seg_idx += 1\n",
    "    # seg_ids = [1 if token == '[SEP]' else 0 for token in padded_tokens]\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    \n",
    "    dev_seq.append(token_ids)\n",
    "    dev_mask.append(attn_mask)\n",
    "    dev_seg.append(seg_ids)\n",
    "\n",
    "for i in tqdm(range(len(train_tweet))):\n",
    "    txt = train_tweet.text.iloc[i]\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "    if len(tokens) < max_len:\n",
    "         padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "    else:\n",
    "        padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "    attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "    seg_ids = []\n",
    "    seg_idx = 0\n",
    "    for token in padded_tokens:\n",
    "        seg_ids.append(seg_idx)\n",
    "        if token == '[SEP]':\n",
    "            seg_idx += 1\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    \n",
    "    train_seq.append(token_ids)\n",
    "    train_mask.append(attn_mask)\n",
    "    train_seg.append(seg_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0c85e1-9dd7-467c-a3f4-3d49fdbc43a2",
   "metadata": {},
   "source": [
    "### test BERT adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d14e6939-428d-4eb8-b857-e85c5999baa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdTweetDataset(Data.Dataset):\n",
    "    def __init__(self, seq, mask, seg, y):\n",
    "        self.seq = torch.tensor(seq)\n",
    "        self.mask = torch.tensor(mask)\n",
    "        self.seg = torch.tensor(seg)\n",
    "        self.y = torch.tensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.seq.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.seq[idx],self.mask[idx],self.seg[idx], self.y[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c982771-f7de-4e1b-b6ca-25dc0b33d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_tweet['label']\n",
    "y_dev = dev_tweet['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "23186e80-a34a-4888-b065-20a04b64826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = AdTweetDataset(train_seq, train_mask, train_seg,y_train)\n",
    "dev_set = AdTweetDataset(dev_seq, dev_mask, dev_seg, y_dev)\n",
    "\n",
    "train_loader = Data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "dev_loader = Data.DataLoader(dev_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "223b9706-ea79-481e-bb13-8ffe7bff9e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1579, 43)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac4ee5f3-9a21-4305-9296-146e7ae607a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RumorClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RumorClassifier, self).__init__()\n",
    "        #Instantiating BERT model object \n",
    "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        self.ffnn = nn.Sequential(nn.Linear(811,128),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(0.3),\n",
    "                                 nn.Linear(128,64),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(0.3),\n",
    "                                  nn.Linear(64,1),\n",
    "                                  nn.Sigmoid()\n",
    "                                 )\n",
    "\n",
    "    def forward(self, seq, attn_masks, seg, stats):\n",
    "        '''\n",
    "        Inputs:\n",
    "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
    "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
    "        '''\n",
    "\n",
    "        #Feeding the input to BERT model to obtain contextualized representations\n",
    "        outputs = self.bert_layer(seq, attention_mask = attn_masks, return_dict=True)\n",
    "        cont_reps = outputs.last_hidden_state\n",
    "\n",
    "        #Obtaining the representation of [CLS] head (the first token)\n",
    "        cls_rep = cont_reps[:, 0]\n",
    "        \n",
    "        x = torch.cat((cls_rep,stats),dim=1)\n",
    "        #Feeding cls_rep to the classifier layer\n",
    "        logits = self.ffnn(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a15bb73-449a-438b-9037-7e7db3321991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache ()\n",
    "net = RumorClassifier()\n",
    "# net = net.to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "opti = optim.Adam(net.parameters(), lr = 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "99dd698a-ed70-46b8-a860-bb755cba759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_from_logits(logits, labels):\n",
    "    probs = logits.unsqueeze(-1)\n",
    "    soft_probs = (probs > 0.5).long()\n",
    "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
    "    return acc\n",
    "\n",
    "\n",
    "def evaluate(net, criterion, dataloader, device):\n",
    "    net.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq, mask, seg, labels, idx in dataloader:\n",
    "            # seq, labels = seq.to(device), labels.to(device)\n",
    "            stats = np.array(train_stat)\n",
    "            stats = torch.tensor(stats[idx]).float()\n",
    "            #Obtaining the logits from the model\n",
    "            logits = net(seq, mask, seg, stats)\n",
    "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
    "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
    "            count += 1\n",
    "\n",
    "    return mean_acc / count, mean_loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f9666cce-201a-4823-ba27-db02fc97e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "best_acc = 0\n",
    "st = time.time()\n",
    "eps = []\n",
    "t_loss = []\n",
    "d_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeadff2-f94c-405b-a565-edc35d3313c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 of epoch 0 complete. \n",
      " Loss: 0.695245087146759; Accuracy: 0.46875; Time taken (s): 42.096938371658325\n",
      "Iteration 10 of epoch 0 complete. \n",
      " Loss: 0.5917180776596069; Accuracy: 0.75; Time taken (s): 340.0651640892029\n",
      "Iteration 20 of epoch 0 complete. \n",
      " Loss: 0.4908359944820404; Accuracy: 0.828125; Time taken (s): 355.8972201347351\n",
      "Development Accuracy: 0.7887731790542603; Development Loss: 0.503157354063458\n",
      "Iteration 0 of epoch 1 complete. \n",
      " Loss: 0.5917550921440125; Accuracy: 0.703125; Time taken (s): 283.69005393981934\n",
      "Iteration 10 of epoch 1 complete. \n",
      " Loss: 0.4563373625278473; Accuracy: 0.828125; Time taken (s): 348.19206833839417\n",
      "Iteration 20 of epoch 1 complete. \n",
      " Loss: 0.4567403793334961; Accuracy: 0.875; Time taken (s): 345.3861474990845\n",
      "Development Accuracy: 0.7974537014961243; Development Loss: 0.4571463267008464\n",
      "Iteration 0 of epoch 2 complete. \n",
      " Loss: 0.402267187833786; Accuracy: 0.796875; Time taken (s): 284.85521507263184\n",
      "Iteration 10 of epoch 2 complete. \n",
      " Loss: 0.4334788918495178; Accuracy: 0.78125; Time taken (s): 364.91032099723816\n",
      "Iteration 20 of epoch 2 complete. \n",
      " Loss: 0.4155523478984833; Accuracy: 0.828125; Time taken (s): 377.2500886917114\n",
      "Development Accuracy: 0.7934027910232544; Development Loss: 0.46353689829508465\n",
      "Iteration 0 of epoch 3 complete. \n",
      " Loss: 0.3128000795841217; Accuracy: 0.84375; Time taken (s): 295.4464819431305\n",
      "Iteration 10 of epoch 3 complete. \n",
      " Loss: 0.3699989318847656; Accuracy: 0.8125; Time taken (s): 365.2523396015167\n",
      "Iteration 20 of epoch 3 complete. \n",
      " Loss: 0.27350157499313354; Accuracy: 0.90625; Time taken (s): 369.15198826789856\n",
      "Development Accuracy: 0.8177083134651184; Development Loss: 0.399629940589269\n"
     ]
    }
   ],
   "source": [
    "for ep in range(20):\n",
    "    eps.append(ep)\n",
    "    net.train()\n",
    "    for it, (seq, mask, seg, labels,idx) in enumerate(train_loader):\n",
    "        \n",
    "        #Clear gradients\n",
    "        opti.zero_grad()\n",
    "        #Converting these to cuda tensors\n",
    "        # seq, mask, seg, labels = seq.to(device), mask.to(device), seg.to(device), labels.to(device)\n",
    "        \n",
    "        stats = np.array(train_stat)\n",
    "        stats = torch.tensor(stats[idx]).float()\n",
    "        #Obtaining the logits from the model\n",
    "        logits = net(seq, mask, seg, stats)\n",
    "        \n",
    "        #Computing loss\n",
    "        loss = criterion(logits.squeeze(), labels.float())\n",
    "\n",
    "        #Backpropagating the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #Optimization step\n",
    "        opti.step()\n",
    "\n",
    "        if it % 10 == 0:\n",
    "\n",
    "            acc = get_accuracy_from_logits(logits, labels)\n",
    "            print(\"Iteration {} of epoch {} complete. \\n Loss: {}; Accuracy: {}; Time taken (s): {}\".format(it, ep, loss.item(), acc, (time.time()-st)))\n",
    "            st = time.time()\n",
    "\n",
    "        \n",
    "    dev_acc, dev_loss = evaluate(net, criterion, dev_loader, 'cpu')\n",
    "    t_loss.append(loss.item())\n",
    "    d_loss.append(dev_loss)\n",
    "    print(\"Development Accuracy: {}; Development Loss: {}\".format(dev_acc, dev_loss))\n",
    "    torch.save(net.state_dict(), 'D:\\\\bertcls_{}.dat'.format(ep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1dcb13f-d5bf-45df-bcc1-878a789f1315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 of epoch 10 complete. \n",
      " Loss: 0.07849052548408508; Accuracy: 0.984375; Time taken (s): 298.74159240722656\n",
      "Iteration 10 of epoch 10 complete. \n",
      " Loss: 0.054368793964385986; Accuracy: 1.0; Time taken (s): 314.43184447288513\n",
      "Iteration 20 of epoch 10 complete. \n",
      " Loss: 0.07636014372110367; Accuracy: 0.984375; Time taken (s): 312.90769386291504\n",
      "Development Accuracy: 0.9131944179534912; Development Loss: 0.3212054984437095\n",
      "Iteration 0 of epoch 11 complete. \n",
      " Loss: 0.08757798373699188; Accuracy: 0.984375; Time taken (s): 226.64579105377197\n",
      "Iteration 10 of epoch 11 complete. \n",
      " Loss: 0.04345118626952171; Accuracy: 1.0; Time taken (s): 330.0390274524689\n",
      "Iteration 20 of epoch 11 complete. \n",
      " Loss: 0.10141359269618988; Accuracy: 0.984375; Time taken (s): 312.7628083229065\n",
      "Development Accuracy: 0.9281249642372131; Development Loss: 0.2378284881512324\n",
      "Iteration 0 of epoch 12 complete. \n",
      " Loss: 0.07583384215831757; Accuracy: 0.984375; Time taken (s): 230.55237460136414\n",
      "Iteration 10 of epoch 12 complete. \n",
      " Loss: 0.03391951322555542; Accuracy: 1.0; Time taken (s): 335.96146750450134\n",
      "Iteration 20 of epoch 12 complete. \n",
      " Loss: 0.031428176909685135; Accuracy: 1.0; Time taken (s): 315.40473103523254\n",
      "Development Accuracy: 0.9479166865348816; Development Loss: 0.1910394820281201\n",
      "Iteration 0 of epoch 13 complete. \n",
      " Loss: 0.037444308400154114; Accuracy: 1.0; Time taken (s): 233.41523575782776\n",
      "Iteration 10 of epoch 13 complete. \n",
      " Loss: 0.16626055538654327; Accuracy: 0.953125; Time taken (s): 317.86219906806946\n",
      "Iteration 20 of epoch 13 complete. \n",
      " Loss: 0.09661096334457397; Accuracy: 0.984375; Time taken (s): 307.6020395755768\n",
      "Development Accuracy: 0.9357638955116272; Development Loss: 0.22219043142265743\n",
      "Iteration 0 of epoch 14 complete. \n",
      " Loss: 0.18432402610778809; Accuracy: 0.953125; Time taken (s): 228.72738075256348\n",
      "Iteration 10 of epoch 14 complete. \n",
      " Loss: 0.04904412478208542; Accuracy: 1.0; Time taken (s): 304.3992097377777\n",
      "Iteration 20 of epoch 14 complete. \n",
      " Loss: 0.10542275756597519; Accuracy: 0.984375; Time taken (s): 315.03060722351074\n",
      "Development Accuracy: 0.9496527910232544; Development Loss: 0.16587353352871206\n",
      "Iteration 0 of epoch 15 complete. \n",
      " Loss: 0.031054746359586716; Accuracy: 1.0; Time taken (s): 227.97458577156067\n",
      "Iteration 10 of epoch 15 complete. \n",
      " Loss: 0.04391176998615265; Accuracy: 1.0; Time taken (s): 317.7657687664032\n",
      "Iteration 20 of epoch 15 complete. \n",
      " Loss: 0.025241993367671967; Accuracy: 1.0; Time taken (s): 308.1505627632141\n",
      "Development Accuracy: 0.9461805820465088; Development Loss: 0.18580661631292766\n",
      "Iteration 0 of epoch 16 complete. \n",
      " Loss: 0.027261588722467422; Accuracy: 1.0; Time taken (s): 230.36909365653992\n",
      "Iteration 10 of epoch 16 complete. \n",
      " Loss: 0.1116090714931488; Accuracy: 0.984375; Time taken (s): 304.9308364391327\n",
      "Iteration 20 of epoch 16 complete. \n",
      " Loss: 0.06476198881864548; Accuracy: 0.984375; Time taken (s): 317.16039514541626\n",
      "Development Accuracy: 0.9444444179534912; Development Loss: 0.20953774260770944\n",
      "Iteration 0 of epoch 17 complete. \n",
      " Loss: 0.08017657697200775; Accuracy: 0.984375; Time taken (s): 234.90545320510864\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits\u001b[38;5;241m.\u001b[39msqueeze(), labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#Backpropagating the gradients\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#Optimization step\u001b[39;00m\n\u001b[0;32m     23\u001b[0m opti\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(10,20):\n",
    "    eps.append(ep)\n",
    "    net.train()\n",
    "    for it, (seq, mask, seg, labels,idx) in enumerate(train_loader):\n",
    "        \n",
    "        #Clear gradients\n",
    "        opti.zero_grad()\n",
    "        #Converting these to cuda tensors\n",
    "        # seq, mask, seg, labels = seq.to(device), mask.to(device), seg.to(device), labels.to(device)\n",
    "        \n",
    "        stats = np.array(train_stat.iloc[:,1:])\n",
    "        stats = torch.tensor(stats[idx]).float()\n",
    "        #Obtaining the logits from the model\n",
    "        logits = net(seq, mask, seg, stats)\n",
    "        \n",
    "        #Computing loss\n",
    "        loss = criterion(logits.squeeze(), labels.float())\n",
    "\n",
    "        #Backpropagating the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #Optimization step\n",
    "        opti.step()\n",
    "\n",
    "        if it % 10 == 0:\n",
    "\n",
    "            acc = get_accuracy_from_logits(logits, labels)\n",
    "            print(\"Iteration {} of epoch {} complete. \\n Loss: {}; Accuracy: {}; Time taken (s): {}\".format(it, ep, loss.item(), acc, (time.time()-st)))\n",
    "            st = time.time()\n",
    "\n",
    "        \n",
    "    dev_acc, dev_loss = evaluate(net, criterion, dev_loader, 'cpu')\n",
    "    t_loss.append(loss.item())\n",
    "    d_loss.append(dev_loss)\n",
    "    print(\"Development Accuracy: {}; Development Loss: {}\".format(dev_acc, dev_loss))\n",
    "    torch.save(net.state_dict(), 'D:\\\\bertcls_{}.dat'.format(ep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a29684-320a-4f85-aa16-51ce4e227314",
   "metadata": {},
   "source": [
    "### Text Only Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d35c4291-4528-4ff0-853b-36d828760796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRumorClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TextRumorClassifier, self).__init__()\n",
    "        #Instantiating BERT model object \n",
    "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        self.ffnn = nn.Sequential(nn.Linear(768,128),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(0.3),\n",
    "                                 nn.Linear(128,64),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(0.3),\n",
    "                                  nn.Linear(64,1),\n",
    "                                  nn.Sigmoid()\n",
    "                                 )\n",
    "\n",
    "    def forward(self, seq, attn_masks, seg):\n",
    "        '''\n",
    "        Inputs:\n",
    "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
    "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
    "        '''\n",
    "\n",
    "        #Feeding the input to BERT model to obtain contextualized representations\n",
    "        outputs = self.bert_layer(seq, attention_mask = attn_masks, return_dict=True)\n",
    "        cont_reps = outputs.last_hidden_state\n",
    "\n",
    "        #Obtaining the representation of [CLS] head (the first token)\n",
    "        cls_rep = cont_reps[:, 0]\n",
    "        \n",
    "        # x = torch.cat((cls_rep,stats),dim=1)\n",
    "        #Feeding cls_rep to the classifier layer\n",
    "        logits = self.ffnn(cls_rep)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fe7e7a2-650c-4e24-aeb3-ee256bdcae7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "net = TextRumorClassifier()\n",
    "# net = net.to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "opti = optim.Adam(net.parameters(), lr = 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f46bc5bb-8c33-4806-85ca-2b0e1380b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_evaluate(net, criterion, dataloader, device):\n",
    "    net.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq, mask, seg, labels, idx in dataloader:\n",
    "            # seq, labels = seq.to(device), labels.to(device)\n",
    "            # stats = np.array(train_stat.iloc[:,1:])\n",
    "            # stats = torch.tensor(stats[idx]).float()\n",
    "            #Obtaining the logits from the model\n",
    "            logits = net(seq, mask, seg)\n",
    "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
    "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
    "            count += 1\n",
    "\n",
    "    return mean_acc / count, mean_loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09e88416-c6ea-457f-94c7-be1087fc15f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "best_acc = 0\n",
    "st = time.time()\n",
    "eps = []\n",
    "t_loss = []\n",
    "d_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a32a1b2f-72a6-4f05-a43a-9d9b94694e3f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 of epoch 0 complete. \n",
      " Loss: 0.6802356839179993; Accuracy: 0.671875; Time taken (s): 81.13227605819702\n",
      "Iteration 10 of epoch 0 complete. \n",
      " Loss: 0.5898295044898987; Accuracy: 0.78125; Time taken (s): 299.43943309783936\n",
      "Iteration 20 of epoch 0 complete. \n",
      " Loss: 0.5761324763298035; Accuracy: 0.75; Time taken (s): 298.0222783088684\n",
      "Development Accuracy: 0.7715277671813965; Development Loss: 0.5319444206025865\n",
      "Iteration 0 of epoch 1 complete. \n",
      " Loss: 0.5774604678153992; Accuracy: 0.734375; Time taken (s): 220.4582164287567\n",
      "Iteration 10 of epoch 1 complete. \n",
      " Loss: 0.4819682836532593; Accuracy: 0.8125; Time taken (s): 296.9613416194916\n",
      "Iteration 20 of epoch 1 complete. \n",
      " Loss: 0.45131972432136536; Accuracy: 0.796875; Time taken (s): 297.24166321754456\n",
      "Development Accuracy: 0.7996528148651123; Development Loss: 0.43302328056759304\n",
      "Iteration 0 of epoch 2 complete. \n",
      " Loss: 0.4024360477924347; Accuracy: 0.8125; Time taken (s): 225.989727973938\n",
      "Iteration 10 of epoch 2 complete. \n",
      " Loss: 0.4486580789089203; Accuracy: 0.765625; Time taken (s): 297.42676305770874\n",
      "Iteration 20 of epoch 2 complete. \n",
      " Loss: 0.4015752673149109; Accuracy: 0.765625; Time taken (s): 302.4298474788666\n",
      "Development Accuracy: 0.7715277671813965; Development Loss: 0.40253406431939864\n",
      "Iteration 0 of epoch 3 complete. \n",
      " Loss: 0.3700542151927948; Accuracy: 0.859375; Time taken (s): 221.20544385910034\n",
      "Iteration 10 of epoch 3 complete. \n",
      " Loss: 0.3114929795265198; Accuracy: 0.875; Time taken (s): 296.1478228569031\n",
      "Iteration 20 of epoch 3 complete. \n",
      " Loss: 0.4102683663368225; Accuracy: 0.703125; Time taken (s): 297.2571277618408\n",
      "Development Accuracy: 0.7809027433395386; Development Loss: 0.3777681522899204\n",
      "Iteration 0 of epoch 4 complete. \n",
      " Loss: 0.3427141010761261; Accuracy: 0.890625; Time taken (s): 218.97034573554993\n",
      "Iteration 10 of epoch 4 complete. \n",
      " Loss: 0.3261837065219879; Accuracy: 0.859375; Time taken (s): 297.1521053314209\n",
      "Iteration 20 of epoch 4 complete. \n",
      " Loss: 0.1853872537612915; Accuracy: 1.0; Time taken (s): 297.5361819267273\n",
      "Development Accuracy: 0.8743055462837219; Development Loss: 0.3650273084640503\n",
      "Iteration 0 of epoch 5 complete. \n",
      " Loss: 0.23465262353420258; Accuracy: 0.953125; Time taken (s): 220.8443422317505\n",
      "Iteration 10 of epoch 5 complete. \n",
      " Loss: 0.2828870117664337; Accuracy: 0.90625; Time taken (s): 296.63211154937744\n",
      "Iteration 20 of epoch 5 complete. \n",
      " Loss: 0.23903009295463562; Accuracy: 0.9375; Time taken (s): 296.602587223053\n",
      "Development Accuracy: 0.8656250238418579; Development Loss: 0.31499414808220333\n",
      "Iteration 0 of epoch 6 complete. \n",
      " Loss: 0.2568912208080292; Accuracy: 0.90625; Time taken (s): 220.6560664176941\n",
      "Iteration 10 of epoch 6 complete. \n",
      " Loss: 0.247569739818573; Accuracy: 0.953125; Time taken (s): 297.4129750728607\n",
      "Iteration 20 of epoch 6 complete. \n",
      " Loss: 0.21808868646621704; Accuracy: 0.953125; Time taken (s): 303.97619438171387\n",
      "Development Accuracy: 0.8732638955116272; Development Loss: 0.384066647125615\n",
      "Iteration 0 of epoch 7 complete. \n",
      " Loss: 0.19976870715618134; Accuracy: 0.9375; Time taken (s): 220.87582063674927\n",
      "Iteration 10 of epoch 7 complete. \n",
      " Loss: 0.27573078870773315; Accuracy: 0.921875; Time taken (s): 296.1779816150665\n",
      "Iteration 20 of epoch 7 complete. \n",
      " Loss: 0.18678443133831024; Accuracy: 0.953125; Time taken (s): 297.39706158638\n",
      "Development Accuracy: 0.9340277910232544; Development Loss: 0.22147591825988558\n",
      "Iteration 0 of epoch 8 complete. \n",
      " Loss: 0.10352814942598343; Accuracy: 0.984375; Time taken (s): 220.7351589202881\n",
      "Iteration 10 of epoch 8 complete. \n",
      " Loss: 0.22030408680438995; Accuracy: 0.953125; Time taken (s): 296.3964297771454\n",
      "Iteration 20 of epoch 8 complete. \n",
      " Loss: 0.19165925681591034; Accuracy: 0.953125; Time taken (s): 296.3505527973175\n",
      "Development Accuracy: 0.9211804866790771; Development Loss: 0.24064936406082577\n",
      "Iteration 0 of epoch 9 complete. \n",
      " Loss: 0.150380939245224; Accuracy: 0.96875; Time taken (s): 218.93811440467834\n",
      "Iteration 10 of epoch 9 complete. \n",
      " Loss: 0.18152907490730286; Accuracy: 0.96875; Time taken (s): 331.6500794887543\n",
      "Iteration 20 of epoch 9 complete. \n",
      " Loss: 0.1733761727809906; Accuracy: 0.96875; Time taken (s): 296.8183481693268\n",
      "Development Accuracy: 0.9083333611488342; Development Loss: 0.22732179363568625\n",
      "Iteration 0 of epoch 10 complete. \n",
      " Loss: 0.09950870275497437; Accuracy: 0.984375; Time taken (s): 221.98526763916016\n",
      "Iteration 10 of epoch 10 complete. \n",
      " Loss: 0.09946000576019287; Accuracy: 1.0; Time taken (s): 296.6942472457886\n",
      "Iteration 20 of epoch 10 complete. \n",
      " Loss: 0.08078835904598236; Accuracy: 0.984375; Time taken (s): 297.30266857147217\n",
      "Development Accuracy: 0.9281249642372131; Development Loss: 0.22359735684262383\n",
      "Iteration 0 of epoch 11 complete. \n",
      " Loss: 0.16118431091308594; Accuracy: 0.96875; Time taken (s): 221.00080060958862\n",
      "Iteration 10 of epoch 11 complete. \n",
      " Loss: 0.18316838145256042; Accuracy: 0.96875; Time taken (s): 303.366548538208\n",
      "Iteration 20 of epoch 11 complete. \n",
      " Loss: 0.11347579956054688; Accuracy: 0.96875; Time taken (s): 297.30295848846436\n",
      "Development Accuracy: 0.9322916865348816; Development Loss: 0.20730443360904852\n",
      "Iteration 0 of epoch 12 complete. \n",
      " Loss: 0.1285964399576187; Accuracy: 0.984375; Time taken (s): 218.70448565483093\n",
      "Iteration 10 of epoch 12 complete. \n",
      " Loss: 0.11941289901733398; Accuracy: 0.984375; Time taken (s): 296.63081550598145\n",
      "Iteration 20 of epoch 12 complete. \n",
      " Loss: 0.058265190571546555; Accuracy: 1.0; Time taken (s): 297.2467796802521\n",
      "Development Accuracy: 0.9281249642372131; Development Loss: 0.25157110227478874\n",
      "Iteration 0 of epoch 13 complete. \n",
      " Loss: 0.060456059873104095; Accuracy: 0.984375; Time taken (s): 220.57226514816284\n",
      "Iteration 10 of epoch 13 complete. \n",
      " Loss: 0.1359124779701233; Accuracy: 0.96875; Time taken (s): 296.16311144828796\n",
      "Iteration 20 of epoch 13 complete. \n",
      " Loss: 0.24394303560256958; Accuracy: 0.9375; Time taken (s): 296.1930947303772\n",
      "Development Accuracy: 0.9315971732139587; Development Loss: 0.2178215417597029\n",
      "Iteration 0 of epoch 14 complete. \n",
      " Loss: 0.043951794505119324; Accuracy: 1.0; Time taken (s): 219.92360663414001\n",
      "Iteration 10 of epoch 14 complete. \n",
      " Loss: 0.03783406689763069; Accuracy: 1.0; Time taken (s): 295.7859377861023\n",
      "Iteration 20 of epoch 14 complete. \n",
      " Loss: 0.10898635536432266; Accuracy: 0.984375; Time taken (s): 295.7577893733978\n",
      "Development Accuracy: 0.9409722089767456; Development Loss: 0.2148100563014547\n",
      "Iteration 0 of epoch 15 complete. \n",
      " Loss: 0.03337579220533371; Accuracy: 1.0; Time taken (s): 220.61015558242798\n",
      "Iteration 10 of epoch 15 complete. \n",
      " Loss: 0.031077606603503227; Accuracy: 1.0; Time taken (s): 301.6768755912781\n",
      "Iteration 20 of epoch 15 complete. \n",
      " Loss: 0.030278261750936508; Accuracy: 1.0; Time taken (s): 294.6953103542328\n",
      "Development Accuracy: 0.9281249642372131; Development Loss: 0.29197897513707477\n",
      "Iteration 0 of epoch 16 complete. \n",
      " Loss: 0.18090198934078217; Accuracy: 0.96875; Time taken (s): 220.5163128376007\n",
      "Iteration 10 of epoch 16 complete. \n",
      " Loss: 0.037820782512426376; Accuracy: 1.0; Time taken (s): 294.73997259140015\n",
      "Iteration 20 of epoch 16 complete. \n",
      " Loss: 0.031452666968107224; Accuracy: 1.0; Time taken (s): 295.52116107940674\n",
      "Development Accuracy: 0.9246527552604675; Development Loss: 0.2850782523552577\n",
      "Iteration 0 of epoch 17 complete. \n",
      " Loss: 0.08480245620012283; Accuracy: 0.984375; Time taken (s): 220.00190448760986\n",
      "Iteration 10 of epoch 17 complete. \n",
      " Loss: 0.038943544030189514; Accuracy: 1.0; Time taken (s): 294.96084427833557\n",
      "Iteration 20 of epoch 17 complete. \n",
      " Loss: 0.08793707191944122; Accuracy: 0.984375; Time taken (s): 296.37982153892517\n",
      "Development Accuracy: 0.9409722089767456; Development Loss: 0.23112470884290007\n",
      "Iteration 0 of epoch 18 complete. \n",
      " Loss: 0.09463363140821457; Accuracy: 0.984375; Time taken (s): 218.76718187332153\n",
      "Iteration 10 of epoch 18 complete. \n",
      " Loss: 0.07292123138904572; Accuracy: 0.984375; Time taken (s): 297.42747044563293\n",
      "Iteration 20 of epoch 18 complete. \n",
      " Loss: 0.09867572039365768; Accuracy: 0.984375; Time taken (s): 297.27133989334106\n",
      "Development Accuracy: 0.9392361044883728; Development Loss: 0.21728208433422777\n",
      "Iteration 0 of epoch 19 complete. \n",
      " Loss: 0.085542231798172; Accuracy: 0.984375; Time taken (s): 221.0791130065918\n",
      "Iteration 10 of epoch 19 complete. \n",
      " Loss: 0.110785573720932; Accuracy: 0.984375; Time taken (s): 296.2733783721924\n",
      "Iteration 20 of epoch 19 complete. \n",
      " Loss: 0.031884439289569855; Accuracy: 1.0; Time taken (s): 303.8342869281769\n",
      "Development Accuracy: 0.9315971732139587; Development Loss: 0.25821830415063435\n"
     ]
    }
   ],
   "source": [
    "for ep in range(20):\n",
    "    eps.append(ep)\n",
    "    net.train()\n",
    "    for it, (seq, mask, seg, labels,idx) in enumerate(train_loader):\n",
    "\n",
    "        #Clear gradients\n",
    "        opti.zero_grad()\n",
    "        #Converting these to cuda tensors\n",
    "        # seq, mask, seg, labels = seq.to(device), mask.to(device), seg.to(device), labels.to(device)\n",
    "\n",
    "        # stats = np.array(train_stat.iloc[:,1:])\n",
    "        # stats = torch.tensor(stats[idx]).float()\n",
    "        #Obtaining the logits from the model\n",
    "        logits = net(seq, mask, seg)\n",
    "\n",
    "        #Computing loss\n",
    "        loss = criterion(logits.squeeze(), labels.float())\n",
    "\n",
    "        #Backpropagating the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #Optimization step\n",
    "        opti.step()\n",
    "\n",
    "        if it % 10 == 0:\n",
    "\n",
    "            acc = get_accuracy_from_logits(logits, labels)\n",
    "            print(\"Iteration {} of epoch {} complete. \\n Loss: {}; Accuracy: {}; Time taken (s): {}\".format(it, ep, loss.item(), acc, (time.time()-st)))\n",
    "            st = time.time()\n",
    "\n",
    "\n",
    "    dev_acc, dev_loss = text_evaluate(net, criterion, dev_loader, 'cpu')\n",
    "    t_loss.append(loss.item())\n",
    "    d_loss.append(dev_loss)\n",
    "    print(\"Development Accuracy: {}; Development Loss: {}\".format(dev_acc, dev_loss))\n",
    "    torch.save(net.state_dict(), 'D:\\\\bertcls_{}.dat'.format(ep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadfc51b-742c-4c70-8752-4fb30faf7ba8",
   "metadata": {},
   "source": [
    "### Text Only Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47479f40-9744-4907-87fa-6a1d151aa79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = TextRumorClassifier()\n",
    "text_model.load_state_dict(torch.load('D:\\\\bertcls_14.dat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a20adf9e-5a46-40e8-b365-bc0e52ad1397",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet = pd.read_csv('./sep_data/test_tweet_df.csv')\n",
    "test_stat = pd.read_csv('./sep_data/test_stat_feat_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20176d53-9f25-43b5-bf3d-1bb0279eb141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/558 [00:00<?, ?it/s]C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_6104\\3174842241.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_tweet.text.iloc[i] = '[CLS] ' + str(test_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(test_tweet.reply_text.iloc[i]).strip()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 558/558 [00:08<00:00, 68.94it/s]\n"
     ]
    }
   ],
   "source": [
    "test_tweet.text.fillna('', inplace=True)\n",
    "test_tweet.reply_text.fillna('', inplace=True)\n",
    "for i in tqdm(range(len(test_tweet))):\n",
    "    test_tweet.text.iloc[i] = '[CLS] ' + str(test_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(test_tweet.reply_text.iloc[i]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4afdab8d-8f34-4e24-999d-517f8407b5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 558/558 [00:02<00:00, 270.06it/s]\n"
     ]
    }
   ],
   "source": [
    "max_len = 256\n",
    "test_seq = []\n",
    "test_mask = []\n",
    "test_seg = []\n",
    "\n",
    "for i in tqdm(range(len(test_tweet))):\n",
    "    try:\n",
    "        txt = test_tweet.text.iloc[i]\n",
    "        tokens = tokenizer.tokenize(txt)\n",
    "        if len(tokens) < max_len:\n",
    "             padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "        else:\n",
    "            padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "        attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "        seg_ids = []\n",
    "        seg_idx = 0\n",
    "        for token in padded_tokens:\n",
    "            seg_ids.append(seg_idx)\n",
    "            if token == '[SEP]':\n",
    "                seg_idx += 1\n",
    "        token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "\n",
    "        test_seq.append(token_ids)\n",
    "        test_mask.append(attn_mask)\n",
    "        test_seg.append(seg_ids)\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5521f55-9298-4586-ba4f-cb65883f31b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 558/558 [02:19<00:00,  4.01it/s]\n"
     ]
    }
   ],
   "source": [
    "text_model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_seq))):\n",
    "        seq = torch.tensor(test_seq[i]).unsqueeze(0)\n",
    "        mask = torch.tensor(test_mask[i]).unsqueeze(0)\n",
    "        seg = torch.tensor(test_seg[i]).unsqueeze(0)\n",
    "        \n",
    "        preds.append(text_model(seq,mask,seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d823e06d-a924-40a0-b4c4-610f79be8a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(preds)):\n",
    "    preds[i] = preds[i].squeeze().squeeze()\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    preds[i] = preds[i].numpy()\n",
    "\n",
    "predictions = preds[0]\n",
    "for i in range(1,len(preds)):\n",
    "    predictions = np.hstack((predictions,preds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5abe73fe-7769-40ed-858e-3ad1d862f41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {'Id':[i for i in range(len(predictions))], 'Predicted':predictions}\n",
    "pred_df = DataFrame(pred_dict)\n",
    "pred_df.Predicted = pred_df.Predicted.apply(lambda x: 1 if x > 0.5 else 0)\n",
    "pred_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f622652f-5545-4a44-8e17-4581e9852eff",
   "metadata": {},
   "source": [
    "### BERT TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1a22695-b546-4db3-b35f-dc59b70ef88c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RumorClassifier()\n",
    "model.load_state_dict(torch.load('D:\\\\bert_feat/bertcls_14.dat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "260e407b-3dfe-4c14-bfc0-9e2f4c3ae50b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dev_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[1;32m----> 2\u001b[0m dev_acc, dev_loss \u001b[38;5;241m=\u001b[39m evaluate(model, criterion, \u001b[43mdev_loader\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDevelopment Accuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m; Development Loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dev_acc, dev_loss))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dev_loader' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "dev_acc, dev_loss = evaluate(model, criterion, dev_loader, 'cpu')\n",
    "print(\"Development Accuracy: {}; Development Loss: {}\".format(dev_acc, dev_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00683eb0-e793-4e20-8d29-d8a9530783db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_tweet = pd.read_csv('./sep_data/test_tweet_df.csv')\n",
    "test_stat = pd.read_csv('./sep_data/test_stat_feat_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a50c9a8c-f5e2-45a8-9f64-94331ce0dc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_id.1</th>\n",
       "      <th>text</th>\n",
       "      <th>reply_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1246482832316301319</td>\n",
       "      <td>1246482832316301319</td>\n",
       "      <td>covid spread</td>\n",
       "      <td>thank wcco station trust media provid true new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1252279738099433473</td>\n",
       "      <td>1252279738099433473</td>\n",
       "      <td>hate keep say capit implod without crisi capit...</td>\n",
       "      <td>believ look chang week [SEP] tell peopl protes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1236050255394877440</td>\n",
       "      <td>1236050255394877440</td>\n",
       "      <td>covid influenza virus differ coronaviru</td>\n",
       "      <td>covid influenza virus similar coronaviru [SEP]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1235582115900796928</td>\n",
       "      <td>1235582115900796928</td>\n",
       "      <td>una de le q coronavirus de la pàgina web de q ...</td>\n",
       "      <td>aquesta informació es basa sobr tot en un arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1258787515592572928</td>\n",
       "      <td>1258787515592572928</td>\n",
       "      <td>absolut blame politician whoever els involv ho...</td>\n",
       "      <td>forget racism institut peopl insid ineffect te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>518827403452637184</td>\n",
       "      <td>518827403452637184</td>\n",
       "      <td>hewlett packard plan split two compani wsj report</td>\n",
       "      <td>heward packlett [SEP] hewlett packard plan spl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>489829414704648192</td>\n",
       "      <td>489829414704648192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>580348081100734464</td>\n",
       "      <td>580348081100734464</td>\n",
       "      <td>germanw sorri confirm passeng crew board fligh...</td>\n",
       "      <td>sad news germanw sorri confirm passeng crew bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1248121143808098305</td>\n",
       "      <td>1248121143808098305</td>\n",
       "      <td>sure differ path mean differ need need say yea...</td>\n",
       "      <td>sometim still stop track believ insulin free w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1258487399014858752</td>\n",
       "      <td>1258487399014858752</td>\n",
       "      <td>depend get drive vehicl alreadi gass plan some...</td>\n",
       "      <td>mayb miss someth would unsaf famili go away da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id           tweet_id.1  \\\n",
       "0  1246482832316301319  1246482832316301319   \n",
       "1  1252279738099433473  1252279738099433473   \n",
       "2  1236050255394877440  1236050255394877440   \n",
       "3  1235582115900796928  1235582115900796928   \n",
       "4  1258787515592572928  1258787515592572928   \n",
       "5   518827403452637184   518827403452637184   \n",
       "6   489829414704648192   489829414704648192   \n",
       "7   580348081100734464   580348081100734464   \n",
       "8  1248121143808098305  1248121143808098305   \n",
       "9  1258487399014858752  1258487399014858752   \n",
       "\n",
       "                                                text  \\\n",
       "0                                       covid spread   \n",
       "1  hate keep say capit implod without crisi capit...   \n",
       "2            covid influenza virus differ coronaviru   \n",
       "3  una de le q coronavirus de la pàgina web de q ...   \n",
       "4  absolut blame politician whoever els involv ho...   \n",
       "5  hewlett packard plan split two compani wsj report   \n",
       "6                                                NaN   \n",
       "7  germanw sorri confirm passeng crew board fligh...   \n",
       "8  sure differ path mean differ need need say yea...   \n",
       "9  depend get drive vehicl alreadi gass plan some...   \n",
       "\n",
       "                                          reply_text  \n",
       "0  thank wcco station trust media provid true new...  \n",
       "1  believ look chang week [SEP] tell peopl protes...  \n",
       "2  covid influenza virus similar coronaviru [SEP]...  \n",
       "3  aquesta informació es basa sobr tot en un arti...  \n",
       "4  forget racism institut peopl insid ineffect te...  \n",
       "5  heward packlett [SEP] hewlett packard plan spl...  \n",
       "6                                                NaN  \n",
       "7  sad news germanw sorri confirm passeng crew bo...  \n",
       "8  sometim still stop track believ insulin free w...  \n",
       "9  mayb miss someth would unsaf famili go away da...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e8d702b-131a-4018-8c63-dd9ad312693a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_id.1</th>\n",
       "      <th>reply_like_count</th>\n",
       "      <th>reply_retweet_count</th>\n",
       "      <th>reply_possibly_sensitive</th>\n",
       "      <th>reply_has_url</th>\n",
       "      <th>reply_mentioned_url_num</th>\n",
       "      <th>reply_id_num</th>\n",
       "      <th>reply_isweekday</th>\n",
       "      <th>reply_senti_score</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>has_url</th>\n",
       "      <th>mentioned_url_num</th>\n",
       "      <th>id_num</th>\n",
       "      <th>isweekday</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>senti_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1246482832316301319</td>\n",
       "      <td>1246482832316301319</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003898</td>\n",
       "      <td>0.130314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1252279738099433473</td>\n",
       "      <td>1252279738099433473</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.040848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1236050255394877440</td>\n",
       "      <td>1236050255394877440</td>\n",
       "      <td>1.306053e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1235582115900796928</td>\n",
       "      <td>1235582115900796928</td>\n",
       "      <td>2.612105e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018072</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1258787515592572928</td>\n",
       "      <td>1258787515592572928</td>\n",
       "      <td>3.918158e-06</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.008529</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.054334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>427944719612915712</td>\n",
       "      <td>427944719612915712</td>\n",
       "      <td>1.306053e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.096916</td>\n",
       "      <td>0.070652</td>\n",
       "      <td>0.025586</td>\n",
       "      <td>0.138554</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.304593</td>\n",
       "      <td>0.339669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>531206167302012929</td>\n",
       "      <td>531206167302012929</td>\n",
       "      <td>7.183289e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237885</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.065032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.077014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>553099685888790528</td>\n",
       "      <td>553099685888790528</td>\n",
       "      <td>6.530263e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039648</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.013859</td>\n",
       "      <td>0.054217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.132341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>1222928724112396288</td>\n",
       "      <td>1222928724112396288</td>\n",
       "      <td>8.162828e-05</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.033049</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.175863</td>\n",
       "      <td>0.055059</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1239324381215707139</td>\n",
       "      <td>1239324381215707139</td>\n",
       "      <td>1.306053e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.015546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id           tweet_id.1  reply_like_count  \\\n",
       "0    1246482832316301319  1246482832316301319      0.000000e+00   \n",
       "1    1252279738099433473  1252279738099433473      0.000000e+00   \n",
       "2    1236050255394877440  1236050255394877440      1.306053e-06   \n",
       "3    1235582115900796928  1235582115900796928      2.612105e-06   \n",
       "4    1258787515592572928  1258787515592572928      3.918158e-06   \n",
       "..                   ...                  ...               ...   \n",
       "553   427944719612915712   427944719612915712      1.306053e-06   \n",
       "554   531206167302012929   531206167302012929      7.183289e-06   \n",
       "555   553099685888790528   553099685888790528      6.530263e-07   \n",
       "556  1222928724112396288  1222928724112396288      8.162828e-05   \n",
       "557  1239324381215707139  1239324381215707139      1.306053e-06   \n",
       "\n",
       "     reply_retweet_count  reply_possibly_sensitive  reply_has_url  \\\n",
       "0               0.000000                  0.000000       0.004405   \n",
       "1               0.000000                  0.000000       0.013216   \n",
       "2               0.000000                  0.000000       0.008811   \n",
       "3               0.000004                  0.000000       0.004405   \n",
       "4               0.000021                  0.000000       0.022026   \n",
       "..                   ...                       ...            ...   \n",
       "553             0.000004                  0.076923       0.096916   \n",
       "554             0.000004                  0.000000       0.237885   \n",
       "555             0.000004                  0.000000       0.039648   \n",
       "556             0.000176                  0.000000       0.017621   \n",
       "557             0.000007                  0.000000       0.008811   \n",
       "\n",
       "     reply_mentioned_url_num  reply_id_num  reply_isweekday  \\\n",
       "0                   0.000000      0.001066         0.006024   \n",
       "1                   0.000000      0.007463         0.036145   \n",
       "2                   0.010870      0.000000         0.012048   \n",
       "3                   0.005435      0.000000         0.018072   \n",
       "4                   0.005435      0.008529         0.036145   \n",
       "..                       ...           ...              ...   \n",
       "553                 0.070652      0.025586         0.138554   \n",
       "554                 0.010870      0.065032         0.000000   \n",
       "555                 0.016304      0.013859         0.054217   \n",
       "556                 0.021739      0.033049         0.024096   \n",
       "557                 0.000000      0.001066         0.000000   \n",
       "\n",
       "     reply_senti_score  ...  retweet_count  possibly_sensitive  has_url  \\\n",
       "0             0.014493  ...       0.000000                 0.0      1.0   \n",
       "1             0.028986  ...       0.000000                 0.0      0.0   \n",
       "2             0.000000  ...       0.000000                 0.0      1.0   \n",
       "3             0.014493  ...       0.000566                 0.0      0.0   \n",
       "4             0.014493  ...       0.000000                 0.0      0.0   \n",
       "..                 ...  ...            ...                 ...      ...   \n",
       "553           0.057971  ...       0.018676                 0.0      1.0   \n",
       "554           0.144928  ...       0.023769                 0.0      1.0   \n",
       "555           0.000000  ...       0.047821                 0.0      1.0   \n",
       "556           0.043478  ...       0.002688                 0.0      1.0   \n",
       "557           0.014493  ...       0.000141                 0.0      1.0   \n",
       "\n",
       "     mentioned_url_num    id_num  isweekday  followers_count  tweet_count  \\\n",
       "0             0.666667  0.000000        0.0         0.003898     0.130314   \n",
       "1             0.000000  0.020408        1.0         0.000010     0.040848   \n",
       "2             0.333333  0.000000        1.0         0.000164     0.000037   \n",
       "3             0.000000  0.000000        1.0         0.000002     0.000082   \n",
       "4             0.000000  0.020408        1.0         0.000004     0.054334   \n",
       "..                 ...       ...        ...              ...          ...   \n",
       "553           0.333333  0.000000        1.0         0.304593     0.339669   \n",
       "554           0.000000  0.000000        0.0         0.008266     0.077014   \n",
       "555           0.666667  0.000000        1.0         0.003944     0.132341   \n",
       "556           0.666667  0.142857        1.0         0.175863     0.055059   \n",
       "557           0.000000  0.000000        0.0         0.000027     0.015546   \n",
       "\n",
       "     verified  senti_score  \n",
       "0         1.0          0.0  \n",
       "1         0.0          0.0  \n",
       "2         0.0          0.0  \n",
       "3         0.0          0.0  \n",
       "4         0.0          1.0  \n",
       "..        ...          ...  \n",
       "553       1.0          0.0  \n",
       "554       1.0          0.0  \n",
       "555       1.0          0.0  \n",
       "556       1.0          0.0  \n",
       "557       0.0          1.0  \n",
       "\n",
       "[558 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f29bdc2-5848-4d0f-8339-b2f69fcc0b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 558 entries, 0 to 557\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_id    558 non-null    int64 \n",
      " 1   tweet_id.1  558 non-null    int64 \n",
      " 2   text        557 non-null    object\n",
      " 3   reply_text  538 non-null    object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 17.6+ KB\n"
     ]
    }
   ],
   "source": [
    "test_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7e3d74d-9603-4dec-b820-cbc49488afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet.text.fillna('', inplace=True)\n",
    "test_tweet.reply_text.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1069919-5425-4456-9ac5-159877e11660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/558 [00:00<?, ?it/s]C:\\Users\\trist\\AppData\\Local\\Temp\\ipykernel_8384\\3605878176.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_tweet.text.iloc[i] = '[CLS] ' + str(test_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(test_tweet.reply_text.iloc[i]).strip()\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 558/558 [00:09<00:00, 60.98it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(test_tweet))):\n",
    "    test_tweet.text.iloc[i] = '[CLS] ' + str(test_tweet.text.iloc[i]).strip() + ' [SEP] ' + str(test_tweet.reply_text.iloc[i]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca68fd5e-aee4-4c2c-917a-43293615b737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 558/558 [00:02<00:00, 267.64it/s]\n"
     ]
    }
   ],
   "source": [
    "max_len = 256\n",
    "test_seq = []\n",
    "test_mask = []\n",
    "test_seg = []\n",
    "\n",
    "for i in tqdm(range(len(test_tweet))):\n",
    "    try:\n",
    "        txt = test_tweet.text.iloc[i]\n",
    "        tokens = tokenizer.tokenize(txt)\n",
    "        if len(tokens) < max_len:\n",
    "             padded_tokens = tokens + ['[PAD]' for _ in range(max_len - len(tokens))]\n",
    "        else:\n",
    "            padded_tokens = tokens[:max_len-1] + ['[SEP]']\n",
    "        attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "        seg_ids = []\n",
    "        seg_idx = 0\n",
    "        for token in padded_tokens:\n",
    "            seg_ids.append(seg_idx)\n",
    "            if token == '[SEP]':\n",
    "                seg_idx += 1\n",
    "        token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "\n",
    "        test_seq.append(token_ids)\n",
    "        test_mask.append(attn_mask)\n",
    "        test_seg.append(seg_ids)\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9e8b069-72a0-483b-80ef-5b9b0144f168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 558 entries, 0 to 557\n",
      "Data columns (total 22 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   tweet_id                  558 non-null    int64  \n",
      " 1   tweet_id.1                558 non-null    int64  \n",
      " 2   reply_like_count          558 non-null    float64\n",
      " 3   reply_retweet_count       558 non-null    float64\n",
      " 4   reply_possibly_sensitive  558 non-null    float64\n",
      " 5   reply_has_url             558 non-null    float64\n",
      " 6   reply_mentioned_url_num   558 non-null    float64\n",
      " 7   reply_id_num              558 non-null    float64\n",
      " 8   reply_isweekday           558 non-null    float64\n",
      " 9   reply_senti_score         558 non-null    float64\n",
      " 10  reply_count               558 non-null    float64\n",
      " 11  like_count                558 non-null    float64\n",
      " 12  retweet_count             558 non-null    float64\n",
      " 13  possibly_sensitive        558 non-null    float64\n",
      " 14  has_url                   558 non-null    float64\n",
      " 15  mentioned_url_num         558 non-null    float64\n",
      " 16  id_num                    558 non-null    float64\n",
      " 17  isweekday                 558 non-null    float64\n",
      " 18  followers_count           558 non-null    float64\n",
      " 19  tweet_count               558 non-null    float64\n",
      " 20  verified                  558 non-null    float64\n",
      " 21  senti_score               558 non-null    float64\n",
      "dtypes: float64(20), int64(2)\n",
      "memory usage: 96.0 KB\n"
     ]
    }
   ],
   "source": [
    "test_stat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c8cbb8e-eee5-4b5c-86a5-2e0c90d1e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TestTweetDataset(Data.Dataset):\n",
    "#     def __init__(self, seq, mask, seg, stat):\n",
    "#         self.seq = torch.tensor(seq).long()\n",
    "#         self.mask = torch.tensor(mask).long()\n",
    "#         self.seg = torch.tensor(seg).long()\n",
    "#         self.stat = torch.tensor(stat).float()\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return self.seq.shape[0]\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.seq[idx],self.mask[idx],self.seg[idx], self.stat[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dac9a35a-5c60-4c32-971f-45a71480dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set = TestTweetDataset(test_seq, test_mask, test_seg, np.array(test_stat)[:,1:])\n",
    "# test_loader = Data.DataLoader(test_set, batch_size=32, shuffle=False, sampler=range(0,len(test_seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "414569d8-a18d-4254-8f94-5ee19c83d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stat = np.array(test_stat)[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "312437ab-3532-449c-b63a-f77446597e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 558/558 [02:23<00:00,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# import gc\n",
    "model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_seq))):\n",
    "        seq = torch.tensor(test_seq[i]).unsqueeze(0)\n",
    "        mask = torch.tensor(test_mask[i]).unsqueeze(0)\n",
    "        seg = torch.tensor(test_seg[i]).unsqueeze(0)\n",
    "        stat = torch.tensor(test_stat[i]).unsqueeze(0).float()\n",
    "        \n",
    "        preds.append(model(seq,mask,seg,stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "241ffe91-d5aa-4a3d-b66c-c739dd44f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(preds)):\n",
    "    preds[i] = preds[i].squeeze().squeeze()\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    preds[i] = preds[i].numpy()\n",
    "\n",
    "predictions = preds[0]\n",
    "for i in range(1,len(preds)):\n",
    "    predictions = np.hstack((predictions,preds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e2c52ee-7db7-478b-8f67-bd7bf181764a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00960896, 0.00972752, 0.00952085, 0.00978349, 0.0104391 ,\n",
       "       0.17435533, 0.6147145 , 0.9618389 , 0.00954586, 0.01426145,\n",
       "       0.01516318, 0.32869858, 0.00991426, 0.6351997 , 0.00942757,\n",
       "       0.00944686, 0.02072934, 0.00936503, 0.00947986, 0.00995967,\n",
       "       0.95477647, 0.00959419, 0.00965702, 0.96135086, 0.00954165,\n",
       "       0.00977335, 0.00943139, 0.67121005, 0.00956026, 0.96181905,\n",
       "       0.00997709, 0.9615813 , 0.01532578, 0.0093721 , 0.00945348,\n",
       "       0.00941826, 0.00936474, 0.00941862, 0.94664955, 0.51345754,\n",
       "       0.00931383, 0.89557517, 0.00974124, 0.04241318, 0.00954079,\n",
       "       0.00941966, 0.00941116, 0.5701327 , 0.00936734, 0.00946443,\n",
       "       0.00968444, 0.00958827, 0.96103114, 0.02022663, 0.00948627,\n",
       "       0.96206814, 0.9604501 , 0.00952147, 0.00958719, 0.00958838,\n",
       "       0.00936145, 0.96135813, 0.00983435, 0.00952646, 0.00983512,\n",
       "       0.0094028 , 0.9579737 , 0.01116851, 0.00933218, 0.01339473,\n",
       "       0.00944619, 0.00932573, 0.0094994 , 0.96128994, 0.00941288,\n",
       "       0.9615127 , 0.00937868, 0.96196413, 0.9617269 , 0.00980053,\n",
       "       0.5364651 , 0.00944636, 0.9619311 , 0.0099092 , 0.96091175,\n",
       "       0.00959348, 0.00987326, 0.00948552, 0.0095325 , 0.00954024,\n",
       "       0.01160125, 0.0094523 , 0.00942333, 0.00970132, 0.00934071,\n",
       "       0.01313484, 0.00978746, 0.00940457, 0.01158286, 0.00951761,\n",
       "       0.00945798, 0.01463985, 0.00989658, 0.96039826, 0.00944428,\n",
       "       0.00958273, 0.9570497 , 0.01007599, 0.00954784, 0.9608912 ,\n",
       "       0.02072001, 0.00955202, 0.00951079, 0.00941361, 0.01043322,\n",
       "       0.06007635, 0.009618  , 0.00944576, 0.42290956, 0.01021707,\n",
       "       0.9617117 , 0.00944742, 0.0094262 , 0.0096989 , 0.00939907,\n",
       "       0.96114916, 0.96187985, 0.01594543, 0.00955731, 0.96199775,\n",
       "       0.9618469 , 0.00948626, 0.16827372, 0.00939254, 0.00942734,\n",
       "       0.9494649 , 0.00937276, 0.9599103 , 0.00948939, 0.00944802,\n",
       "       0.01111157, 0.00957765, 0.9585521 , 0.00936445, 0.51309144,\n",
       "       0.00946717, 0.00945388, 0.9611527 , 0.00959743, 0.00940863,\n",
       "       0.00943261, 0.03670104, 0.00953251, 0.00993945, 0.46885896,\n",
       "       0.9613517 , 0.00997777, 0.0094857 , 0.3619478 , 0.00942681,\n",
       "       0.961696  , 0.9616949 , 0.00978135, 0.01341956, 0.9618966 ,\n",
       "       0.00942914, 0.01167663, 0.00939095, 0.00938828, 0.00941857,\n",
       "       0.00954421, 0.9618805 , 0.00945868, 0.96152717, 0.96070236,\n",
       "       0.0102143 , 0.00963869, 0.0094478 , 0.00997342, 0.00954   ,\n",
       "       0.0094682 , 0.00954992, 0.00946122, 0.01070585, 0.00932171,\n",
       "       0.00938394, 0.00949412, 0.00944052, 0.9615199 , 0.01117542,\n",
       "       0.5196286 , 0.00938651, 0.0096384 , 0.00941685, 0.00945887,\n",
       "       0.00952266, 0.00964027, 0.00938482, 0.00941806, 0.00939434,\n",
       "       0.00950087, 0.94916874, 0.00942937, 0.00934973, 0.9532995 ,\n",
       "       0.00938542, 0.87943614, 0.00940917, 0.00956663, 0.00941892,\n",
       "       0.02172121, 0.96158856, 0.54043686, 0.95848864, 0.96182835,\n",
       "       0.01231433, 0.96108353, 0.00949433, 0.9591384 , 0.93002355,\n",
       "       0.00939825, 0.0141722 , 0.00934192, 0.00953026, 0.00952686,\n",
       "       0.00946307, 0.00948061, 0.01228843, 0.0094485 , 0.0094747 ,\n",
       "       0.01025971, 0.03502991, 0.0097823 , 0.0095082 , 0.0095786 ,\n",
       "       0.009892  , 0.0093991 , 0.96157473, 0.00928319, 0.9288056 ,\n",
       "       0.00946303, 0.9614719 , 0.00951334, 0.00967345, 0.00936327,\n",
       "       0.9585882 , 0.01258158, 0.00949085, 0.00945094, 0.00959316,\n",
       "       0.00978236, 0.00940666, 0.00989675, 0.01082904, 0.00941835,\n",
       "       0.00940788, 0.29724932, 0.6208809 , 0.00963025, 0.00936554,\n",
       "       0.00961459, 0.9503843 , 0.0094761 , 0.00936184, 0.00933281,\n",
       "       0.00965281, 0.01238381, 0.00970858, 0.9620903 , 0.00938773,\n",
       "       0.00956781, 0.96178156, 0.00947832, 0.928933  , 0.00938314,\n",
       "       0.00981427, 0.00940501, 0.9598622 , 0.00938881, 0.9604772 ,\n",
       "       0.01006652, 0.00966375, 0.00947439, 0.9616012 , 0.01524979,\n",
       "       0.00994298, 0.00942594, 0.00970507, 0.9612376 , 0.00938054,\n",
       "       0.01076131, 0.00938371, 0.05639477, 0.0093192 , 0.9607959 ,\n",
       "       0.00966692, 0.00935248, 0.00957591, 0.00943746, 0.00942679,\n",
       "       0.01160583, 0.00941111, 0.95204216, 0.953269  , 0.00940062,\n",
       "       0.00972611, 0.00938914, 0.01732556, 0.00956349, 0.01157351,\n",
       "       0.00936141, 0.00934394, 0.00942814, 0.07557201, 0.00945954,\n",
       "       0.0095418 , 0.00941134, 0.00974964, 0.01462441, 0.00954067,\n",
       "       0.8612607 , 0.00952617, 0.9620908 , 0.9597943 , 0.9619651 ,\n",
       "       0.00937513, 0.00930978, 0.00944373, 0.00951969, 0.010159  ,\n",
       "       0.00941018, 0.95884454, 0.00951553, 0.00952209, 0.01062138,\n",
       "       0.5125293 , 0.00942082, 0.9620334 , 0.010848  , 0.9620206 ,\n",
       "       0.00996545, 0.01000859, 0.00956142, 0.00944258, 0.00947288,\n",
       "       0.07141114, 0.9618107 , 0.00937029, 0.00939849, 0.70133656,\n",
       "       0.9615328 , 0.0099926 , 0.96121764, 0.00957137, 0.00957683,\n",
       "       0.00958624, 0.00943448, 0.0096803 , 0.96161634, 0.00949861,\n",
       "       0.00939168, 0.00942321, 0.96181655, 0.0097849 , 0.00967119,\n",
       "       0.00965241, 0.00937322, 0.00935713, 0.31970733, 0.00935406,\n",
       "       0.00951294, 0.0093848 , 0.96160924, 0.96108055, 0.00954245,\n",
       "       0.16234674, 0.00939732, 0.00949703, 0.9619489 , 0.01132522,\n",
       "       0.47227642, 0.00947528, 0.9611025 , 0.00944255, 0.955686  ,\n",
       "       0.0095641 , 0.00943035, 0.00942124, 0.00946011, 0.9621252 ,\n",
       "       0.00944517, 0.00938337, 0.00956309, 0.7626197 , 0.00958316,\n",
       "       0.00951771, 0.00933996, 0.00985467, 0.00948441, 0.01027278,\n",
       "       0.95848686, 0.962076  , 0.00940724, 0.9608328 , 0.00954873,\n",
       "       0.00974881, 0.9601121 , 0.46986452, 0.00945288, 0.00951091,\n",
       "       0.00954628, 0.9616401 , 0.88645446, 0.00952127, 0.9612224 ,\n",
       "       0.93861353, 0.00958506, 0.0094502 , 0.00942952, 0.0095773 ,\n",
       "       0.29604602, 0.1799427 , 0.9617646 , 0.9182048 , 0.9616131 ,\n",
       "       0.01123948, 0.00944345, 0.01073077, 0.00932355, 0.00941965,\n",
       "       0.9407797 , 0.06047646, 0.02767019, 0.00972645, 0.00937701,\n",
       "       0.0094283 , 0.00963974, 0.0096288 , 0.00960887, 0.9589318 ,\n",
       "       0.0101128 , 0.96140605, 0.00990194, 0.00947442, 0.00945085,\n",
       "       0.0096622 , 0.2564023 , 0.00944585, 0.00945488, 0.01059586,\n",
       "       0.42542318, 0.00940998, 0.95174253, 0.00962554, 0.96114564,\n",
       "       0.96137595, 0.00949642, 0.87646043, 0.00943324, 0.01316516,\n",
       "       0.00952265, 0.00948811, 0.01067083, 0.00954196, 0.00945112,\n",
       "       0.9446003 , 0.00992331, 0.00943362, 0.9620056 , 0.00941946,\n",
       "       0.00949377, 0.00949343, 0.0094463 , 0.00941876, 0.9561682 ,\n",
       "       0.9613636 , 0.8770227 , 0.00951709, 0.01755567, 0.00962607,\n",
       "       0.00943125, 0.00952383, 0.0094983 , 0.00949717, 0.0095342 ,\n",
       "       0.00943737, 0.9616559 , 0.00932876, 0.00950096, 0.00951981,\n",
       "       0.00945569, 0.00957244, 0.9615471 , 0.00946928, 0.00939837,\n",
       "       0.00944462, 0.82195747, 0.00937226, 0.00968139, 0.01011415,\n",
       "       0.00938665, 0.96133274, 0.00963666, 0.01095337, 0.00940982,\n",
       "       0.01074625, 0.96167684, 0.00937825, 0.00950294, 0.00956198,\n",
       "       0.00938127, 0.01006103, 0.00959528, 0.00966759, 0.9291802 ,\n",
       "       0.00957628, 0.961449  , 0.00940058, 0.9620107 , 0.00934863,\n",
       "       0.00944407, 0.00955157, 0.00949293, 0.96039206, 0.00945276,\n",
       "       0.01068227, 0.00943265, 0.00965537, 0.00945968, 0.01875288,\n",
       "       0.00971592, 0.00938356, 0.00938278, 0.63807374, 0.96191394,\n",
       "       0.009402  , 0.00941396, 0.00938923, 0.02145126, 0.0095522 ,\n",
       "       0.00946844, 0.0093643 , 0.00952848, 0.00952846, 0.00961114,\n",
       "       0.00942502, 0.00998056, 0.03088425, 0.0093621 , 0.9607125 ,\n",
       "       0.01125766, 0.00973345, 0.96157235, 0.00966295, 0.00989289,\n",
       "       0.96064216, 0.00938139, 0.00934749], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58b84233-9e78-44c6-b99d-932f91109f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {'Id':[i for i in range(len(predictions))], 'Predicted':predictions}\n",
    "pred_df = DataFrame(pred_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3574adbd-b4af-4ce4-b873-b03161c54ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.009609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.009521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.009783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.010439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>553</td>\n",
       "      <td>0.009663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>554</td>\n",
       "      <td>0.009893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>555</td>\n",
       "      <td>0.960642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>556</td>\n",
       "      <td>0.009381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>557</td>\n",
       "      <td>0.009347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Predicted\n",
       "0      0   0.009609\n",
       "1      1   0.009728\n",
       "2      2   0.009521\n",
       "3      3   0.009783\n",
       "4      4   0.010439\n",
       "..   ...        ...\n",
       "553  553   0.009663\n",
       "554  554   0.009893\n",
       "555  555   0.960642\n",
       "556  556   0.009381\n",
       "557  557   0.009347\n",
       "\n",
       "[558 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8de5c313-831d-4d7f-bbe2-7ee219671ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.Predicted = pred_df.Predicted.apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d67d4be5-0389-48af-af69-3471cbc6bdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.Predicted.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c4b7f3f-999d-4a6b-9b1a-a0adf646462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3fe9a67-e3d7-4dc3-aaa3-1cd5232428a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('predictions1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9e3e681-7d3e-403e-85d3-e669ae16c956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(a)):\n",
    "    if a.iloc[i].Predicted != pred_df.iloc[i].Predicted:\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70c29698-030b-4be7-918d-b8942f828d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(558, 256)\n",
      "(558, 24)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(test_seq).shape)\n",
    "print(np.array(test_stat).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e4a48f8-54cb-4ec0-a742-c9d19d74f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = torch.tensor(test_seq).long()\n",
    "test_mask = torch.tensor(test_mask).long()\n",
    "test_seg = torch.tensor(test_seg).long()\n",
    "test_stat = torch.tensor(np.array(test_stat)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b8c5b1-37c1-4333-a42b-ece0470ed583",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "test_stat = np.array(test_stat)\n",
    "for i in range(len(test_seq)):\n",
    "    seq = torch.tensor(test_seq[i]).long().unsqueeze(0)\n",
    "    mask = torch.tensor(test_mask[i]).long().unsqueeze(0)\n",
    "    seg = torch.tensor(test_seg[i]).long().unsqueeze(0)\n",
    "    stat = torch.tensor(test_stat[i,1:]).float().unsqueeze(0)\n",
    "    preds.append(model(seq, mask, seg, stat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e460c87-f926-4d28-bef7-93dc439938af",
   "metadata": {},
   "source": [
    "### Create Train and Dev Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "feecfa1f-4cfe-498b-acdd-7ea02a534380",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_dev = []\n",
    "for i in range(train_stat.shape[0]):\n",
    "    X_train.append(list(train_tokens[i].reshape(-1)))\n",
    "    for j in range(1,train_stat.shape[1]):\n",
    "        X_train[i].append(train_stat.iloc[i,j])\n",
    "\n",
    "for i in range(dev_stat.shape[0]):\n",
    "    X_dev.append(list(dev_tokens[i].reshape(-1)))\n",
    "    for j in range(1,dev_stat.shape[1]):\n",
    "        X_dev[i].append(dev_stat.iloc[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4450b35a-db76-45dc-8139-435a7f25e6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1542"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "442b807a-76ac-4cb9-b6a1-f3c0fed6ad63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "791"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3382aaff-cdec-4aa9-9f64-4ae2cafae6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_tweet['label']\n",
    "y_dev = dev_tweet['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e435d-c046-4abf-bc48-8363c3aa35ec",
   "metadata": {},
   "source": [
    "### Test on simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e804cab2-226c-4c48-b725-5940eba222d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1e0a2bed-a9c8-4176-a6e9-dff543d9272b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.867816091954023"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(predictions, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7a2b01c3-66e6-45f3-bf3e-a0f6259d66fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.943579766536965"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = lr.predict(X_train)\n",
    "accuracy_score(train_preds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "030b153a-0955-4dbc-9a82-38a0ca5f640b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6609195402298851"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "accuracy_score(gnb.predict(X_dev), y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9bdb3ba2-1573-4a79-94d2-371ccedffd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('X_train.pkl', 'wb') as file:\n",
    "    pickle.dump(X_train, file)\n",
    "with open('X_dev.pkl', 'wb') as file:\n",
    "    pickle.dump(X_dev, file)\n",
    "with open('y_train.pkl', 'wb') as file:\n",
    "    pickle.dump(list(y_train), file)\n",
    "with open('y_dev.pkl', 'wb') as file:\n",
    "    pickle.dump(list(y_dev), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a39838-4e40-4d32-a268-0445606cd164",
   "metadata": {},
   "source": [
    "### Test simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4d72b566-f8d7-4da6-8933-78a1bdd0ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mlp, self).__init__()\n",
    "        self.ffnn = nn.Sequential(nn.Linear(791,128),\n",
    "                                  nn.ReLU(),\n",
    "                                  # nn.Dropout(0.3),\n",
    "                                 nn.Linear(128,64),\n",
    "                                  nn.ReLU(),\n",
    "                                  # nn.Dropout(0.3),\n",
    "                                  nn.Linear(64,1),\n",
    "                                  nn.Sigmoid()\n",
    "                                 )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.ffnn(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ef89ef1c-17d2-416b-974e-71a914a25c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b334580150>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d50aff54-ec06-4038-8187-b2d2dc4e6033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "EPOCH = 5\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8d055d7b-773e-4d50-b92e-0155c0a54037",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_dev = np.array(X_dev)\n",
    "y_train = np.array(y_train)\n",
    "y_dev = np.array(y_dev)\n",
    "X = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "y = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "dev_X = torch.from_numpy(X_dev).type(torch.FloatTensor)\n",
    "dev_y = torch.from_numpy(y_dev).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "70a0b495-7d5c-40b5-bffb-76c7aaa151b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1542"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e33cc3f4-b096-4594-974b-ee9995d5c9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "296dc716-edd7-4ce6-b663-efb7fe28f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TweetDataset(X,y)\n",
    "dev_set = TweetDataset(dev_X, dev_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f355687f-8290-42c9-9dda-f8e72d35acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_loader = Data.DataLoader(dev_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "78c34c8c-9150-4c49-9ba5-e08d0e4d0d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, criterion, dataloader, device):\n",
    "    net.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq, labels in dataloader:\n",
    "            seq, labels = seq.to(device), labels.to(device)\n",
    "            logits = net(seq)\n",
    "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
    "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
    "            count += 1\n",
    "\n",
    "    return mean_acc / count, mean_loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7749fc1b-31f6-4621-977f-1b0815999566",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mlp()\n",
    "net = net.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "opti = optim.Adam(net.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "14e9825f-acd4-417d-8e84-57894369eed6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 of epoch 0 complete. \n",
      " Loss: 0.02590068057179451; Accuracy: 1.0; Time taken (s): 0.004000186920166016\n",
      "Development Accuracy: 0.8802083134651184; Development Loss: 0.434159043762419\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "best_acc = 0\n",
    "st = time.time()\n",
    "eps = []\n",
    "t_loss = []\n",
    "d_loss = []\n",
    "for ep in range(1):\n",
    "    eps.append(ep)\n",
    "    net.train()\n",
    "    for it, (seq, labels) in enumerate(train_loader):\n",
    "        \n",
    "        #Clear gradients\n",
    "        opti.zero_grad()\n",
    "        #Converting these to cuda tensors\n",
    "        seq, labels = seq.to(device), labels.to(device)\n",
    "\n",
    "        #Obtaining the logits from the model\n",
    "        logits = net(seq)\n",
    "        \n",
    "        #Computing loss\n",
    "        loss = criterion(logits.squeeze(), labels.float())\n",
    "\n",
    "        #Backpropagating the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #Optimization step\n",
    "        opti.step()\n",
    "\n",
    "        if it % 100 == 0:\n",
    "\n",
    "            acc = get_accuracy_from_logits(logits, labels)\n",
    "            print(\"Iteration {} of epoch {} complete. \\n Loss: {}; Accuracy: {}; Time taken (s): {}\".format(it, ep, loss.item(), acc, (time.time()-st)))\n",
    "            st = time.time()\n",
    "\n",
    "        \n",
    "    dev_acc, dev_loss = evaluate(net, criterion, dev_loader, device)\n",
    "    t_loss.append(loss.item())\n",
    "    d_loss.append(dev_loss)\n",
    "    print(\"Development Accuracy: {}; Development Loss: {}\".format(dev_acc, dev_loss))\n",
    "    if dev_acc > best_acc:\n",
    "        # print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, dev_acc))\n",
    "        best_acc = dev_acc\n",
    "        # torch.save(net.state_dict(), 'sstcls_{}.dat'.format(ep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "289e761b-9b28-4e76-a02c-31eabbc776a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(eps,t_loss)\n",
    "plt.plot(eps,d_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "95f7cc04-ce28-417b-a1d4-41cc3bb75eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'sstcls_{}.dat'.format(ep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b707ac33-63aa-4e81-b71e-604078a51291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
