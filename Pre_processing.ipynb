{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/HandanYU/Rumour-detection/blob/main/Pre_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fY6now2OGTd"
   },
   "source": [
    "- replace_abbreviations\n",
    "- remove url \n",
    "- get the emoji and replace them as words\n",
    "- remove stop words\n",
    "- keep only english letters\n",
    "- stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYirQl2NPOE6",
    "outputId": "f1cb8b6b-ba64-4306-fb55-7f395c23cb76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=5a92f91dcf134fc24011694b0e97f509edb85899e2f6e4aeb666514621a3bb94\n",
      "  Stored in directory: c:\\users\\trist\\appdata\\local\\pip\\cache\\wheels\\5e\\8c\\80\\c3646df8201ba6f5070297fe3779a4b70265d0bfd961c15302\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-1.7.0\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: click in c:\\users\\trist\\anaconda3\\envs\\pytorch\\lib\\site-packages (from nltk) (8.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\trist\\anaconda3\\envs\\pytorch\\lib\\site-packages (from nltk) (4.63.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\trist\\anaconda3\\envs\\pytorch\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\trist\\anaconda3\\envs\\pytorch\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\trist\\anaconda3\\envs\\pytorch\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.7\n"
     ]
    }
   ],
   "source": [
    "# !pip install emoji\n",
    "# !pip install nltk\n",
    "# !pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort raw data by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer('ms')\n",
    "\n",
    "def sort_by_time(raw_file, json_file):\n",
    "    with open(raw_file) as file:\n",
    "        ids = file.readlines()\n",
    "\n",
    "    with open(json_file, 'r+') as file:\n",
    "        content = file.read()\n",
    "        content=json.loads(content)\n",
    "        df = pd.DataFrame(content)\n",
    "        df = df.T\n",
    "\n",
    "    save_name = raw_file[:-4] + '_sorted.txt'\n",
    "    with open(save_name, 'w') as file:\n",
    "        date = pd.Series(pd.DatetimeIndex(df.iloc[:, 6]), index=df.index)\n",
    "        df.drop(['created_at'], axis=1, inplace=True)\n",
    "        df['time'] = date\n",
    "\n",
    "        for id_ in ids:\n",
    "            ids_ = id_.strip().split(',')\n",
    "            source_id = ids_[0]\n",
    "            file.write(source_id)\n",
    "            if len(ids_) > 1:\n",
    "                reply_ids = ids_[1:]\n",
    "                reply_ids[-1] = reply_ids[-1].replace('\\n', '')\n",
    "                valid_ids = [index for index in reply_ids if index in df.index]\n",
    "                sorted_replies = df.loc[valid_ids].sort_values(by='time')\n",
    "                if len(valid_ids) > 0:\n",
    "                    file.write(',')\n",
    "\n",
    "                for i, index in enumerate(sorted_replies.index):\n",
    "                    file.write(index)\n",
    "                    if i != len(sorted_replies.index) - 1:\n",
    "                        file.write(',')\n",
    "\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_files = ['train.data.txt', 'dev.data.txt']\n",
    "json_files = ['./filtered data/train_reply.json', './filtered data/dev_reply.json']\n",
    "for raw_file, json_file in zip(raw_files, json_files):\n",
    "    sort_by_time(raw_file, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(raw_files[0]) as file:\n",
    "    train = file.readlines()\n",
    "with open('train.data_sorted.txt') as file:\n",
    "    s = file.readlines()\n",
    "assert len(train) == len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "d-oy_gqAPf32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuhandan/anaconda3/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.8' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "import json\n",
    "import pandas as pd\n",
    "from utils import timer\n",
    "from datetime import datetime\n",
    "from textblob import TextBlob\n",
    "# from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/yuhandan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "stopword = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NOc33_ivOCT_"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "@timer('ms')\n",
    "# def replace_duplicate_letter(word):\n",
    "#     repeat_reg = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "#     repl = r'\\1\\2\\3'\n",
    "#     if wordnet.synsets(word):  # 判断当前字符串是否是单词\n",
    "#         return word\n",
    "#     repl_word = repeat_reg.sub(repl, word)\n",
    "#     if repl_word != word:\n",
    "#         return replace_duplicate_letter(repl_word)\n",
    "#     else:\n",
    "#         return repl_word\n",
    "  \n",
    "def clean_tweet(content):\n",
    "    from time import strftime\n",
    "    # def compute_num_month(content):\n",
    "    #     month_num = 0\n",
    "    #     month = [\"january\", \"february\", \"march\", \"april\", \"may\", \"june\", \"july\", \"august\", \"september\", \"octorber\", \"november\", \"december\", \n",
    "    #             \"jan.\", \"feb.\", \"mar.\", \"apr.\", \"may.\", \"jun.\", \"jul.\", \"aug.\", \"sept.\", \"oct.\", \"nov.\", \"dec.\"]\n",
    "    #     for i in content:\n",
    "    #         if i in month:\n",
    "    #             month_num += 1\n",
    "    #     return month_num\n",
    "    # replace_abbreviations\n",
    "    content = content.lower()\n",
    "    content = re.sub(r\"won't\", \"will not\", content)\n",
    "    content = re.sub(r\"can't\", \"can not\", content)\n",
    "    content = re.sub(r\"cannot\", \"can not\", content)\n",
    "    content = re.sub(r\"n't\", \" not\", content)\n",
    "    content = re.sub(r\"'re\", \" are\", content)\n",
    "    content = re.sub(r\"'s\", \" is\", content)\n",
    "    content = re.sub(r\"'d\", \" would\", content)\n",
    "    content = re.sub(r\"'ll\", \" will\", content)\n",
    "    content = re.sub(r\"'t\", \" not\", content)\n",
    "    content = re.sub(r\"'ve\", \" have\", content)\n",
    "    content = re.sub(r\"'m\", \" am\", content)\n",
    "    content = re.sub(r\".”\", \" \", content)\n",
    "    \n",
    "    # get the number of month be mentioned\n",
    "    # month_num = compute_num_month(content)\n",
    "\n",
    "    # get the number of url\n",
    "    mentioned_url_num = len(re.findall(r'https?://[^ ]+', content))\n",
    "    mentioned_url_num += len(re.findall(r'www.[^ ]+', content))\n",
    "    # get the number of twitter ID be mentioned\n",
    "    id_num = len(re.findall(r'@[A-Za-z0-9_]+', content))\n",
    "    content = re.sub(r'@[A-Za-z0-9_]+', '', content) # remove twitter ID\n",
    "    # remove url \n",
    "    ## http, https\n",
    "    content = re.sub(r'https?://[^ ]+', '', content) \n",
    "    ## www.\n",
    "    content = re.sub(r'www.[^ ]+', '', content)\n",
    "    # get the emoji and replace them as words\n",
    "    emojis = emoji.distinct_emoji_list(content)\n",
    "    for e in emojis:\n",
    "        content = re.sub(e, emoji.demojize(e), content)\n",
    "    content = re.sub('\\w+\\d+\\w+', '', content) # remove the word contains numbers\n",
    "    \n",
    "    content = re.sub(r'[:_!+“\\-=——,$%^\\?\\\\~\\\"\\'@#$%&*<>{}\\[\\]()/]', ' ', content) # remove punctuation, except .\n",
    "    \n",
    "    content = re.sub(r\"\\s+\", \" \", content) # conver multiple spaces as a single space\n",
    "    content = content.strip()\n",
    "    \n",
    "    # remove stop words \n",
    "    # TODO: and keep only english letters\n",
    "    \n",
    "    content = [c for c in content.split(' ') if c not in stopword and c.isalpha()]\n",
    "    # do stemming\n",
    "    content = [stemmer.stem(token.strip()) for token in content]\n",
    "    \n",
    "    return ' '.join(content), mentioned_url_num, id_num \n",
    "    #, month_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QzSuMwzhPKnd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @timer('ms')\n",
    "def json2df(json_file):\n",
    "    \"\"\"\n",
    "    json_file: 'train_reply.json'\n",
    "    \"\"\"\n",
    "    with open(json_file,'r+') as file:\n",
    "        content = file.read()\n",
    "    content = json.loads(content)\n",
    "    df = pd.DataFrame(content)\n",
    "    df = df.T\n",
    "    return df\n",
    "# df = json2df('train_reply.json')\n",
    "def clean_data(data_type):\n",
    "  \"\"\"\n",
    "  Args: \n",
    "    data_type: 'dev', 'train'\n",
    "  Returns:\n",
    "    source_df, reply_df\n",
    "  \"\"\"\n",
    "  source_df = json2df(f'./data/full data/{data_type}_source.json')\n",
    "  source_df['temp'] = source_df['text'].apply(lambda x: clean_tweet(x))\n",
    "  source_df['text'] = source_df['temp'].apply(lambda x: x[0])\n",
    "  source_df['mentioned_url_num'] = source_df['temp'].apply(lambda x: x[1])\n",
    "  source_df['id_num'] = source_df['temp'].apply(lambda x: x[2])\n",
    "  source_df = source_df.drop(columns='temp')\n",
    "  source_df['tweet_id'] = source_df.index\n",
    "\n",
    "  reply_df = json2df(f'./data/full data/{data_type}_reply.json')\n",
    "  reply_df['temp'] = reply_df['text'].apply(lambda x: clean_tweet(x))\n",
    "  reply_df['text'] = reply_df['temp'].apply(lambda x: x[0])\n",
    "  reply_df['mentioned_url_num'] = reply_df['temp'].apply(lambda x: x[1])\n",
    "  reply_df['id_num'] = reply_df['temp'].apply(lambda x: x[2])\n",
    "  reply_df = reply_df.drop(columns='temp')\n",
    "  reply_df['tweet_id'] = reply_df.index\n",
    "  \n",
    "  return source_df, reply_df\n",
    "# train_source_df, train_reply_df = clean_data('train')\n",
    "\n",
    "# dev_source_df, dev_reply_df = clean_data('dev')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def concat_label(data_type, source_feature_df):\n",
    "    \"\"\"Concat labels on source tweets\n",
    "    data_type: 'dev', 'train'\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(columns=['tweet_id', 'label'])\n",
    "    with open(f'./data/original_data/{data_type}_source.txt', 'r') as f:\n",
    "        ids = f.readlines()\n",
    "    with open(f'./data/original_data/{data_type}.label.txt', 'r') as f:\n",
    "        labels = f.readlines()\n",
    "    df['tweet_id'] = [id.strip() for id in ids]\n",
    "    df['label'] = [label.strip() for label in labels]\n",
    "    df_labels = pd.merge(source_feature_df, df, on='tweet_id', how='left')\n",
    "    df_labels['label'] = df_labels['label'].apply(lambda x: 0 if x == 'nonrumour' else 1)\n",
    "    return df_labels\n",
    "\n",
    "# dev_source_df = concat_label('dev', dev_source_df)\n",
    "# train_source_df = concat_label('train', train_source_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat Sorted reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_reply(data_type, source_df):\n",
    "    \"\"\"concat replies on source tweets\n",
    "    data_type: 'dev', 'train'\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(columns=['tweet_id', 'reply'])\n",
    "    with open(f'./data/original_data/{data_type}.data_sorted.txt', 'r') as f:\n",
    "        content = f.readlines()\n",
    "    df['tweet_id'] = [c.split(',')[0].strip() for c in content]\n",
    "    df['reply'] = [','.join([i.strip() for i in c.split(',')[1:]]) for c in content]\n",
    "    source_df = pd.merge(source_df, df, on='tweet_id', how='left')\n",
    "    return source_df\n",
    "\n",
    "# dev_source_df = concat_reply('dev', dev_source_df)\n",
    "# train_source_df = concat_reply('train', train_source_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check whether the created date is on weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_weekday(df):\n",
    "    \"\"\"\n",
    "    df: source_df or reply_df\n",
    "    \"\"\"\n",
    "    df['isoweekday'] = df['created_at'].apply(lambda x: datetime.strptime(x.split('T')[0], '%Y-%m-%d').isoweekday())\n",
    "    df['isweekday'] = df['isoweekday'].apply(lambda x: 1 <= x <= 5)\n",
    "    df = df.drop(columns='isoweekday')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat user info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_user_info(data_type, source_df):\n",
    "    \"\"\"concat user info on source tweets\n",
    "    data_type: 'dev', 'train'\n",
    "    \"\"\"\n",
    "    df = json2df(f'./data/full data/{data_type}_source_userinfo.json')\n",
    "    df['user_id'] = df.index\n",
    "    source_df = pd.merge(source_df, df, on='user_id', how='left')\n",
    "    return source_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat reply's features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_reply_info(reply_ids, reply_df, statis_feature):\n",
    "    statistic_dict = dict()   \n",
    "    replies_txt = ''\n",
    "    if reply_ids == '':\n",
    "        return [None] * (len(statis_feature) + 1)\n",
    "    for r in reply_ids.split(','):\n",
    "        # reply_num = len(reply_ids.split(','))\n",
    "        replies_txt += reply_df.loc[r]['text']\n",
    "        ## get statistic features\n",
    "        for f in statis_feature:\n",
    "            statistic_dict[f] = statistic_dict.get(f, 0) + int(reply_df.loc[r][f])    \n",
    "    res_values = [replies_txt]\n",
    "    for f in statis_feature:\n",
    "        res_values.append(statistic_dict[f])\n",
    "    return res_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(data_type):\n",
    "    \n",
    "    source_df, reply_df = clean_data(data_type)\n",
    "    source_df = concat_label(data_type, source_df)\n",
    "    source_df = concat_reply(data_type, source_df)\n",
    "    source_df = check_weekday(source_df)\n",
    "    source_df = concat_user_info(data_type, source_df)\n",
    "    reply_df = check_weekday(reply_df)\n",
    "    # add sentiment score\n",
    "    source_df['senti_score'] = source_df['text'].apply(lambda x: 1 if TextBlob(x).sentiment.polarity > 0 else 0)\n",
    "    reply_df['senti_score'] = reply_df['text'].apply(lambda x: 1 if TextBlob(x).sentiment.polarity > 0 else 0)\n",
    "    reply_df.index = reply_df['tweet_id']\n",
    "    # concat replies info to source_df\n",
    "    statis_feature = ['reply_count', 'like_count', 'retweet_count', 'quote_count', \n",
    "                        'possibly_sensitive', 'has_url', 'mentioned_url_num', \n",
    "                        'id_num', 'isweekday', 'senti_score']\n",
    "    source_df[['reply_text'] + statis_feature] = source_df.apply(lambda x: concat_reply_info(x['reply'], reply_df, statis_feature), axis=1, result_type='expand')                \n",
    "\n",
    "    return source_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = processing('train')\n",
    "dev_df = processing('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_df.to_csv('./data/filtered_data/train_source_df.csv')\n",
    "train_reply_df.to_csv('./data/filtered_data/train_reply_df.csv')\n",
    "dev_source_df.to_csv('./data/filtered_data/dev_source_df.csv')\n",
    "dev_reply_df.to_csv('./data/filtered_data/dev_reply_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>has_url</th>\n",
       "      <th>mentioned_url_num</th>\n",
       "      <th>id_num</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>label</th>\n",
       "      <th>reply</th>\n",
       "      <th>isweekday</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>senti_score</th>\n",
       "      <th>reply_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid fact hand dryer effect kill new coronavi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-11T16:01:39.000Z</td>\n",
       "      <td>35761403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1249004694950817796</td>\n",
       "      <td>0</td>\n",
       "      <td>1249011200068730880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34984</td>\n",
       "      <td>64281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fact germ breed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>expect result husband pend antibodi test pleas...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-06-01T20:23:06.000Z</td>\n",
       "      <td>2734457193</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1267552274819227649</td>\n",
       "      <td>0</td>\n",
       "      <td>1270394169836568576,1270502071175909376</td>\n",
       "      <td>2.0</td>\n",
       "      <td>758</td>\n",
       "      <td>14269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hi luck boat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid spread peopl catch covid other diseas sp...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-04T16:19:03.000Z</td>\n",
       "      <td>53980699</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1235238334722699265</td>\n",
       "      <td>0</td>\n",
       "      <td>1235234904281165825,1235234927937048577,123523...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3010</td>\n",
       "      <td>111037</td>\n",
       "      <td>3.0</td>\n",
       "      <td>read lot corona viru late think share highligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>everi news outlet use headlin like antibiot ef...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-10T22:56:50.000Z</td>\n",
       "      <td>393187879</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1248746792914546688</td>\n",
       "      <td>0</td>\n",
       "      <td>1248775858120097792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>939</td>\n",
       "      <td>17292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>appar headlin question answer usual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>research encount goliath birdeat world largest...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-10-19T12:59:47.000Z</td>\n",
       "      <td>39585367</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>523820806917603328</td>\n",
       "      <td>0</td>\n",
       "      <td>523821510042353664,523822210071658496,52382235...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1353894</td>\n",
       "      <td>46894</td>\n",
       "      <td>4.0</td>\n",
       "      <td>eu tenho uma dessa em casa são ótima para coça...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>cure covid howev sever ongo clinic trial inclu...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-13T06:17:21.000Z</td>\n",
       "      <td>817903682847182848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1249582429565829120</td>\n",
       "      <td>0</td>\n",
       "      <td>1249582412004306944,1249582416827727872,124958...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>113</td>\n",
       "      <td>2169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>treatment option covid includ drug vaccin ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>specul arrest banksi debut new mural bristol</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-10-22T11:15:21.000Z</td>\n",
       "      <td>20622594</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>524881688825167872</td>\n",
       "      <td>1</td>\n",
       "      <td>524882269941809153,525128786074173440</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1971453</td>\n",
       "      <td>58412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stori say someon vandalis black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>question answer red question mark repli number...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-03-20T07:51:15.000Z</td>\n",
       "      <td>570876529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1240908749256232960</td>\n",
       "      <td>0</td>\n",
       "      <td>1240908751063965696,1240908752842362881</td>\n",
       "      <td>2.0</td>\n",
       "      <td>158</td>\n",
       "      <td>736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>catch covid infect surfac packag infect area p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>anonym oper kkk klux klan never stop watch opk...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-11-02T08:49:29.000Z</td>\n",
       "      <td>247399641</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>661102820976930816</td>\n",
       "      <td>1</td>\n",
       "      <td>661241325237444608,661250292550270976</td>\n",
       "      <td>2.0</td>\n",
       "      <td>103802</td>\n",
       "      <td>231196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>call men hide time truth come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>expos sun temperatur higher degre prevent coro...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-09T14:47:39.000Z</td>\n",
       "      <td>300389524</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1248261299160612870</td>\n",
       "      <td>0</td>\n",
       "      <td>1248260447821869061,1248260618991304712,124826...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5021</td>\n",
       "      <td>149265</td>\n",
       "      <td>2.0</td>\n",
       "      <td>fast viru spread misinform surround covid equa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>538 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  reply_count  \\\n",
       "0    covid fact hand dryer effect kill new coronavi...          0.0   \n",
       "1    expect result husband pend antibodi test pleas...          2.0   \n",
       "2    covid spread peopl catch covid other diseas sp...          9.0   \n",
       "3    everi news outlet use headlin like antibiot ef...          0.0   \n",
       "4    research encount goliath birdeat world largest...          5.0   \n",
       "..                                                 ...          ...   \n",
       "533  cure covid howev sever ongo clinic trial inclu...          6.0   \n",
       "534       specul arrest banksi debut new mural bristol          1.0   \n",
       "535  question answer red question mark repli number...          1.0   \n",
       "536  anonym oper kkk klux klan never stop watch opk...          0.0   \n",
       "537  expos sun temperatur higher degre prevent coro...          5.0   \n",
       "\n",
       "     like_count  retweet_count  quote_count  possibly_sensitive  \\\n",
       "0           0.0            0.0          0.0                 0.0   \n",
       "1           0.0            0.0          0.0                 0.0   \n",
       "2           3.0            2.0          1.0                 0.0   \n",
       "3           1.0            0.0          0.0                 0.0   \n",
       "4           2.0            1.0          0.0                 0.0   \n",
       "..          ...            ...          ...                 ...   \n",
       "533         0.0            0.0          0.0                 0.0   \n",
       "534         0.0            0.0          0.0                 0.0   \n",
       "535         0.0            0.0          0.0                 0.0   \n",
       "536         0.0            0.0          0.0                 0.0   \n",
       "537        50.0           58.0          3.0                 0.0   \n",
       "\n",
       "                   created_at             user_id  has_url  mentioned_url_num  \\\n",
       "0    2020-04-11T16:01:39.000Z            35761403      1.0                0.0   \n",
       "1    2020-06-01T20:23:06.000Z          2734457193      2.0                0.0   \n",
       "2    2020-03-04T16:19:03.000Z            53980699      3.0                0.0   \n",
       "3    2020-04-10T22:56:50.000Z           393187879      1.0                0.0   \n",
       "4    2014-10-19T12:59:47.000Z            39585367     26.0               10.0   \n",
       "..                        ...                 ...      ...                ...   \n",
       "533  2020-04-13T06:17:21.000Z  817903682847182848      0.0                0.0   \n",
       "534  2014-10-22T11:15:21.000Z            20622594      2.0                0.0   \n",
       "535  2020-03-20T07:51:15.000Z           570876529      0.0                0.0   \n",
       "536  2015-11-02T08:49:29.000Z           247399641      2.0                1.0   \n",
       "537  2020-04-09T14:47:39.000Z           300389524      2.0                0.0   \n",
       "\n",
       "     id_num             tweet_id  label  \\\n",
       "0       1.0  1249004694950817796      0   \n",
       "1       4.0  1267552274819227649      0   \n",
       "2       0.0  1235238334722699265      0   \n",
       "3       1.0  1248746792914546688      0   \n",
       "4      59.0   523820806917603328      0   \n",
       "..      ...                  ...    ...   \n",
       "533     0.0  1249582429565829120      0   \n",
       "534     3.0   524881688825167872      1   \n",
       "535     0.0  1240908749256232960      0   \n",
       "536     4.0   661102820976930816      1   \n",
       "537     2.0  1248261299160612870      0   \n",
       "\n",
       "                                                 reply  isweekday  \\\n",
       "0                                  1249011200068730880        0.0   \n",
       "1              1270394169836568576,1270502071175909376        2.0   \n",
       "2    1235234904281165825,1235234927937048577,123523...       10.0   \n",
       "3                                  1248775858120097792        0.0   \n",
       "4    523821510042353664,523822210071658496,52382235...        4.0   \n",
       "..                                                 ...        ...   \n",
       "533  1249582412004306944,1249582416827727872,124958...        7.0   \n",
       "534              524882269941809153,525128786074173440        2.0   \n",
       "535            1240908751063965696,1240908752842362881        2.0   \n",
       "536              661241325237444608,661250292550270976        2.0   \n",
       "537  1248260447821869061,1248260618991304712,124826...        4.0   \n",
       "\n",
       "     followers_count  tweet_count  senti_score  \\\n",
       "0              34984        64281          0.0   \n",
       "1                758        14269          0.0   \n",
       "2               3010       111037          3.0   \n",
       "3                939        17292          0.0   \n",
       "4            1353894        46894          4.0   \n",
       "..               ...          ...          ...   \n",
       "533              113         2169          1.0   \n",
       "534          1971453        58412          0.0   \n",
       "535              158          736          0.0   \n",
       "536           103802       231196          0.0   \n",
       "537             5021       149265          2.0   \n",
       "\n",
       "                                            reply_text  \n",
       "0                                      fact germ breed  \n",
       "1                                         hi luck boat  \n",
       "2    read lot corona viru late think share highligh...  \n",
       "3                  appar headlin question answer usual  \n",
       "4    eu tenho uma dessa em casa são ótima para coça...  \n",
       "..                                                 ...  \n",
       "533  treatment option covid includ drug vaccin ther...  \n",
       "534                    stori say someon vandalis black  \n",
       "535  catch covid infect surfac packag infect area p...  \n",
       "536                      call men hide time truth come  \n",
       "537  fast viru spread misinform surround covid equa...  \n",
       "\n",
       "[538 rows x 19 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOajrT/dzdArYA2l9SrPGaw",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Pre-processing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
